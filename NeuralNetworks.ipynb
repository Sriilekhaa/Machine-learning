{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JQx4_4zmaVh",
        "outputId": "cab833fe-1423-47eb-ae46-5eeb8a6bef7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training AND gate with Sigmoid activation function and bias:\n",
            "Epoch 1:\n",
            "Updated Weights: [-0.15863512  0.62865669]\n",
            "Updated Bias: -0.18527686119676431\n",
            "Total Error: 1.8952988708722698\n",
            "Epoch 2:\n",
            "Updated Weights: [-0.15788406  0.62684013]\n",
            "Updated Bias: -0.19790095541050168\n",
            "Total Error: 1.9450480380123991\n",
            "Epoch 3:\n",
            "Updated Weights: [-0.15708919  0.62526773]\n",
            "Updated Bias: -0.20994692871265552\n",
            "Total Error: 1.9373997537211152\n",
            "Epoch 4:\n",
            "Updated Weights: [-0.15675254  0.62320825]\n",
            "Updated Bias: -0.22192797760876073\n",
            "Total Error: 1.8694368583777212\n",
            "Epoch 5:\n",
            "Updated Weights: [-0.15613158  0.62130377]\n",
            "Updated Bias: -0.23411473800384505\n",
            "Total Error: 1.9086174486047593\n",
            "Epoch 6:\n",
            "Updated Weights: [-0.15521422  0.61940414]\n",
            "Updated Bias: -0.24621892061254932\n",
            "Total Error: 1.8975144300254336\n",
            "Epoch 7:\n",
            "Updated Weights: [-0.15317307  0.6183576 ]\n",
            "Updated Bias: -0.25653161447998524\n",
            "Total Error: 1.8591186552386771\n",
            "Epoch 8:\n",
            "Updated Weights: [-0.15239385  0.61702568]\n",
            "Updated Bias: -0.2683358871694912\n",
            "Total Error: 1.909366145194476\n",
            "\n",
            "Training AND gate with Sigmoid activation function without bias:\n",
            "Epoch 1:\n",
            "Updated Weights: [-0.30601865 -0.03949427]\n",
            "Total Error: 1.996303039206249\n",
            "Epoch 2:\n",
            "Updated Weights: [-0.30420632 -0.03849765]\n",
            "Total Error: 2.0193714422651374\n",
            "Epoch 3:\n",
            "Updated Weights: [-0.30242363 -0.03756841]\n",
            "Total Error: 2.0301490674835283\n",
            "Epoch 4:\n",
            "Updated Weights: [-0.30059881 -0.03671191]\n",
            "Total Error: 1.9935003256428692\n",
            "Epoch 5:\n",
            "Updated Weights: [-0.29894744 -0.03565609]\n",
            "Total Error: 2.0144713069914317\n",
            "Epoch 6:\n",
            "Updated Weights: [-0.29712204 -0.03468291]\n",
            "Total Error: 2.0017837086269674\n",
            "Epoch 7:\n",
            "Updated Weights: [-0.29510056 -0.03369685]\n",
            "Total Error: 1.991912379929862\n",
            "Epoch 8:\n",
            "Updated Weights: [-0.29316909 -0.03274078]\n",
            "Total Error: 2.0202219001533726\n",
            "Epoch 9:\n",
            "Updated Weights: [-0.29138301 -0.03174065]\n",
            "Total Error: 1.981439393894822\n",
            "Epoch 10:\n",
            "Updated Weights: [-0.28921603 -0.03062732]\n",
            "Total Error: 1.97134840313051\n",
            "Epoch 11:\n",
            "Updated Weights: [-0.2871962  -0.02958449]\n",
            "Total Error: 1.9973878506897094\n",
            "Epoch 12:\n",
            "Updated Weights: [-0.28532627 -0.02877963]\n",
            "Total Error: 1.9767372726901986\n",
            "\n",
            "Training AND gate with Tanh activation function and bias:\n",
            "Epoch 1:\n",
            "Updated Weights: [ 0.78479377 -0.31856506]\n",
            "Updated Bias: -0.4820100391019235\n",
            "Total Error: 2.6696372387811755\n",
            "Epoch 2:\n",
            "Updated Weights: [ 0.81865067 -0.25151927]\n",
            "Updated Bias: -0.4135035071374295\n",
            "Total Error: 2.5153755109209515\n",
            "Epoch 3:\n",
            "Updated Weights: [ 0.84259353 -0.1952048 ]\n",
            "Updated Bias: -0.3522616017614926\n",
            "Total Error: 2.1793218701321435\n",
            "Epoch 4:\n",
            "Updated Weights: [ 0.84752506 -0.15554888]\n",
            "Updated Bias: -0.31633670216449983\n",
            "Total Error: 1.7974768803690782\n",
            "Epoch 5:\n",
            "Updated Weights: [ 0.8574232  -0.11124347]\n",
            "Updated Bias: -0.27430945166231696\n",
            "Total Error: 1.8267434303774137\n",
            "Epoch 6:\n",
            "Updated Weights: [ 0.87142738 -0.07130685]\n",
            "Updated Bias: -0.24168441382201533\n",
            "Total Error: 1.3932061653481398\n",
            "Epoch 7:\n",
            "Updated Weights: [ 0.86944097 -0.04532921]\n",
            "Updated Bias: -0.22088731582583127\n",
            "Total Error: 1.557374650076814\n",
            "Epoch 8:\n",
            "Updated Weights: [ 0.86653605 -0.01655777]\n",
            "Updated Bias: -0.20237685069546318\n",
            "Total Error: 1.4372468464105963\n",
            "Epoch 9:\n",
            "Updated Weights: [0.86197987 0.0010626 ]\n",
            "Updated Bias: -0.19344604166992266\n",
            "Total Error: 1.2957136265479265\n",
            "Epoch 10:\n",
            "Updated Weights: [0.86907297 0.03255101]\n",
            "Updated Bias: -0.174875616206261\n",
            "Total Error: 1.502853079079743\n",
            "\n",
            "Training AND gate with Tanh activation function without bias:\n",
            "Epoch 1:\n",
            "Updated Weights: [ 0.49507278 -0.65191593]\n",
            "Total Error: 2.2296972434073656\n",
            "Epoch 2:\n",
            "Updated Weights: [ 0.53411246 -0.57507115]\n",
            "Total Error: 2.308092140420212\n",
            "Epoch 3:\n",
            "Updated Weights: [ 0.56916199 -0.50505637]\n",
            "Total Error: 2.0359467036059495\n",
            "Epoch 4:\n",
            "Updated Weights: [ 0.59771963 -0.43895395]\n",
            "Total Error: 1.9617328325609686\n",
            "Epoch 5:\n",
            "Updated Weights: [ 0.61963707 -0.38035523]\n",
            "Total Error: 1.8170750929410078\n",
            "Epoch 6:\n",
            "Updated Weights: [ 0.64377408 -0.32603646]\n",
            "Total Error: 1.6941129135144664\n",
            "Epoch 7:\n",
            "Updated Weights: [ 0.65290691 -0.28574587]\n",
            "Total Error: 1.533645802967162\n",
            "Epoch 8:\n",
            "Updated Weights: [ 0.65934379 -0.25086395]\n",
            "Total Error: 1.3396518885609372\n",
            "Epoch 9:\n",
            "Updated Weights: [ 0.66689002 -0.21449312]\n",
            "Total Error: 1.4113010312584784\n",
            "Epoch 10:\n",
            "Updated Weights: [ 0.67210053 -0.18976423]\n",
            "Total Error: 1.2397363480238508\n",
            "Epoch 11:\n",
            "Updated Weights: [ 0.6837281  -0.15276387]\n",
            "Total Error: 1.440666105922683\n",
            "Epoch 12:\n",
            "Updated Weights: [ 0.67915783 -0.12713476]\n",
            "Total Error: 1.2962436219919615\n",
            "Epoch 13:\n",
            "Updated Weights: [ 0.67867785 -0.10133466]\n",
            "Total Error: 1.3444427194564699\n",
            "Epoch 14:\n",
            "Updated Weights: [ 0.67572322 -0.07203366]\n",
            "Total Error: 1.3859965117352187\n",
            "\n",
            "Training AND gate with ReLU activation function and bias:\n",
            "Epoch 1:\n",
            "Updated Weights: [-0.67586443  0.46807261]\n",
            "Updated Bias: -0.5470995805724054\n",
            "Total Error: 1.0308136500414788\n",
            "Epoch 2:\n",
            "Updated Weights: [-0.67586443  0.46807261]\n",
            "Updated Bias: -0.5470995805724054\n",
            "Total Error: 1.0\n",
            "Epoch 3:\n",
            "Updated Weights: [-0.67586443  0.46807261]\n",
            "Updated Bias: -0.5470995805724054\n",
            "Total Error: 1.0\n",
            "Epoch 4:\n",
            "Updated Weights: [-0.67586443  0.46807261]\n",
            "Updated Bias: -0.5470995805724054\n",
            "Total Error: 1.0\n",
            "Epoch 5:\n",
            "Updated Weights: [-0.67586443  0.46807261]\n",
            "Updated Bias: -0.5470995805724054\n",
            "Total Error: 1.0\n",
            "Epoch 6:\n",
            "Updated Weights: [-0.67586443  0.46807261]\n",
            "Updated Bias: -0.5470995805724054\n",
            "Total Error: 1.0\n",
            "Epoch 7:\n",
            "Updated Weights: [-0.67586443  0.46136894]\n",
            "Updated Bias: -0.5538032438471835\n",
            "Total Error: 1.1340732654955623\n",
            "\n",
            "Training AND gate with ReLU activation function without bias:\n",
            "Epoch 1:\n",
            "Updated Weights: [0.73894422 0.87307036]\n",
            "Total Error: 2.397644170017405\n",
            "Epoch 2:\n",
            "Updated Weights: [0.68210109 0.80792822]\n",
            "Total Error: 2.187915188967386\n",
            "Epoch 3:\n",
            "Updated Weights: [0.63120817 0.73236566]\n",
            "Total Error: 2.0027330129205243\n",
            "Epoch 4:\n",
            "Updated Weights: [0.58193251 0.6789067 ]\n",
            "Total Error: 1.6631917571751507\n",
            "Epoch 5:\n",
            "Updated Weights: [0.5401254  0.64473679]\n",
            "Total Error: 1.3735915378043497\n",
            "Epoch 6:\n",
            "Updated Weights: [0.50468326 0.59863505]\n",
            "Total Error: 1.4271332577672702\n",
            "Epoch 7:\n",
            "Updated Weights: [0.48088622 0.56146056]\n",
            "Total Error: 1.3430345818528777\n",
            "Epoch 8:\n",
            "Updated Weights: [0.44966375 0.52564986]\n",
            "Total Error: 1.1752548161075642\n",
            "Epoch 9:\n",
            "Updated Weights: [0.42704502 0.50822892]\n",
            "Total Error: 0.8945902471966811\n",
            "\n",
            "Training XOR gate with Sigmoid activation function and bias:\n",
            "Epoch 1:\n",
            "Updated Weights: [ 0.65143944 -0.38150654]\n",
            "Updated Bias: 0.9102033638346395\n",
            "Total Error: 2.0434928954730154\n",
            "Epoch 2:\n",
            "Updated Weights: [ 0.64580291 -0.38377567]\n",
            "Updated Bias: 0.9020580617676648\n",
            "Total Error: 2.069104880956403\n",
            "Epoch 3:\n",
            "Updated Weights: [ 0.64023095 -0.38588495]\n",
            "Updated Bias: 0.8940809533908052\n",
            "Total Error: 2.058502700513815\n",
            "Epoch 4:\n",
            "Updated Weights: [ 0.63455329 -0.38801589]\n",
            "Updated Bias: 0.8861497134907684\n",
            "Total Error: 2.0800809528243644\n",
            "Epoch 5:\n",
            "Updated Weights: [ 0.62887177 -0.39006384]\n",
            "Updated Bias: 0.8779602165526365\n",
            "Total Error: 2.0423797470128306\n",
            "Epoch 6:\n",
            "Updated Weights: [ 0.62302438 -0.39252031]\n",
            "Updated Bias: 0.8695109076023693\n",
            "Total Error: 2.039150647678428\n",
            "Epoch 7:\n",
            "Updated Weights: [ 0.61740761 -0.39476032]\n",
            "Updated Bias: 0.8613332722675431\n",
            "Total Error: 2.034176090618629\n",
            "Epoch 8:\n",
            "Updated Weights: [ 0.61153255 -0.39682489]\n",
            "Updated Bias: 0.8532667797413128\n",
            "Total Error: 2.04702667656562\n",
            "Epoch 9:\n",
            "Updated Weights: [ 0.60578602 -0.39897359]\n",
            "Updated Bias: 0.8450672541093605\n",
            "Total Error: 2.03045964550657\n",
            "Epoch 10:\n",
            "Updated Weights: [ 0.5999925  -0.40134106]\n",
            "Updated Bias: 0.8367605625439749\n",
            "Total Error: 2.030545607628558\n",
            "Epoch 11:\n",
            "Updated Weights: [ 0.59464344 -0.40359898]\n",
            "Updated Bias: 0.8289738794684451\n",
            "Total Error: 2.059702359556473\n",
            "Epoch 12:\n",
            "Updated Weights: [ 0.58910974 -0.40605819]\n",
            "Updated Bias: 0.8207920934022186\n",
            "Total Error: 2.0302596814527365\n",
            "\n",
            "Training XOR gate with Sigmoid activation function without bias:\n",
            "Epoch 1:\n",
            "Updated Weights: [-0.13840637  0.45305152]\n",
            "Total Error: 1.9871492399172934\n",
            "Epoch 2:\n",
            "Updated Weights: [-0.13863364  0.45061056]\n",
            "Total Error: 2.0010863185370096\n",
            "Epoch 3:\n",
            "Updated Weights: [-0.13887946  0.44839356]\n",
            "Total Error: 1.9817334858025348\n",
            "Epoch 4:\n",
            "Updated Weights: [-0.13981019  0.44582583]\n",
            "Total Error: 1.9606352720925293\n",
            "Epoch 5:\n",
            "Updated Weights: [-0.1403356   0.44307075]\n",
            "Total Error: 1.9806228825248273\n",
            "Epoch 6:\n",
            "Updated Weights: [-0.1407257   0.44071711]\n",
            "Total Error: 2.0049298768972093\n",
            "Epoch 7:\n",
            "Updated Weights: [-0.14122171  0.43833091]\n",
            "Total Error: 2.0192200791892545\n",
            "Epoch 8:\n",
            "Updated Weights: [-0.14208778  0.43580979]\n",
            "Total Error: 1.97994802323125\n",
            "Epoch 9:\n",
            "Updated Weights: [-0.14258309  0.43338527]\n",
            "Total Error: 1.9804224171685934\n",
            "Epoch 10:\n",
            "Updated Weights: [-0.14295052  0.43112351]\n",
            "Total Error: 1.999721229772131\n",
            "\n",
            "Training XOR gate with Tanh activation function and bias:\n",
            "Epoch 1:\n",
            "Updated Weights: [0.29439334 0.12960936]\n",
            "Updated Bias: -0.435696976576131\n",
            "Total Error: 3.262357234984272\n",
            "Epoch 2:\n",
            "Updated Weights: [0.33634509 0.17571688]\n",
            "Updated Bias: -0.31789053491677416\n",
            "Total Error: 3.1244909706080044\n",
            "Epoch 3:\n",
            "Updated Weights: [0.36249684 0.21532075]\n",
            "Updated Bias: -0.22062400397917792\n",
            "Total Error: 2.8067436137532096\n",
            "Epoch 4:\n",
            "Updated Weights: [0.38282398 0.2451792 ]\n",
            "Updated Bias: -0.13977288609937044\n",
            "Total Error: 2.5816061829630543\n",
            "Epoch 5:\n",
            "Updated Weights: [0.39501125 0.2709355 ]\n",
            "Updated Bias: -0.07250459962845539\n",
            "Total Error: 2.342709392517075\n",
            "Epoch 6:\n",
            "Updated Weights: [0.40719818 0.2930345 ]\n",
            "Updated Bias: -0.015248621228008574\n",
            "Total Error: 2.275421633735071\n",
            "Epoch 7:\n",
            "Updated Weights: [0.40986374 0.30785579]\n",
            "Updated Bias: 0.023705078816657225\n",
            "Total Error: 1.949671945955469\n",
            "Epoch 8:\n",
            "Updated Weights: [0.41900947 0.32809735]\n",
            "Updated Bias: 0.07091040621162549\n",
            "Total Error: 2.123061234767289\n",
            "\n",
            "Training XOR gate with Tanh activation function without bias:\n",
            "Epoch 1:\n",
            "Updated Weights: [ 0.31819526 -0.00682483]\n",
            "Total Error: 1.990817453837165\n",
            "Epoch 2:\n",
            "Updated Weights: [0.33467389 0.02781467]\n",
            "Total Error: 2.115926915084807\n",
            "Epoch 3:\n",
            "Updated Weights: [0.34742839 0.06102869]\n",
            "Total Error: 2.0983200929429833\n",
            "Epoch 4:\n",
            "Updated Weights: [0.3571463  0.09152293]\n",
            "Total Error: 2.0325168378516096\n",
            "Epoch 5:\n",
            "Updated Weights: [0.37461547 0.11657636]\n",
            "Total Error: 2.068955298118258\n",
            "Epoch 6:\n",
            "Updated Weights: [0.38213156 0.13873124]\n",
            "Total Error: 1.9861256799222602\n",
            "Epoch 7:\n",
            "Updated Weights: [0.39036724 0.15631823]\n",
            "Total Error: 1.9411950669123534\n",
            "Epoch 8:\n",
            "Updated Weights: [0.40121185 0.17194391]\n",
            "Total Error: 1.997782423506349\n",
            "Epoch 9:\n",
            "Updated Weights: [0.40936636 0.19079533]\n",
            "Total Error: 2.0353670635529277\n",
            "Epoch 10:\n",
            "Updated Weights: [0.41694581 0.20788786]\n",
            "Total Error: 2.068799276030564\n",
            "Epoch 11:\n",
            "Updated Weights: [0.42274497 0.22732967]\n",
            "Total Error: 2.0508017940431973\n",
            "\n",
            "Training XOR gate with ReLU activation function and bias:\n",
            "Epoch 1:\n",
            "Updated Weights: [0.35890388 0.70597889]\n",
            "Updated Bias: 0.378618371762593\n",
            "Total Error: 2.559444532420833\n",
            "Epoch 2:\n",
            "Updated Weights: [0.30111612 0.63095145]\n",
            "Updated Bias: 0.2990869751769423\n",
            "Total Error: 2.1114818317822026\n",
            "Epoch 3:\n",
            "Updated Weights: [0.25648654 0.57116718]\n",
            "Updated Bias: 0.2458186576874979\n",
            "Total Error: 1.8625899030672721\n",
            "Epoch 4:\n",
            "Updated Weights: [0.23186242 0.5229328 ]\n",
            "Updated Bias: 0.20925506426427168\n",
            "Total Error: 2.096975405851185\n",
            "Epoch 5:\n",
            "Updated Weights: [0.20972684 0.48279852]\n",
            "Updated Bias: 0.19158268007346754\n",
            "Total Error: 2.1510891424170797\n",
            "Epoch 6:\n",
            "Updated Weights: [0.19216654 0.45165847]\n",
            "Updated Bias: 0.17725503342207266\n",
            "Total Error: 2.210793570706126\n",
            "Epoch 7:\n",
            "Updated Weights: [0.17444528 0.42348928]\n",
            "Updated Bias: 0.16676074368901952\n",
            "Total Error: 2.0335706168366188\n",
            "Epoch 8:\n",
            "Updated Weights: [0.16589067 0.40266102]\n",
            "Updated Bias: 0.17134688803556233\n",
            "Total Error: 1.913115789491394\n",
            "Epoch 9:\n",
            "Updated Weights: [0.15725146 0.38550085]\n",
            "Updated Bias: 0.17916860315329663\n",
            "Total Error: 2.2255677669960745\n",
            "\n",
            "Training XOR gate with ReLU activation function without bias:\n",
            "Epoch 1:\n",
            "Updated Weights: [-0.61925858 -0.70085499]\n",
            "Total Error: 2.1382397144153202\n",
            "Epoch 2:\n",
            "Updated Weights: [-0.61925858 -0.70085499]\n",
            "Total Error: 2.2345117340705682\n",
            "Epoch 3:\n",
            "Updated Weights: [-0.61925858 -0.70085499]\n",
            "Total Error: 2.035541086225467\n",
            "Epoch 4:\n",
            "Updated Weights: [-0.61925858 -0.70085499]\n",
            "Total Error: 2.055814035261074\n",
            "Epoch 5:\n",
            "Updated Weights: [-0.61925858 -0.70085499]\n",
            "Total Error: 2.0\n",
            "Epoch 6:\n",
            "Updated Weights: [-0.61925858 -0.70085499]\n",
            "Total Error: 2.0\n",
            "Epoch 7:\n",
            "Updated Weights: [-0.61925858 -0.70085499]\n",
            "Total Error: 2.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define activation functions and their derivatives\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "def tanh_derivative(x):\n",
        "    return 1 - x ** 2\n",
        "\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def relu_derivative(x):\n",
        "    return np.where(x > 0, 1, 0)\n",
        "\n",
        "# Single Layer Perceptron class\n",
        "class SingleLayerPerceptron:\n",
        "    def __init__(self, input_size, activation_function, activation_derivative, bias=True, learning_rate=0.05):\n",
        "        self.weights = np.random.uniform(-1, 1, input_size)\n",
        "        self.bias = np.random.uniform(-1, 1) if bias else 0\n",
        "        self.activation_function = activation_function\n",
        "        self.activation_derivative = activation_derivative\n",
        "        self.learning_rate = learning_rate\n",
        "        self.bias_included = bias\n",
        "\n",
        "    def predict(self, inputs):\n",
        "        weighted_sum = np.dot(inputs, self.weights) + self.bias\n",
        "        return self.activation_function(weighted_sum)\n",
        "\n",
        "    def train(self, inputs, labels, epochs=8):\n",
        "        for epoch in range(epochs):\n",
        "            total_error = 0\n",
        "            for input_vector, label in zip(inputs, labels):\n",
        "                noisy_input = input_vector + np.random.normal(0, 0.1, input_vector.shape)\n",
        "                output = self.predict(noisy_input)\n",
        "                error = label - output\n",
        "                total_error += np.sum(np.abs(error))  # Absolute Error\n",
        "\n",
        "                adjustment = self.learning_rate * error * self.activation_derivative(output)\n",
        "                self.weights += adjustment * input_vector\n",
        "                if self.bias_included:\n",
        "                    self.bias += adjustment\n",
        "\n",
        "            # Print updated weights, bias, and error at each epoch\n",
        "            print(f'Epoch {epoch + 1}:')\n",
        "            print(f'Updated Weights: {self.weights}')\n",
        "            if self.bias_included:\n",
        "                print(f'Updated Bias: {self.bias}')\n",
        "            print(f'Total Error: {total_error}')\n",
        "\n",
        "# Define datasets\n",
        "AND_inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "AND_labels = np.array([0, 0, 0, 1])\n",
        "\n",
        "XOR_inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "XOR_labels = np.array([0, 1, 1, 0])\n",
        "\n",
        "# Training for AND gate\n",
        "\n",
        "# Sigmoid activation function with bias\n",
        "print(\"Training AND gate with Sigmoid activation function and bias:\")\n",
        "perceptron_and_sigmoid = SingleLayerPerceptron(input_size=2, activation_function=sigmoid, activation_derivative=sigmoid_derivative, bias=True)\n",
        "perceptron_and_sigmoid.train(AND_inputs, AND_labels, epochs=8)\n",
        "\n",
        "# Sigmoid activation function without bias\n",
        "print(\"\\nTraining AND gate with Sigmoid activation function without bias:\")\n",
        "perceptron_and_sigmoid_no_bias = SingleLayerPerceptron(input_size=2, activation_function=sigmoid, activation_derivative=sigmoid_derivative, bias=False)\n",
        "perceptron_and_sigmoid_no_bias.train(AND_inputs, AND_labels, epochs=12)\n",
        "\n",
        "# Tanh activation function with bias\n",
        "print(\"\\nTraining AND gate with Tanh activation function and bias:\")\n",
        "perceptron_and_tanh = SingleLayerPerceptron(input_size=2, activation_function=tanh, activation_derivative=tanh_derivative, bias=True)\n",
        "perceptron_and_tanh.train(AND_inputs, AND_labels, epochs=10)\n",
        "\n",
        "# Tanh activation function without bias\n",
        "print(\"\\nTraining AND gate with Tanh activation function without bias:\")\n",
        "perceptron_and_tanh_no_bias = SingleLayerPerceptron(input_size=2, activation_function=tanh, activation_derivative=tanh_derivative, bias=False)\n",
        "perceptron_and_tanh_no_bias.train(AND_inputs, AND_labels, epochs=14)\n",
        "\n",
        "# ReLU activation function with bias\n",
        "print(\"\\nTraining AND gate with ReLU activation function and bias:\")\n",
        "perceptron_and_relu = SingleLayerPerceptron(input_size=2, activation_function=relu, activation_derivative=relu_derivative, bias=True)\n",
        "perceptron_and_relu.train(AND_inputs, AND_labels, epochs=7)\n",
        "\n",
        "# ReLU activation function without bias\n",
        "print(\"\\nTraining AND gate with ReLU activation function without bias:\")\n",
        "perceptron_and_relu_no_bias = SingleLayerPerceptron(input_size=2, activation_function=relu, activation_derivative=relu_derivative, bias=False)\n",
        "perceptron_and_relu_no_bias.train(AND_inputs, AND_labels, epochs=9)\n",
        "\n",
        "# Training for XOR gate\n",
        "\n",
        "# Sigmoid activation function with bias\n",
        "print(\"\\nTraining XOR gate with Sigmoid activation function and bias:\")\n",
        "perceptron_xor_sigmoid = SingleLayerPerceptron(input_size=2, activation_function=sigmoid, activation_derivative=sigmoid_derivative, bias=True)\n",
        "perceptron_xor_sigmoid.train(XOR_inputs, XOR_labels, epochs=12)\n",
        "\n",
        "# Sigmoid activation function without bias\n",
        "print(\"\\nTraining XOR gate with Sigmoid activation function without bias:\")\n",
        "perceptron_xor_sigmoid_no_bias = SingleLayerPerceptron(input_size=2, activation_function=sigmoid, activation_derivative=sigmoid_derivative, bias=False)\n",
        "perceptron_xor_sigmoid_no_bias.train(XOR_inputs, XOR_labels, epochs=10)\n",
        "\n",
        "# Tanh activation function with bias\n",
        "print(\"\\nTraining XOR gate with Tanh activation function and bias:\")\n",
        "perceptron_xor_tanh = SingleLayerPerceptron(input_size=2, activation_function=tanh, activation_derivative=tanh_derivative, bias=True)\n",
        "perceptron_xor_tanh.train(XOR_inputs, XOR_labels, epochs=8)\n",
        "\n",
        "# Tanh activation function without bias\n",
        "print(\"\\nTraining XOR gate with Tanh activation function without bias:\")\n",
        "perceptron_xor_tanh_no_bias = SingleLayerPerceptron(input_size=2, activation_function=tanh, activation_derivative=tanh_derivative, bias=False)\n",
        "perceptron_xor_tanh_no_bias.train(XOR_inputs, XOR_labels, epochs=11)\n",
        "\n",
        "# ReLU activation function with bias\n",
        "print(\"\\nTraining XOR gate with ReLU activation function and bias:\")\n",
        "perceptron_xor_relu = SingleLayerPerceptron(input_size=2, activation_function=relu, activation_derivative=relu_derivative, bias=True)\n",
        "perceptron_xor_relu.train(XOR_inputs, XOR_labels, epochs=9)\n",
        "\n",
        "# ReLU activation function without bias\n",
        "print(\"\\nTraining XOR gate with ReLU activation function without bias:\")\n",
        "perceptron_xor_relu_no_bias = SingleLayerPerceptron(input_size=2, activation_function=relu, activation_derivative=relu_derivative, bias=False)\n",
        "perceptron_xor_relu_no_bias.train(XOR_inputs, XOR_labels, epochs=7)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define activation functions and their gradients\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_grad(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "def tanh_grad(x):\n",
        "    return 1 - np.power(x, 2)\n",
        "\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def relu_grad(x):\n",
        "    return (x > 0).astype(float)\n",
        "\n",
        "# Multi-Layer Perceptron class\n",
        "class MLP:\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, activation_fn, activation_grad, use_bias=True, lr=0.1):\n",
        "        self.w_in_hidden = np.random.uniform(-1, 1, (input_dim, hidden_dim))\n",
        "        self.w_hidden_out = np.random.uniform(-1, 1, (hidden_dim, output_dim))\n",
        "        self.bias_hidden = np.random.uniform(-1, 1, hidden_dim) if use_bias else np.zeros(hidden_dim)\n",
        "        self.bias_output = np.random.uniform(-1, 1, output_dim) if use_bias else np.zeros(output_dim)\n",
        "        self.activation_fn = activation_fn\n",
        "        self.activation_grad = activation_grad\n",
        "        self.lr = lr\n",
        "        self.use_bias = use_bias\n",
        "\n",
        "    def forward_pass(self, inputs):\n",
        "        self.hidden_input = np.dot(inputs, self.w_in_hidden) + self.bias_hidden\n",
        "        self.hidden_output = self.activation_fn(self.hidden_input)\n",
        "        self.final_input = np.dot(self.hidden_output, self.w_hidden_out) + self.bias_output\n",
        "        self.final_output = self.activation_fn(self.final_input)\n",
        "        return self.final_output\n",
        "\n",
        "    def calculate_loss(self, targets):\n",
        "        return np.mean(np.square(targets - self.final_output))\n",
        "\n",
        "    def backprop(self, inputs, targets):\n",
        "        output_error = targets - self.final_output\n",
        "        output_delta = output_error * self.activation_grad(self.final_output)\n",
        "\n",
        "        hidden_error = np.dot(output_delta, self.w_hidden_out.T)\n",
        "        hidden_delta = hidden_error * self.activation_grad(self.hidden_output)\n",
        "\n",
        "        self.w_hidden_out += self.lr * np.dot(self.hidden_output.T, output_delta)\n",
        "        self.w_in_hidden += self.lr * np.dot(inputs.T, hidden_delta)\n",
        "\n",
        "        if self.use_bias:\n",
        "            self.bias_output += self.lr * np.sum(output_delta, axis=0)\n",
        "            self.bias_hidden += self.lr * np.sum(hidden_delta, axis=0)\n",
        "\n",
        "    def train(self, inputs, targets, num_epochs=10):\n",
        "        for epoch in range(num_epochs):\n",
        "            epoch_loss = 0\n",
        "            for input_sample, target in zip(inputs, targets):\n",
        "                input_sample = input_sample.reshape(1, -1)\n",
        "                target = target.reshape(1, -1)\n",
        "                self.forward_pass(input_sample)\n",
        "                self.backprop(input_sample, target)\n",
        "                epoch_loss += self.calculate_loss(target)\n",
        "\n",
        "            # Print the status after each epoch\n",
        "            print(f'Epoch {epoch + 1}:')\n",
        "            print(f'Weights (Input to Hidden):\\n{self.w_in_hidden}')\n",
        "            print(f'Weights (Hidden to Output):\\n{self.w_hidden_out}')\n",
        "            if self.use_bias:\n",
        "                print(f'Hidden Bias:\\n{self.bias_hidden}')\n",
        "                print(f'Output Bias:\\n{self.bias_output}')\n",
        "            print(f'Epoch Loss: {epoch_loss}\\n')\n",
        "\n",
        "# Define datasets\n",
        "AND_inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "AND_labels_single_output = np.array([[0], [0], [0], [1]])\n",
        "AND_labels_multi_output = np.array([[1, 0], [0, 1], [0, 1], [1, 0]])\n",
        "\n",
        "XOR_inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "XOR_labels_single_output = np.array([[0], [1], [1], [0]])\n",
        "XOR_labels_multi_output = np.array([[1, 0], [0, 1], [0, 1], [1, 0]])\n",
        "\n",
        "# Training for AND gate (Single Output)\n",
        "\n",
        "# Sigmoid activation function with bias\n",
        "print(\"Training AND gate (Single Output) with Sigmoid activation function and bias:\")\n",
        "mlp_and_sigmoid = MLP(input_dim=2, hidden_dim=2, output_dim=1, activation_fn=sigmoid, activation_grad=sigmoid_grad, use_bias=True)\n",
        "mlp_and_sigmoid.train(AND_inputs, AND_labels_single_output, num_epochs=10)\n",
        "\n",
        "# Sigmoid activation function without bias\n",
        "print(\"\\nTraining AND gate (Single Output) with Sigmoid activation function without bias:\")\n",
        "mlp_and_sigmoid_no_bias = MLP(input_dim=2, hidden_dim=2, output_dim=1, activation_fn=sigmoid, activation_grad=sigmoid_grad, use_bias=False)\n",
        "mlp_and_sigmoid_no_bias.train(AND_inputs, AND_labels_single_output, num_epochs=10)\n",
        "\n",
        "# Tanh activation function with bias\n",
        "print(\"\\nTraining AND gate (Single Output) with Tanh activation function and bias:\")\n",
        "mlp_and_tanh = MLP(input_dim=2, hidden_dim=2, output_dim=1, activation_fn=tanh, activation_grad=tanh_grad, use_bias=True)\n",
        "mlp_and_tanh.train(AND_inputs, AND_labels_single_output, num_epochs=10)\n",
        "\n",
        "# Tanh activation function without bias\n",
        "print(\"\\nTraining AND gate (Single Output) with Tanh activation function without bias:\")\n",
        "mlp_and_tanh_no_bias = MLP(input_dim=2, hidden_dim=2, output_dim=1, activation_fn=tanh, activation_grad=tanh_grad, use_bias=False)\n",
        "mlp_and_tanh_no_bias.train(AND_inputs, AND_labels_single_output, num_epochs=10)\n",
        "\n",
        "# ReLU activation function with bias\n",
        "print(\"\\nTraining AND gate (Single Output) with ReLU activation function and bias:\")\n",
        "mlp_and_relu = MLP(input_dim=2, hidden_dim=2, output_dim=1, activation_fn=relu, activation_grad=relu_grad, use_bias=True)\n",
        "mlp_and_relu.train(AND_inputs, AND_labels_single_output, num_epochs=10)\n",
        "\n",
        "# ReLU activation function without bias\n",
        "print(\"\\nTraining AND gate (Single Output) with ReLU activation function without bias:\")\n",
        "mlp_and_relu_no_bias = MLP(input_dim=2, hidden_dim=2, output_dim=1, activation_fn=relu, activation_grad=relu_grad, use_bias=False)\n",
        "mlp_and_relu_no_bias.train(AND_inputs, AND_labels_single_output, num_epochs=10)\n",
        "\n",
        "# Training for XOR gate (Single Output)\n",
        "\n",
        "# Sigmoid activation function with bias\n",
        "print(\"\\nTraining XOR gate (Single Output) with Sigmoid activation function and bias:\")\n",
        "mlp_xor_sigmoid = MLP(input_dim=2, hidden_dim=2, output_dim=1, activation_fn=sigmoid, activation_grad=sigmoid_grad, use_bias=True)\n",
        "mlp_xor_sigmoid.train(XOR_inputs, XOR_labels_single_output, num_epochs=10)\n",
        "\n",
        "# Sigmoid activation function without bias\n",
        "print(\"\\nTraining XOR gate (Single Output) with Sigmoid activation function without bias:\")\n",
        "mlp_xor_sigmoid_no_bias = MLP(input_dim=2, hidden_dim=2, output_dim=1, activation_fn=sigmoid, activation_grad=sigmoid_grad, use_bias=False)\n",
        "mlp_xor_sigmoid_no_bias.train(XOR_inputs, XOR_labels_single_output, num_epochs=10)\n",
        "\n",
        "# Tanh activation function with bias\n",
        "print(\"\\nTraining XOR gate (Single Output) with Tanh activation function and bias:\")\n",
        "mlp_xor_tanh = MLP(input_dim=2, hidden_dim=2, output_dim=1, activation_fn=tanh, activation_grad=tanh_grad, use_bias=True)\n",
        "mlp_xor_tanh.train(XOR_inputs, XOR_labels_single_output, num_epochs=10)\n",
        "\n",
        "# Tanh activation function without bias\n",
        "print(\"\\nTraining XOR gate (Single Output) with Tanh activation function without bias:\")\n",
        "mlp_xor_tanh_no_bias = MLP(input_dim=2, hidden_dim=2, output_dim=1, activation_fn=tanh, activation_grad=tanh_grad, use_bias=False)\n",
        "mlp_xor_tanh_no_bias.train(XOR_inputs, XOR_labels_single_output, num_epochs=10)\n",
        "\n",
        "# ReLU activation function with bias\n",
        "print(\"\\nTraining XOR gate (Single Output) with ReLU activation function and bias:\")\n",
        "mlp_xor_relu = MLP(input_dim=2, hidden_dim=2, output_dim=1, activation_fn=relu, activation_grad=relu_grad, use_bias=True)\n",
        "mlp_xor_relu.train(XOR_inputs, XOR_labels_single_output, num_epochs=10)\n",
        "\n",
        "# ReLU activation function without bias\n",
        "print(\"\\nTraining XOR gate (Single Output) with ReLU activation function without bias:\")\n",
        "mlp_xor_relu_no_bias = MLP(input_dim=2, hidden_dim=2, output_dim=1, activation_fn=relu, activation_grad=relu_grad, use_bias=False)\n",
        "mlp_xor_relu_no_bias.train(XOR_inputs, XOR_labels_single_output, num_epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ym6qHpWcnJ3J",
        "outputId": "517ee11a-39fc-4c5a-8aa8-c53989259895"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training AND gate (Single Output) with Sigmoid activation function and bias:\n",
            "Epoch 1:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.52648317  0.70757532]\n",
            " [-0.42910053 -0.86570893]]\n",
            "Weights (Hidden to Output):\n",
            "[[ 0.23684218]\n",
            " [-0.09211747]]\n",
            "Hidden Bias:\n",
            "[-0.51254848  0.39968476]\n",
            "Output Bias:\n",
            "[-0.59600022]\n",
            "Epoch Loss: 0.813510381772742\n",
            "\n",
            "Epoch 2:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.52631996  0.70733575]\n",
            " [-0.42897558 -0.86590568]]\n",
            "Weights (Hidden to Output):\n",
            "[[ 0.23207765]\n",
            " [-0.09798143]]\n",
            "Hidden Bias:\n",
            "[-0.51324182  0.39982168]\n",
            "Output Bias:\n",
            "[-0.60577864]\n",
            "Epoch Loss: 0.8102246777736442\n",
            "\n",
            "Epoch 3:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.5261549   0.70708154]\n",
            " [-0.42884835 -0.86611439]]\n",
            "Weights (Hidden to Output):\n",
            "[[ 0.22741793]\n",
            " [-0.10364895]]\n",
            "Hidden Bias:\n",
            "[-0.51390494  0.39996199]\n",
            "Output Bias:\n",
            "[-0.61522004]\n",
            "Epoch Loss: 0.8071467761750346\n",
            "\n",
            "Epoch 4:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.52598837  0.70681299]\n",
            " [-0.4287192  -0.86633488]]\n",
            "Weights (Hidden to Output):\n",
            "[[ 0.22285886]\n",
            " [-0.10912819]]\n",
            "Hidden Bias:\n",
            "[-0.51453943  0.4001048 ]\n",
            "Output Bias:\n",
            "[-0.62433829]\n",
            "Epoch Loss: 0.804261612936392\n",
            "\n",
            "Epoch 5:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.52582072  0.70653041]\n",
            " [-0.42858847 -0.86656697]]\n",
            "Weights (Hidden to Output):\n",
            "[[ 0.21839646]\n",
            " [-0.11442694]]\n",
            "Hidden Bias:\n",
            "[-0.51514679  0.40024935]\n",
            "Output Bias:\n",
            "[-0.63314658]\n",
            "Epoch Loss: 0.8015553096115338\n",
            "\n",
            "Epoch 6:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.52565226  0.70623409]\n",
            " [-0.42845646 -0.86681047]]\n",
            "Weights (Hidden to Output):\n",
            "[[ 0.21402693]\n",
            " [-0.11955261]]\n",
            "Hidden Bias:\n",
            "[-0.51572844  0.40039492]\n",
            "Output Bias:\n",
            "[-0.64165748]\n",
            "Epoch Loss: 0.7990150769975131\n",
            "\n",
            "Epoch 7:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.52548331  0.70592436]\n",
            " [-0.42832347 -0.86706518]]\n",
            "Weights (Hidden to Output):\n",
            "[[ 0.20974666]\n",
            " [-0.12451228]]\n",
            "Hidden Bias:\n",
            "[-0.51628568  0.40054091]\n",
            "Output Bias:\n",
            "[-0.64988298]\n",
            "Epoch Loss: 0.796629126143779\n",
            "\n",
            "Epoch 8:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.52531412  0.70560151]\n",
            " [-0.42818976 -0.86733088]]\n",
            "Weights (Hidden to Output):\n",
            "[[ 0.20555218]\n",
            " [-0.12931268]]\n",
            "Hidden Bias:\n",
            "[-0.51681977  0.40068673]\n",
            "Output Bias:\n",
            "[-0.6578345]\n",
            "Epoch Loss: 0.7943865863355177\n",
            "\n",
            "Epoch 9:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.52514494  0.70526587]\n",
            " [-0.42805556 -0.86760737]]\n",
            "Weights (Hidden to Output):\n",
            "[[ 0.20144021]\n",
            " [-0.13396025]]\n",
            "Hidden Bias:\n",
            "[-0.51733186  0.40083191]\n",
            "Output Bias:\n",
            "[-0.66552292]\n",
            "Epoch Loss: 0.7922774296378667\n",
            "\n",
            "Epoch 10:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.524976    0.70491773]\n",
            " [-0.4279211  -0.86789443]]\n",
            "Weights (Hidden to Output):\n",
            "[[ 0.19740759]\n",
            " [-0.1384611 ]]\n",
            "Hidden Bias:\n",
            "[-0.51782303  0.40097599]\n",
            "Output Bias:\n",
            "[-0.67295862]\n",
            "Epoch Loss: 0.7902924015761407\n",
            "\n",
            "\n",
            "Training AND gate (Single Output) with Sigmoid activation function without bias:\n",
            "Epoch 1:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.04241586 -0.27754725]\n",
            " [ 0.28084311  0.95976913]]\n",
            "Weights (Hidden to Output):\n",
            "[[-0.49630162]\n",
            " [-0.71985589]]\n",
            "Epoch Loss: 0.8193602300472498\n",
            "\n",
            "Epoch 2:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.04320856 -0.27845779]\n",
            " [ 0.2797976   0.95830906]]\n",
            "Weights (Hidden to Output):\n",
            "[[-0.49990602]\n",
            " [-0.7224251 ]]\n",
            "Epoch Loss: 0.8188620052923478\n",
            "\n",
            "Epoch 3:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.04400937 -0.27937665]\n",
            " [ 0.27874179  0.9568395 ]]\n",
            "Weights (Hidden to Output):\n",
            "[[-0.50347943]\n",
            " [-0.72496155]]\n",
            "Epoch Loss: 0.8183702838601543\n",
            "\n",
            "Epoch 4:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.04481823 -0.28030378]\n",
            " [ 0.27767576  0.95536053]]\n",
            "Weights (Hidden to Output):\n",
            "[[-0.50702238]\n",
            " [-0.72746585]]\n",
            "Epoch Loss: 0.8178848368984076\n",
            "\n",
            "Epoch 5:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.0456351  -0.28123914]\n",
            " [ 0.27659958  0.95387224]]\n",
            "Weights (Hidden to Output):\n",
            "[[-0.51053544]\n",
            " [-0.72993857]]\n",
            "Epoch Loss: 0.8174054429591603\n",
            "\n",
            "Epoch 6:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.04645994 -0.28218267]\n",
            " [ 0.27551331  0.95237471]]\n",
            "Weights (Hidden to Output):\n",
            "[[-0.51401912]\n",
            " [-0.73238032]]\n",
            "Epoch Loss: 0.8169318877309213\n",
            "\n",
            "Epoch 7:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.04729268 -0.28313433]\n",
            " [ 0.27441702  0.95086802]]\n",
            "Weights (Hidden to Output):\n",
            "[[-0.51747395]\n",
            " [-0.73479164]]\n",
            "Epoch Loss: 0.816463963781252\n",
            "\n",
            "Epoch 8:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.0481333  -0.28409408]\n",
            " [ 0.27331078  0.94935224]]\n",
            "Weights (Hidden to Output):\n",
            "[[-0.52090045]\n",
            " [-0.7371731 ]]\n",
            "Epoch Loss: 0.8160014703093855\n",
            "\n",
            "Epoch 9:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.04898173 -0.28506186]\n",
            " [ 0.27219465  0.94782747]]\n",
            "Weights (Hidden to Output):\n",
            "[[-0.52429911]\n",
            " [-0.73952524]]\n",
            "Epoch Loss: 0.8155442129084607\n",
            "\n",
            "Epoch 10:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.04983793 -0.28603763]\n",
            " [ 0.2710687   0.94629377]]\n",
            "Weights (Hidden to Output):\n",
            "[[-0.52767044]\n",
            " [-0.7418486 ]]\n",
            "Epoch Loss: 0.8150920033369822\n",
            "\n",
            "\n",
            "Training AND gate (Single Output) with Tanh activation function and bias:\n",
            "Epoch 1:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.44449265 -0.69907782]\n",
            " [-0.09981618  0.91086742]]\n",
            "Weights (Hidden to Output):\n",
            "[[-0.56967054]\n",
            " [ 0.36543413]]\n",
            "Hidden Bias:\n",
            "[-0.61301493  0.94997568]\n",
            "Output Bias:\n",
            "[-0.57108242]\n",
            "Epoch Loss: 1.3684829561309761\n",
            "\n",
            "Epoch 2:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.46073976 -0.68798614]\n",
            " [-0.11049667  0.9196373 ]]\n",
            "Weights (Hidden to Output):\n",
            "[[-0.63166762]\n",
            " [ 0.42036263]]\n",
            "Hidden Bias:\n",
            "[-0.62453221  0.96048683]\n",
            "Output Bias:\n",
            "[-0.49844157]\n",
            "Epoch Loss: 0.7000795701774645\n",
            "\n",
            "Epoch 3:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.47297766 -0.68132584]\n",
            " [-0.11454157  0.92694688]]\n",
            "Weights (Hidden to Output):\n",
            "[[-0.66060905]\n",
            " [ 0.4408865 ]]\n",
            "Hidden Bias:\n",
            "[-0.62065237  0.96329449]\n",
            "Output Bias:\n",
            "[-0.47456756]\n",
            "Epoch Loss: 0.6310120070612882\n",
            "\n",
            "Epoch 4:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.4835561  -0.676771  ]\n",
            " [-0.11608779  0.93358202]]\n",
            "Weights (Hidden to Output):\n",
            "[[-0.67747067]\n",
            " [ 0.44937593]]\n",
            "Hidden Bias:\n",
            "[-0.61077289  0.96280049]\n",
            "Output Bias:\n",
            "[-0.46813628]\n",
            "Epoch Loss: 0.6284649426426442\n",
            "\n",
            "Epoch 5:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.49347906 -0.67323132]\n",
            " [-0.1165802   0.93988218]]\n",
            "Weights (Hidden to Output):\n",
            "[[-0.68975397]\n",
            " [ 0.45338239]]\n",
            "Hidden Bias:\n",
            "[-0.59832853  0.96088113]\n",
            "Output Bias:\n",
            "[-0.46844151]\n",
            "Epoch Loss: 0.6259625137154003\n",
            "\n",
            "Epoch 6:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.50316371 -0.67024555]\n",
            " [-0.11656823  0.94598894]]\n",
            "Weights (Hidden to Output):\n",
            "[[-0.70030387]\n",
            " [ 0.45570957]]\n",
            "Hidden Bias:\n",
            "[-0.5846446   0.95829597]\n",
            "Output Bias:\n",
            "[-0.47148601]\n",
            "Epoch Loss: 0.6199112751487179\n",
            "\n",
            "Epoch 7:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.51278529 -0.66761976]\n",
            " [-0.11627537  0.95196428]]\n",
            "Weights (Hidden to Output):\n",
            "[[-0.71025798]\n",
            " [ 0.45747607]]\n",
            "Hidden Bias:\n",
            "[-0.57027025  0.95536046]\n",
            "Output Bias:\n",
            "[-0.47567006]\n",
            "Epoch Loss: 0.6117110706475326\n",
            "\n",
            "Epoch 8:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.52241701 -0.66527227]\n",
            " [-0.11579519  0.95783742]]\n",
            "Weights (Hidden to Output):\n",
            "[[-0.72008108]\n",
            " [ 0.45914379]]\n",
            "Hidden Bias:\n",
            "[-0.55544524  0.95220878]\n",
            "Output Bias:\n",
            "[-0.48033022]\n",
            "Epoch Loss: 0.6023696013944552\n",
            "\n",
            "Epoch 9:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.53208803 -0.66316892]\n",
            " [-0.11516715  0.96362385]]\n",
            "Weights (Hidden to Output):\n",
            "[[-0.72996279]\n",
            " [ 0.46090721]]\n",
            "Hidden Bias:\n",
            "[-0.54028153  0.94889964]\n",
            "Output Bias:\n",
            "[-0.4851846]\n",
            "Epoch Loss: 0.5923792693654414\n",
            "\n",
            "Epoch 10:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.54180793 -0.66129595]\n",
            " [-0.11440793  0.96933313]]\n",
            "Weights (Hidden to Output):\n",
            "[[-0.73997803]\n",
            " [ 0.46285025]]\n",
            "Hidden Bias:\n",
            "[-0.52483839  0.94546001]\n",
            "Output Bias:\n",
            "[-0.49010937]\n",
            "Epoch Loss: 0.5819620038051249\n",
            "\n",
            "\n",
            "Training AND gate (Single Output) with Tanh activation function without bias:\n",
            "Epoch 1:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.8911846  -0.91004927]\n",
            " [-0.51017082  0.28274865]]\n",
            "Weights (Hidden to Output):\n",
            "[[-0.41217384]\n",
            " [ 0.80556262]]\n",
            "Epoch Loss: 1.9628716854225776\n",
            "\n",
            "Epoch 2:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.90593854 -0.84369344]\n",
            " [-0.50914552  0.31437751]]\n",
            "Weights (Hidden to Output):\n",
            "[[-0.50953324]\n",
            " [ 0.7171345 ]]\n",
            "Epoch Loss: 1.3867423878489387\n",
            "\n",
            "Epoch 3:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.91863101 -0.79202605]\n",
            " [-0.50489408  0.33852195]]\n",
            "Weights (Hidden to Output):\n",
            "[[-0.58161641]\n",
            " [ 0.65308819]]\n",
            "Epoch Loss: 1.0153627686767135\n",
            "\n",
            "Epoch 4:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.92801237 -0.75298017]\n",
            " [-0.49758723  0.35615274]]\n",
            "Weights (Hidden to Output):\n",
            "[[-0.63219371]\n",
            " [ 0.60750657]]\n",
            "Epoch Loss: 0.8172292949571047\n",
            "\n",
            "Epoch 5:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.93442263 -0.72288709]\n",
            " [-0.48791101  0.36923013]]\n",
            "Weights (Hidden to Output):\n",
            "[[-0.66749392]\n",
            " [ 0.57403823]]\n",
            "Epoch Loss: 0.7147604465639282\n",
            "\n",
            "Epoch 6:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.93855244 -0.69890565]\n",
            " [-0.47650465  0.37928013]]\n",
            "Weights (Hidden to Output):\n",
            "[[-0.69238644]\n",
            " [ 0.54840644]]\n",
            "Epoch Loss: 0.6585917724818667\n",
            "\n",
            "Epoch 7:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.94100772 -0.6791544 ]\n",
            " [-0.4638522   0.38731428]]\n",
            "Weights (Hidden to Output):\n",
            "[[-0.71015393]\n",
            " [ 0.52800105]]\n",
            "Epoch Loss: 0.6248542531464948\n",
            "\n",
            "Epoch 8:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.9422446  -0.66241324]\n",
            " [-0.45030736  0.39399019]]\n",
            "Weights (Hidden to Output):\n",
            "[[-0.72296456]\n",
            " [ 0.51122872]]\n",
            "Epoch Loss: 0.6024590878801268\n",
            "\n",
            "Epoch 9:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.9425943  -0.64787726]\n",
            " [-0.43613184  0.3997434 ]]\n",
            "Weights (Hidden to Output):\n",
            "[[-0.73227232]\n",
            " [ 0.49709015]]\n",
            "Epoch Loss: 0.5861057488442953\n",
            "\n",
            "Epoch 10:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.94229705 -0.63500112]\n",
            " [-0.42152427  0.40487034]]\n",
            "Weights (Hidden to Output):\n",
            "[[-0.73907549]\n",
            " [ 0.48493835]]\n",
            "Epoch Loss: 0.5731502319601613\n",
            "\n",
            "\n",
            "Training AND gate (Single Output) with ReLU activation function and bias:\n",
            "Epoch 1:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.6907705  -0.88705911]\n",
            " [ 0.23615485 -0.88794065]]\n",
            "Weights (Hidden to Output):\n",
            "[[ 0.84665835]\n",
            " [-0.29621795]]\n",
            "Hidden Bias:\n",
            "[-0.43090217  0.44733004]\n",
            "Output Bias:\n",
            "[0.28802558]\n",
            "Epoch Loss: 0.7669166929463382\n",
            "\n",
            "Epoch 2:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.6907705  -0.88705911]\n",
            " [ 0.23615485 -0.88794065]]\n",
            "Weights (Hidden to Output):\n",
            "[[ 0.84665835]\n",
            " [-0.30317476]]\n",
            "Hidden Bias:\n",
            "[-0.43090217  0.45193677]\n",
            "Output Bias:\n",
            "[0.29863336]\n",
            "Epoch Loss: 0.7658665566387238\n",
            "\n",
            "Epoch 3:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.6907705  -0.88705911]\n",
            " [ 0.23615485 -0.88794065]]\n",
            "Weights (Hidden to Output):\n",
            "[[ 0.84665835]\n",
            " [-0.31047885]]\n",
            "Hidden Bias:\n",
            "[-0.43090217  0.45683661]\n",
            "Output Bias:\n",
            "[0.3059218]\n",
            "Epoch Loss: 0.7652868588475346\n",
            "\n",
            "Epoch 4:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.6907705  -0.88705911]\n",
            " [ 0.23615485 -0.88794065]]\n",
            "Weights (Hidden to Output):\n",
            "[[ 0.84665835]\n",
            " [-0.31797479]]\n",
            "Hidden Bias:\n",
            "[-0.43090217  0.46193106]\n",
            "Output Bias:\n",
            "[0.31105529]\n",
            "Epoch Loss: 0.7646153364892294\n",
            "\n",
            "Epoch 5:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.6907705  -0.88705911]\n",
            " [ 0.23615485 -0.88794065]]\n",
            "Weights (Hidden to Output):\n",
            "[[ 0.84665835]\n",
            " [-0.32555845]]\n",
            "Hidden Bias:\n",
            "[-0.43090217  0.46715134]\n",
            "Output Bias:\n",
            "[0.31479111]\n",
            "Epoch Loss: 0.7637251321173262\n",
            "\n",
            "Epoch 6:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.6907705  -0.88705911]\n",
            " [ 0.23615485 -0.88794065]]\n",
            "Weights (Hidden to Output):\n",
            "[[ 0.84665835]\n",
            " [-0.33315928]]\n",
            "Hidden Bias:\n",
            "[-0.43090217  0.47244838]\n",
            "Output Bias:\n",
            "[0.31762145]\n",
            "Epoch Loss: 0.7626352860540293\n",
            "\n",
            "Epoch 7:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.6907705  -0.88705911]\n",
            " [ 0.23615485 -0.88794065]]\n",
            "Weights (Hidden to Output):\n",
            "[[ 0.84665835]\n",
            " [-0.34072889]]\n",
            "Hidden Bias:\n",
            "[-0.43090217  0.47778628]\n",
            "Output Bias:\n",
            "[0.31986593]\n",
            "Epoch Loss: 0.7614015859064575\n",
            "\n",
            "Epoch 8:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.6907705  -0.88705911]\n",
            " [ 0.23615485 -0.88794065]]\n",
            "Weights (Hidden to Output):\n",
            "[[ 0.84665835]\n",
            " [-0.3482335 ]]\n",
            "Hidden Bias:\n",
            "[-0.43090217  0.48313812]\n",
            "Output Bias:\n",
            "[0.32173184]\n",
            "Epoch Loss: 0.7600790868913745\n",
            "\n",
            "Epoch 9:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.6907705  -0.88705911]\n",
            " [ 0.23615485 -0.88794065]]\n",
            "Weights (Hidden to Output):\n",
            "[[ 0.84665835]\n",
            " [-0.35564904]]\n",
            "Hidden Bias:\n",
            "[-0.43090217  0.48848305]\n",
            "Output Bias:\n",
            "[0.32335331]\n",
            "Epoch Loss: 0.7587119161772343\n",
            "\n",
            "Epoch 10:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.6907705  -0.88705911]\n",
            " [ 0.23615485 -0.88794065]]\n",
            "Weights (Hidden to Output):\n",
            "[[ 0.84665835]\n",
            " [-0.36295795]]\n",
            "Hidden Bias:\n",
            "[-0.43090217  0.49380444]\n",
            "Output Bias:\n",
            "[0.32481692]\n",
            "Epoch Loss: 0.7573326343124944\n",
            "\n",
            "\n",
            "Training AND gate (Single Output) with ReLU activation function without bias:\n",
            "Epoch 1:\n",
            "Weights (Input to Hidden):\n",
            "[[ 0.9683749   0.7013587 ]\n",
            " [ 0.48591164 -0.41326032]]\n",
            "Weights (Hidden to Output):\n",
            "[[0.18233496]\n",
            " [0.67559367]]\n",
            "Epoch Loss: 0.9830895806467682\n",
            "\n",
            "Epoch 2:\n",
            "Weights (Input to Hidden):\n",
            "[[ 0.9647155   0.70052984]\n",
            " [ 0.49214164 -0.37043008]]\n",
            "Weights (Hidden to Output):\n",
            "[[0.21338533]\n",
            " [0.64688052]]\n",
            "Epoch Loss: 0.8872611262525837\n",
            "\n",
            "Epoch 3:\n",
            "Weights (Input to Hidden):\n",
            "[[ 0.96006455  0.6953616 ]\n",
            " [ 0.49886782 -0.33329045]]\n",
            "Weights (Hidden to Output):\n",
            "[[0.23416089]\n",
            " [0.61884643]]\n",
            "Epoch Loss: 0.820581125583002\n",
            "\n",
            "Epoch 4:\n",
            "Weights (Input to Hidden):\n",
            "[[ 0.9547955   0.68821599]\n",
            " [ 0.5056945  -0.30023969]]\n",
            "Weights (Hidden to Output):\n",
            "[[0.24901332]\n",
            " [0.59222392]]\n",
            "Epoch Loss: 0.7674559291907439\n",
            "\n",
            "Epoch 5:\n",
            "Weights (Input to Hidden):\n",
            "[[ 0.94920384  0.68030222]\n",
            " [ 0.51247837 -0.27029528]]\n",
            "Weights (Hidden to Output):\n",
            "[[0.26036344]\n",
            " [0.56735293]]\n",
            "Epoch Loss: 0.7228406156306129\n",
            "\n",
            "Epoch 6:\n",
            "Weights (Input to Hidden):\n",
            "[[ 0.94347845  0.67222729]\n",
            " [ 0.51916531 -0.24281881]]\n",
            "Weights (Hidden to Output):\n",
            "[[0.26957178]\n",
            " [0.54433178]]\n",
            "Epoch Loss: 0.6846501819536586\n",
            "\n",
            "Epoch 7:\n",
            "Weights (Input to Hidden):\n",
            "[[ 0.9377292   0.66428549]\n",
            " [ 0.52573305 -0.21737158]]\n",
            "Weights (Hidden to Output):\n",
            "[[0.2774109]\n",
            " [0.5231288]]\n",
            "Epoch Loss: 0.651684160389575\n",
            "\n",
            "Epoch 8:\n",
            "Weights (Input to Hidden):\n",
            "[[ 0.93201588  0.65660969]\n",
            " [ 0.53217069 -0.19363595]]\n",
            "Weights (Hidden to Output):\n",
            "[[0.28432453]\n",
            " [0.50365003]]\n",
            "Epoch Loss: 0.6230675974656315\n",
            "\n",
            "Epoch 9:\n",
            "Weights (Input to Hidden):\n",
            "[[ 0.92636855  0.64925027]\n",
            " [ 0.53847137 -0.1713711 ]]\n",
            "Weights (Hidden to Output):\n",
            "[[0.29057087]\n",
            " [0.48577689]]\n",
            "Epoch Loss: 0.5980984399600557\n",
            "\n",
            "Epoch 10:\n",
            "Weights (Input to Hidden):\n",
            "[[ 0.92080036  0.64221629]\n",
            " [ 0.54462987 -0.15038733]]\n",
            "Weights (Hidden to Output):\n",
            "[[0.2963026 ]\n",
            " [0.46938604]]\n",
            "Epoch Loss: 0.5761986575638647\n",
            "\n",
            "\n",
            "Training XOR gate (Single Output) with Sigmoid activation function and bias:\n",
            "Epoch 1:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.08359443 -0.47002562]\n",
            " [ 0.11604912 -0.86011663]]\n",
            "Weights (Hidden to Output):\n",
            "[[-0.65234512]\n",
            " [ 0.44838163]]\n",
            "Hidden Bias:\n",
            "[0.37250614 0.9919265 ]\n",
            "Output Bias:\n",
            "[0.23767268]\n",
            "Epoch Loss: 1.0131581579597229\n",
            "\n",
            "Epoch 2:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.08345305 -0.47023199]\n",
            " [ 0.1161407  -0.86019359]]\n",
            "Weights (Hidden to Output):\n",
            "[[-0.65383679]\n",
            " [ 0.44693327]]\n",
            "Hidden Bias:\n",
            "[0.37287903 0.99185611]\n",
            "Output Bias:\n",
            "[0.23510931]\n",
            "Epoch Loss: 1.012926331413256\n",
            "\n",
            "Epoch 3:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.08332007 -0.47043186]\n",
            " [ 0.11622432 -0.86026476]]\n",
            "Weights (Hidden to Output):\n",
            "[[-0.65526597]\n",
            " [ 0.44554568]]\n",
            "Hidden Bias:\n",
            "[0.37323624 0.99179676]\n",
            "Output Bias:\n",
            "[0.23265125]\n",
            "Epoch Loss: 1.0127132950105184\n",
            "\n",
            "Epoch 4:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.08319519 -0.47062556]\n",
            " [ 0.11630029 -0.8603304 ]]\n",
            "Weights (Hidden to Output):\n",
            "[[-0.6566352 ]\n",
            " [ 0.44421639]]\n",
            "Hidden Bias:\n",
            "[0.37357833 0.99174793]\n",
            "Output Bias:\n",
            "[0.23029419]\n",
            "Epoch Loss: 1.012517533304292\n",
            "\n",
            "Epoch 5:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.0830781  -0.47081336]\n",
            " [ 0.11636889 -0.86039078]]\n",
            "Weights (Hidden to Output):\n",
            "[[-0.6579469 ]\n",
            " [ 0.44294301]]\n",
            "Hidden Bias:\n",
            "[0.37390587 0.99170912]\n",
            "Output Bias:\n",
            "[0.228034]\n",
            "Epoch Loss: 1.0123376506142276\n",
            "\n",
            "Epoch 6:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.08296849 -0.47099555]\n",
            " [ 0.11643042 -0.86044616]]\n",
            "Weights (Hidden to Output):\n",
            "[[-0.65920343]\n",
            " [ 0.44172323]]\n",
            "Hidden Bias:\n",
            "[0.3742194  0.99167986]\n",
            "Output Bias:\n",
            "[0.22586668]\n",
            "Epoch Loss: 1.0121723619451553\n",
            "\n",
            "Epoch 7:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.08286609 -0.47117239]\n",
            " [ 0.11648514 -0.86049678]]\n",
            "Weights (Hidden to Output):\n",
            "[[-0.66040704]\n",
            " [ 0.44055485]]\n",
            "Hidden Bias:\n",
            "[0.37451943 0.99165971]\n",
            "Output Bias:\n",
            "[0.22378841]\n",
            "Epoch Loss: 1.0120204845342862\n",
            "\n",
            "Epoch 8:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.08277062 -0.47134414]\n",
            " [ 0.11653332 -0.86054285]]\n",
            "Weights (Hidden to Output):\n",
            "[[-0.66155991]\n",
            " [ 0.43943575]]\n",
            "Hidden Bias:\n",
            "[0.37480649 0.99164824]\n",
            "Output Bias:\n",
            "[0.22179552]\n",
            "Epoch Loss: 1.0118809299933211\n",
            "\n",
            "Epoch 9:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.08268182 -0.47151102]\n",
            " [ 0.11657521 -0.86058461]]\n",
            "Weights (Hidden to Output):\n",
            "[[-0.6626641]\n",
            " [ 0.4383639]]\n",
            "Hidden Bias:\n",
            "[0.37508105 0.99164505]\n",
            "Output Bias:\n",
            "[0.21988447]\n",
            "Epoch Loss: 1.0117526970116664\n",
            "\n",
            "Epoch 10:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.08259941 -0.47167328]\n",
            " [ 0.11661106 -0.86062225]]\n",
            "Weights (Hidden to Output):\n",
            "[[-0.66372163]\n",
            " [ 0.43733734]]\n",
            "Hidden Bias:\n",
            "[0.37534361 0.99164975]\n",
            "Output Bias:\n",
            "[0.21805188]\n",
            "Epoch Loss: 1.0116348645875048\n",
            "\n",
            "\n",
            "Training XOR gate (Single Output) with Sigmoid activation function without bias:\n",
            "Epoch 1:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.52542364 -0.63248213]\n",
            " [ 0.18386785  0.40571951]]\n",
            "Weights (Hidden to Output):\n",
            "[[0.19557645]\n",
            " [0.01076655]]\n",
            "Epoch Loss: 1.0049969635767486\n",
            "\n",
            "Epoch 2:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.52550875 -0.63250115]\n",
            " [ 0.18378809  0.4056817 ]]\n",
            "Weights (Hidden to Output):\n",
            "[[0.19450819]\n",
            " [0.00967956]]\n",
            "Epoch Loss: 1.00494930798919\n",
            "\n",
            "Epoch 3:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.52559298 -0.63251961]\n",
            " [ 0.18370923  0.40564431]]\n",
            "Weights (Hidden to Output):\n",
            "[[0.19345169]\n",
            " [0.00860477]]\n",
            "Epoch Loss: 1.004902702808029\n",
            "\n",
            "Epoch 4:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.52567636 -0.63253752]\n",
            " [ 0.18363125  0.40560733]]\n",
            "Weights (Hidden to Output):\n",
            "[[0.19240682]\n",
            " [0.00754206]]\n",
            "Epoch Loss: 1.0048571247952722\n",
            "\n",
            "Epoch 5:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.52575889 -0.63255489]\n",
            " [ 0.18355415  0.40557074]]\n",
            "Weights (Hidden to Output):\n",
            "[[0.19137344]\n",
            " [0.00649129]]\n",
            "Epoch Loss: 1.004812551226599\n",
            "\n",
            "Epoch 6:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.52584059 -0.63257173]\n",
            " [ 0.1834779   0.40553454]]\n",
            "Weights (Hidden to Output):\n",
            "[[0.19035144]\n",
            " [0.00545233]]\n",
            "Epoch Loss: 1.0047689598800844\n",
            "\n",
            "Epoch 7:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.52592148 -0.63258805]\n",
            " [ 0.18340249  0.40549871]]\n",
            "Weights (Hidden to Output):\n",
            "[[0.18934068]\n",
            " [0.00442505]]\n",
            "Epoch Loss: 1.0047263290251665\n",
            "\n",
            "Epoch 8:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.52600156 -0.63260387]\n",
            " [ 0.18332789  0.40546325]]\n",
            "Weights (Hidden to Output):\n",
            "[[0.18834104]\n",
            " [0.00340932]]\n",
            "Epoch Loss: 1.0046846374118492\n",
            "\n",
            "Epoch 9:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.52608086 -0.63261919]\n",
            " [ 0.18325411  0.40542813]]\n",
            "Weights (Hidden to Output):\n",
            "[[0.1873524]\n",
            " [0.002405 ]]\n",
            "Epoch Loss: 1.0046438642601385\n",
            "\n",
            "Epoch 10:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.52615938 -0.63263402]\n",
            " [ 0.18318111  0.40539337]]\n",
            "Weights (Hidden to Output):\n",
            "[[0.18637463]\n",
            " [0.00141198]]\n",
            "Epoch Loss: 1.0046039892497087\n",
            "\n",
            "\n",
            "Training XOR gate (Single Output) with Tanh activation function and bias:\n",
            "Epoch 1:\n",
            "Weights (Input to Hidden):\n",
            "[[0.0024542  0.94617189]\n",
            " [0.64709887 0.17976422]]\n",
            "Weights (Hidden to Output):\n",
            "[[0.97746776]\n",
            " [0.32070774]]\n",
            "Hidden Bias:\n",
            "[0.84879522 0.6426916 ]\n",
            "Output Bias:\n",
            "[-0.65502322]\n",
            "Epoch Loss: 1.6585726069675197\n",
            "\n",
            "Epoch 2:\n",
            "Weights (Input to Hidden):\n",
            "[[0.02435683 0.94741169]\n",
            " [0.65011752 0.18705911]]\n",
            "Weights (Hidden to Output):\n",
            "[[1.01413878]\n",
            " [0.35891187]]\n",
            "Hidden Bias:\n",
            "[0.87030101 0.6486425 ]\n",
            "Output Bias:\n",
            "[-0.60580548]\n",
            "Epoch Loss: 1.222735703000215\n",
            "\n",
            "Epoch 3:\n",
            "Weights (Input to Hidden):\n",
            "[[0.0407749  0.94829952]\n",
            " [0.65161815 0.19325412]]\n",
            "Weights (Hidden to Output):\n",
            "[[1.03043114]\n",
            " [0.37751982]]\n",
            "Hidden Bias:\n",
            "[0.88010898 0.65067914]\n",
            "Output Bias:\n",
            "[-0.58398557]\n",
            "Epoch Loss: 1.1373213046423416\n",
            "\n",
            "Epoch 4:\n",
            "Weights (Input to Hidden):\n",
            "[[0.05460414 0.94901384]\n",
            " [0.65256063 0.19890182]]\n",
            "Weights (Hidden to Output):\n",
            "[[1.03807653]\n",
            " [0.38775218]]\n",
            "Hidden Bias:\n",
            "[0.88490763 0.65088577]\n",
            "Output Bias:\n",
            "[-0.57369687]\n",
            "Epoch Loss: 1.1117407459540145\n",
            "\n",
            "Epoch 5:\n",
            "Weights (Input to Hidden):\n",
            "[[0.06700333 0.94963733]\n",
            " [0.65329742 0.2042734 ]]\n",
            "Weights (Hidden to Output):\n",
            "[[1.0415523 ]\n",
            " [0.39388136]]\n",
            "Hidden Bias:\n",
            "[0.88719378 0.65016805]\n",
            "Output Bias:\n",
            "[-0.56900638]\n",
            "Epoch Loss: 1.100608828354574\n",
            "\n",
            "Epoch 6:\n",
            "Weights (Input to Hidden):\n",
            "[[0.07851672 0.95021166]\n",
            " [0.65398227 0.20950549]]\n",
            "Weights (Hidden to Output):\n",
            "[[1.04288304]\n",
            " [0.39784167]]\n",
            "Hidden Bias:\n",
            "[0.88808374 0.6489592 ]\n",
            "Output Bias:\n",
            "[-0.5672581]\n",
            "Epoch Loss: 1.0939823054852345\n",
            "\n",
            "Epoch 7:\n",
            "Weights (Input to Hidden):\n",
            "[[0.0894281  0.95075931]\n",
            " [0.65468917 0.21467004]]\n",
            "Weights (Hidden to Output):\n",
            "[[1.04308712]\n",
            " [0.40060907]]\n",
            "Hidden Bias:\n",
            "[0.88813758 0.64748363]\n",
            "Output Bias:\n",
            "[-0.56712192]\n",
            "Epoch Loss: 1.0890568492118298\n",
            "\n",
            "Epoch 8:\n",
            "Weights (Input to Hidden):\n",
            "[[0.09989662 0.95129307]\n",
            " [0.65545526 0.21980579]]\n",
            "Weights (Hidden to Output):\n",
            "[[1.04270913]\n",
            " [0.40270873]]\n",
            "Hidden Bias:\n",
            "[0.88765719 0.64586326]\n",
            "Output Bias:\n",
            "[-0.56788642]\n",
            "Epoch Loss: 1.0848946232965067\n",
            "\n",
            "Epoch 9:\n",
            "Weights (Input to Hidden):\n",
            "[[0.11001687 0.95182045]\n",
            " [0.65629893 0.22493356]]\n",
            "Weights (Hidden to Output):\n",
            "[[1.04204984]\n",
            " [0.40443409]]\n",
            "Hidden Bias:\n",
            "[0.88681311 0.64416593]\n",
            "Output Bias:\n",
            "[-0.56915658]\n",
            "Epoch Loss: 1.081136184279126\n",
            "\n",
            "Epoch 10:\n",
            "Weights (Input to Hidden):\n",
            "[[0.11984822 0.95234605]\n",
            " [0.65722862 0.23006421]]\n",
            "Weights (Hidden to Output):\n",
            "[[1.04127753]\n",
            " [0.40595269]]\n",
            "Hidden Bias:\n",
            "[0.88570503 0.64242964]\n",
            "Output Bias:\n",
            "[-0.57070875]\n",
            "Epoch Loss: 1.0776250858579108\n",
            "\n",
            "\n",
            "Training XOR gate (Single Output) with Tanh activation function without bias:\n",
            "Epoch 1:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.43600123 -0.64310854]\n",
            " [ 0.62114108  0.91755754]]\n",
            "Weights (Hidden to Output):\n",
            "[[ 0.52175577]\n",
            " [-0.94522209]]\n",
            "Epoch Loss: 2.774810736279698\n",
            "\n",
            "Epoch 2:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.40027277 -0.68621846]\n",
            " [ 0.66487344  0.86308562]]\n",
            "Weights (Hidden to Output):\n",
            "[[ 0.55808385]\n",
            " [-0.89980123]]\n",
            "Epoch Loss: 2.4726528320322414\n",
            "\n",
            "Epoch 3:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.36874322 -0.71313381]\n",
            " [ 0.70189762  0.81913634]]\n",
            "Weights (Hidden to Output):\n",
            "[[ 0.59563545]\n",
            " [-0.86074039]]\n",
            "Epoch Loss: 2.263764642071873\n",
            "\n",
            "Epoch 4:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.33897661 -0.7297986 ]\n",
            " [ 0.73362466  0.78312017]]\n",
            "Weights (Hidden to Output):\n",
            "[[ 0.63176083]\n",
            " [-0.82679593]]\n",
            "Epoch Loss: 2.1132880965055634\n",
            "\n",
            "Epoch 5:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.30923691 -0.74022679]\n",
            " [ 0.76122964  0.75299655]]\n",
            "Weights (Hidden to Output):\n",
            "[[ 0.66541856]\n",
            " [-0.79745701]]\n",
            "Epoch Loss: 1.9972705939859048\n",
            "\n",
            "Epoch 6:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.27853549 -0.74678949]\n",
            " [ 0.78557556  0.72741943]]\n",
            "Weights (Hidden to Output):\n",
            "[[ 0.6963877 ]\n",
            " [-0.77232164]]\n",
            "Epoch Loss: 1.9030046655576454\n",
            "\n",
            "Epoch 7:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.24642124 -0.75084735]\n",
            " [ 0.80733477  0.705465  ]]\n",
            "Weights (Hidden to Output):\n",
            "[[ 0.72487706]\n",
            " [-0.75089081]]\n",
            "Epoch Loss: 1.823277032553528\n",
            "\n",
            "Epoch 8:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.21279889 -0.75318424]\n",
            " [ 0.82706074  0.68645215]]\n",
            "Weights (Hidden to Output):\n",
            "[[ 0.75130003]\n",
            " [-0.73258433]]\n",
            "Epoch Loss: 1.753377193984665\n",
            "\n",
            "Epoch 9:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.17780549 -0.75425758]\n",
            " [ 0.84521113  0.66985895]]\n",
            "Weights (Hidden to Output):\n",
            "[[ 0.77612716]\n",
            " [-0.71680904]]\n",
            "Epoch Loss: 1.6900315108467507\n",
            "\n",
            "Epoch 10:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.14172808 -0.75433836]\n",
            " [ 0.86215253  0.65528373]]\n",
            "Weights (Hidden to Output):\n",
            "[[ 0.79979178]\n",
            " [-0.70301446]]\n",
            "Epoch Loss: 1.6310247185372455\n",
            "\n",
            "\n",
            "Training XOR gate (Single Output) with ReLU activation function and bias:\n",
            "Epoch 1:\n",
            "Weights (Input to Hidden):\n",
            "[[ 0.10935637  0.14509358]\n",
            " [-0.33391087 -0.52039913]]\n",
            "Weights (Hidden to Output):\n",
            "[[-0.18102201]\n",
            " [ 0.58556644]]\n",
            "Hidden Bias:\n",
            "[0.34653546 0.7073428 ]\n",
            "Output Bias:\n",
            "[0.15123441]\n",
            "Epoch Loss: 1.3691312858183313\n",
            "\n",
            "Epoch 2:\n",
            "Weights (Input to Hidden):\n",
            "[[ 0.10956929  0.14023844]\n",
            " [-0.34170209 -0.50381146]]\n",
            "Weights (Hidden to Output):\n",
            "[[-0.18183979]\n",
            " [ 0.57829225]]\n",
            "Hidden Bias:\n",
            "[0.33964124 0.7179713 ]\n",
            "Output Bias:\n",
            "[0.17705205]\n",
            "Epoch Loss: 1.317373224601418\n",
            "\n",
            "Epoch 3:\n",
            "Weights (Input to Hidden):\n",
            "[[ 0.11051623  0.13338152]\n",
            " [-0.34825516 -0.49103818]]\n",
            "Weights (Hidden to Output):\n",
            "[[-0.18481529]\n",
            " [ 0.56717134]]\n",
            "Hidden Bias:\n",
            "[0.33467778 0.72248588]\n",
            "Output Bias:\n",
            "[0.19262463]\n",
            "Epoch Loss: 1.2973063852946358\n",
            "\n",
            "Epoch 4:\n",
            "Weights (Input to Hidden):\n",
            "[[ 0.11151251  0.12643078]\n",
            " [-0.33897518 -0.48027525]]\n",
            "Weights (Hidden to Output):\n",
            "[[-0.18887244]\n",
            " [ 0.5555287 ]]\n",
            "Hidden Bias:\n",
            "[0.34566414 0.72477046]\n",
            "Output Bias:\n",
            "[0.20458815]\n",
            "Epoch Loss: 1.2829463773132506\n",
            "\n",
            "Epoch 5:\n",
            "Weights (Input to Hidden):\n",
            "[[ 0.11264658  0.11923844]\n",
            " [-0.344768   -0.47102565]]\n",
            "Weights (Hidden to Output):\n",
            "[[-0.19189087]\n",
            " [ 0.54387979]]\n",
            "Hidden Bias:\n",
            "[0.34162039 0.72580076]\n",
            "Output Bias:\n",
            "[0.21452696]\n",
            "Epoch Loss: 1.276598360470758\n",
            "\n",
            "Epoch 6:\n",
            "Weights (Input to Hidden):\n",
            "[[ 0.11377619  0.11218399]\n",
            " [-0.35018904 -0.46311785]]\n",
            "Weights (Hidden to Output):\n",
            "[[-0.19488455]\n",
            " [ 0.53250916]]\n",
            "Hidden Bias:\n",
            "[0.33786621 0.72588494]\n",
            "Output Bias:\n",
            "[0.22292498]\n",
            "Epoch Loss: 1.2676623522353423\n",
            "\n",
            "Epoch 7:\n",
            "Weights (Input to Hidden):\n",
            "[[ 0.11463577  0.10582398]\n",
            " [-0.34020422 -0.45598258]]\n",
            "Weights (Hidden to Output):\n",
            "[[-0.19831285]\n",
            " [ 0.5221746 ]]\n",
            "Hidden Bias:\n",
            "[0.34932012 0.72588646]\n",
            "Output Bias:\n",
            "[0.23136056]\n",
            "Epoch Loss: 1.2578494858281064\n",
            "\n",
            "Epoch 8:\n",
            "Weights (Input to Hidden):\n",
            "[[ 0.11552733  0.09947753]\n",
            " [-0.34542252 -0.44962286]]\n",
            "Weights (Hidden to Output):\n",
            "[[-0.2003989 ]\n",
            " [ 0.51231046]]\n",
            "Hidden Bias:\n",
            "[0.3455125  0.72558737]\n",
            "Output Bias:\n",
            "[0.23936443]\n",
            "Epoch Loss: 1.255527763560853\n",
            "\n",
            "Epoch 9:\n",
            "Weights (Input to Hidden):\n",
            "[[ 0.11637853  0.09331135]\n",
            " [-0.35035654 -0.44413302]]\n",
            "Weights (Hidden to Output):\n",
            "[[-0.20240884]\n",
            " [ 0.50273405]]\n",
            "Hidden Bias:\n",
            "[0.34188782 0.72476274]\n",
            "Output Bias:\n",
            "[0.2464693]\n",
            "Epoch Loss: 1.2494456859858307\n",
            "\n",
            "Epoch 10:\n",
            "Weights (Input to Hidden):\n",
            "[[ 0.11716142  0.08737906]\n",
            " [-0.3550548  -0.43935804]]\n",
            "Weights (Hidden to Output):\n",
            "[[-0.20426294]\n",
            " [ 0.4935714 ]]\n",
            "Hidden Bias:\n",
            "[0.33837221 0.72361788]\n",
            "Output Bias:\n",
            "[0.25304295]\n",
            "Epoch Loss: 1.2440373712312802\n",
            "\n",
            "\n",
            "Training XOR gate (Single Output) with ReLU activation function without bias:\n",
            "Epoch 1:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.46461031  0.71217945]\n",
            " [-0.77616111 -0.58885703]]\n",
            "Weights (Hidden to Output):\n",
            "[[ 0.88823364]\n",
            " [-0.60612579]]\n",
            "Epoch Loss: 2.0\n",
            "\n",
            "Epoch 2:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.46461031  0.71217945]\n",
            " [-0.77616111 -0.58885703]]\n",
            "Weights (Hidden to Output):\n",
            "[[ 0.88823364]\n",
            " [-0.60612579]]\n",
            "Epoch Loss: 2.0\n",
            "\n",
            "Epoch 3:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.46461031  0.71217945]\n",
            " [-0.77616111 -0.58885703]]\n",
            "Weights (Hidden to Output):\n",
            "[[ 0.88823364]\n",
            " [-0.60612579]]\n",
            "Epoch Loss: 2.0\n",
            "\n",
            "Epoch 4:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.46461031  0.71217945]\n",
            " [-0.77616111 -0.58885703]]\n",
            "Weights (Hidden to Output):\n",
            "[[ 0.88823364]\n",
            " [-0.60612579]]\n",
            "Epoch Loss: 2.0\n",
            "\n",
            "Epoch 5:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.46461031  0.71217945]\n",
            " [-0.77616111 -0.58885703]]\n",
            "Weights (Hidden to Output):\n",
            "[[ 0.88823364]\n",
            " [-0.60612579]]\n",
            "Epoch Loss: 2.0\n",
            "\n",
            "Epoch 6:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.46461031  0.71217945]\n",
            " [-0.77616111 -0.58885703]]\n",
            "Weights (Hidden to Output):\n",
            "[[ 0.88823364]\n",
            " [-0.60612579]]\n",
            "Epoch Loss: 2.0\n",
            "\n",
            "Epoch 7:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.46461031  0.71217945]\n",
            " [-0.77616111 -0.58885703]]\n",
            "Weights (Hidden to Output):\n",
            "[[ 0.88823364]\n",
            " [-0.60612579]]\n",
            "Epoch Loss: 2.0\n",
            "\n",
            "Epoch 8:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.46461031  0.71217945]\n",
            " [-0.77616111 -0.58885703]]\n",
            "Weights (Hidden to Output):\n",
            "[[ 0.88823364]\n",
            " [-0.60612579]]\n",
            "Epoch Loss: 2.0\n",
            "\n",
            "Epoch 9:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.46461031  0.71217945]\n",
            " [-0.77616111 -0.58885703]]\n",
            "Weights (Hidden to Output):\n",
            "[[ 0.88823364]\n",
            " [-0.60612579]]\n",
            "Epoch Loss: 2.0\n",
            "\n",
            "Epoch 10:\n",
            "Weights (Input to Hidden):\n",
            "[[-0.46461031  0.71217945]\n",
            " [-0.77616111 -0.58885703]]\n",
            "Weights (Hidden to Output):\n",
            "[[ 0.88823364]\n",
            " [-0.60612579]]\n",
            "Epoch Loss: 2.0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define activation functions and their derivatives\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "def tanh_derivative(x):\n",
        "    return 1 - x ** 2\n",
        "\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def relu_derivative(x):\n",
        "    return np.where(x > 0, 1, 0)\n",
        "\n",
        "# Multi-Layer Perceptron class\n",
        "class MultiLayerPerceptron:\n",
        "    def __init__(self, input_size, hidden_size, output_size, activation_function, activation_derivative, bias=True, learning_rate=0.1):\n",
        "        # Initialize weights and biases\n",
        "        self.weights_input_hidden = np.random.rand(input_size, hidden_size)\n",
        "        self.weights_hidden_output = np.random.rand(hidden_size, output_size)\n",
        "        self.bias_hidden = np.random.rand(hidden_size) if bias else np.zeros(hidden_size)\n",
        "        self.bias_output = np.random.rand(output_size) if bias else np.zeros(output_size)\n",
        "        self.activation_function = activation_function\n",
        "        self.activation_derivative = activation_derivative\n",
        "        self.learning_rate = learning_rate\n",
        "        self.bias_included = bias\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        self.hidden_input = np.dot(inputs, self.weights_input_hidden) + self.bias_hidden\n",
        "        self.hidden_output = self.activation_function(self.hidden_input)\n",
        "        self.final_input = np.dot(self.hidden_output, self.weights_hidden_output) + self.bias_output\n",
        "        self.final_output = self.activation_function(self.final_input)\n",
        "        return self.final_output\n",
        "\n",
        "    def compute_error(self, labels):\n",
        "        return np.mean(np.square(labels - self.final_output))\n",
        "\n",
        "    def backpropagate(self, inputs, labels):\n",
        "        error_output_layer = labels - self.final_output\n",
        "        delta_output_layer = error_output_layer * self.activation_derivative(self.final_output)\n",
        "\n",
        "        error_hidden_layer = np.dot(delta_output_layer, self.weights_hidden_output.T)\n",
        "        delta_hidden_layer = error_hidden_layer * self.activation_derivative(self.hidden_output)\n",
        "\n",
        "        # Update weights\n",
        "        self.weights_hidden_output += self.learning_rate * np.dot(self.hidden_output.T, delta_output_layer)\n",
        "        self.weights_input_hidden += self.learning_rate * np.dot(inputs.T, delta_hidden_layer)\n",
        "\n",
        "        # Update biases if included\n",
        "        if self.bias_included:\n",
        "            self.bias_output += self.learning_rate * np.sum(delta_output_layer, axis=0)\n",
        "            self.bias_hidden += self.learning_rate * np.sum(delta_hidden_layer, axis=0)\n",
        "\n",
        "    def train(self, inputs, labels, epochs=10):\n",
        "        for epoch in range(epochs):\n",
        "            total_error = 0\n",
        "            for input_vector, label in zip(inputs, labels):\n",
        "                input_vector = input_vector.reshape(1, -1)\n",
        "                label = label.reshape(1, -1)\n",
        "                self.forward(input_vector)\n",
        "                self.backpropagate(input_vector, label)\n",
        "                total_error += self.compute_error(label)\n",
        "\n",
        "            # Print updated weights, biases, and error at each epoch\n",
        "            print(f'Epoch {epoch + 1}:')\n",
        "            print(f'Updated Weights Input-Hidden:\\n{self.weights_input_hidden}')\n",
        "            print(f'Updated Weights Hidden-Output:\\n{self.weights_hidden_output}')\n",
        "            if self.bias_included:\n",
        "                print(f'Updated Bias Hidden:\\n{self.bias_hidden}')\n",
        "                print(f'Updated Bias Output:\\n{self.bias_output}')\n",
        "            print(f'Total Error: {total_error}\\n')\n",
        "\n",
        "# Define datasets\n",
        "AND_inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "AND_labels_multiple_output = np.array([[1, 0], [0, 1], [0, 1], [1, 0]])\n",
        "\n",
        "XOR_inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "XOR_labels_multiple_output = np.array([[1, 0], [0, 1], [0, 1], [1, 0]])\n",
        "\n",
        "# Training for AND gate (Multiple Outputs)\n",
        "\n",
        "# Sigmoid activation function with bias\n",
        "print(\"Training AND gate (Multiple Outputs) with Sigmoid activation function and bias:\")\n",
        "mlp_and_sigmoid = MultiLayerPerceptron(input_size=2, hidden_size=2, output_size=2, activation_function=sigmoid, activation_derivative=sigmoid_derivative, bias=True)\n",
        "mlp_and_sigmoid.train(AND_inputs, AND_labels_multiple_output, epochs=10)\n",
        "\n",
        "# Sigmoid activation function without bias\n",
        "print(\"\\nTraining AND gate (Multiple Outputs) with Sigmoid activation function without bias:\")\n",
        "mlp_and_sigmoid_no_bias = MultiLayerPerceptron(input_size=2, hidden_size=2, output_size=2, activation_function=sigmoid, activation_derivative=sigmoid_derivative, bias=False)\n",
        "mlp_and_sigmoid_no_bias.train(AND_inputs, AND_labels_multiple_output, epochs=10)\n",
        "\n",
        "# Tanh activation function with bias\n",
        "print(\"\\nTraining AND gate (Multiple Outputs) with Tanh activation function and bias:\")\n",
        "mlp_and_tanh = MultiLayerPerceptron(input_size=2, hidden_size=2, output_size=2, activation_function=tanh, activation_derivative=tanh_derivative, bias=True)\n",
        "mlp_and_tanh.train(AND_inputs, AND_labels_multiple_output, epochs=10)\n",
        "\n",
        "# Tanh activation function without bias\n",
        "print(\"\\nTraining AND gate (Multiple Outputs) with Tanh activation function without bias:\")\n",
        "mlp_and_tanh_no_bias = MultiLayerPerceptron(input_size=2, hidden_size=2, output_size=2, activation_function=tanh, activation_derivative=tanh_derivative, bias=False)\n",
        "mlp_and_tanh_no_bias.train(AND_inputs, AND_labels_multiple_output, epochs=10)\n",
        "\n",
        "# ReLU activation function with bias\n",
        "print(\"\\nTraining AND gate (Multiple Outputs) with ReLU activation function and bias:\")\n",
        "mlp_and_relu = MultiLayerPerceptron(input_size=2, hidden_size=2, output_size=2, activation_function=relu, activation_derivative=relu_derivative, bias=True)\n",
        "mlp_and_relu.train(AND_inputs, AND_labels_multiple_output, epochs=10)\n",
        "\n",
        "# ReLU activation function without bias\n",
        "print(\"\\nTraining AND gate (Multiple Outputs) with ReLU activation function without bias:\")\n",
        "mlp_and_relu_no_bias = MultiLayerPerceptron(input_size=2, hidden_size=2, output_size=2, activation_function=relu, activation_derivative=relu_derivative, bias=False)\n",
        "mlp_and_relu_no_bias.train(AND_inputs, AND_labels_multiple_output, epochs=10)\n",
        "\n",
        "# Training for XOR gate (Multiple Outputs)\n",
        "\n",
        "# Sigmoid activation function with bias\n",
        "print(\"\\nTraining XOR gate (Multiple Outputs) with Sigmoid activation function and bias:\")\n",
        "mlp_xor_sigmoid = MultiLayerPerceptron(input_size=2, hidden_size=2, output_size=2, activation_function=sigmoid, activation_derivative=sigmoid_derivative, bias=True)\n",
        "mlp_xor_sigmoid.train(XOR_inputs, XOR_labels_multiple_output, epochs=10)\n",
        "\n",
        "# Sigmoid activation function without bias\n",
        "print(\"\\nTraining XOR gate (Multiple Outputs) with Sigmoid activation function without bias:\")\n",
        "mlp_xor_sigmoid_no_bias = MultiLayerPerceptron(input_size=2, hidden_size=2, output_size=2, activation_function=sigmoid, activation_derivative=sigmoid_derivative, bias=False)\n",
        "mlp_xor_sigmoid_no_bias.train(XOR_inputs, XOR_labels_multiple_output, epochs=10)\n",
        "\n",
        "# Tanh activation function with bias\n",
        "print(\"\\nTraining XOR gate (Multiple Outputs) with Tanh activation function and bias:\")\n",
        "mlp_xor_tanh = MultiLayerPerceptron(input_size=2, hidden_size=2, output_size=2, activation_function=tanh, activation_derivative=tanh_derivative, bias=True)\n",
        "mlp_xor_tanh.train(XOR_inputs, XOR_labels_multiple_output, epochs=10)\n",
        "\n",
        "# Tanh activation function without bias\n",
        "print(\"\\nTraining XOR gate (Multiple Outputs) with Tanh activation function without bias:\")\n",
        "mlp_xor_tanh_no_bias = MultiLayerPerceptron(input_size=2, hidden_size=2, output_size=2, activation_function=tanh, activation_derivative=tanh_derivative, bias=False)\n",
        "mlp_xor_tanh_no_bias.train(XOR_inputs, XOR_labels_multiple_output, epochs=10)\n",
        "\n",
        "# ReLU activation function with bias\n",
        "print(\"\\nTraining XOR gate (Multiple Outputs) with ReLU activation function and bias:\")\n",
        "mlp_xor_relu = MultiLayerPerceptron(input_size=2, hidden_size=2, output_size=2, activation_function=relu, activation_derivative=relu_derivative, bias=True)\n",
        "mlp_xor_relu.train(XOR_inputs, XOR_labels_multiple_output, epochs=10)\n",
        "\n",
        "# ReLU activation function without bias\n",
        "print(\"\\nTraining XOR gate (Multiple Outputs) with ReLU activation function without bias:\")\n",
        "mlp_xor_relu_no_bias = MultiLayerPerceptron(input_size=2, hidden_size=2, output_size=2, activation_function=relu, activation_derivative=relu_derivative, bias=False)\n",
        "mlp_xor_relu_no_bias.train(XOR_inputs, XOR_labels_multiple_output, epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zx2VtR4tn0n1",
        "outputId": "b45180f9-31ed-4460-f779-7890d63c1998"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training AND gate (Multiple Outputs) with Sigmoid activation function and bias:\n",
            "Epoch 1:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.28364981 0.32811935]\n",
            " [0.39518471 0.12871518]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.39816688 0.33882661]\n",
            " [0.06030412 0.19406389]]\n",
            "Updated Bias Hidden:\n",
            "[0.85814693 0.82584782]\n",
            "Updated Bias Output:\n",
            "[0.4501092  0.48834255]\n",
            "Total Error: 1.176535265439763\n",
            "\n",
            "Epoch 2:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.28262065 0.32775414]\n",
            " [0.39416932 0.12832324]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.3859104  0.32597354]\n",
            " [0.04851926 0.18155754]]\n",
            "Updated Bias Hidden:\n",
            "[0.85597225 0.82500288]\n",
            "Updated Bias Output:\n",
            "[0.43424252 0.47138836]\n",
            "Total Error: 1.1647711904053617\n",
            "\n",
            "Epoch 3:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.28164605 0.32742988]\n",
            " [0.3932052  0.12797393]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.37399366 0.31341988]\n",
            " [0.03705891 0.16933538]]\n",
            "Updated Bias Hidden:\n",
            "[0.8539167  0.82424819]\n",
            "Updated Bias Output:\n",
            "[0.41880878 0.45481407]\n",
            "Total Error: 1.1535707615339055\n",
            "\n",
            "Epoch 4:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.28072486 0.32714448]\n",
            " [0.39229131 0.12766505]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.36242706 0.3011816 ]\n",
            " [0.02593338 0.15741321]]\n",
            "Updated Bias Hidden:\n",
            "[0.8519777  0.82357915]\n",
            "Updated Bias Output:\n",
            "[0.40382271 0.43864172]\n",
            "Total Error: 1.1429455655862355\n",
            "\n",
            "Epoch 5:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.27985566 0.32689568]\n",
            " [0.39142637 0.12739426]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.35121869 0.2892725 ]\n",
            " [0.0151508  0.14580472]]\n",
            "Updated Bias Hidden:\n",
            "[0.85015208 0.82299088]\n",
            "Updated Bias Output:\n",
            "[0.389296   0.42289048]\n",
            "Total Error: 1.1329014068971877\n",
            "\n",
            "Epoch 6:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.27903681 0.32668115]\n",
            " [0.39060886 0.12715914]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.34037437 0.27770413]\n",
            " [0.00471714 0.13452147]]\n",
            "Updated Bias Hidden:\n",
            "[0.84843624 0.82247831]\n",
            "Updated Bias Output:\n",
            "[0.37523738 0.40757655]\n",
            "Total Error: 1.1234386220181143\n",
            "\n",
            "Epoch 7:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.27826648 0.32649849]\n",
            " [0.3898371  0.12695719]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[ 0.32989782  0.26648579]\n",
            " [-0.00536372  0.12357285]]\n",
            "Updated Bias Hidden:\n",
            "[0.84682615 0.82203621]\n",
            "Updated Bias Output:\n",
            "[0.36165271 0.39271317]\n",
            "Total Error: 1.1145525008987252\n",
            "\n",
            "Epoch 8:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.27754269 0.32634529]\n",
            " [0.38910927 0.12678588]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[ 0.31979071  0.25562458]\n",
            " [-0.01508983  0.11296611]]\n",
            "Updated Bias Hidden:\n",
            "[0.84531748 0.82165934]\n",
            "Updated Bias Output:\n",
            "[0.34854517 0.37831061]\n",
            "Total Error: 1.1062337892741099\n",
            "\n",
            "Epoch 9:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.27686335 0.32621913]\n",
            " [0.3884234  0.12664271]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[ 0.31005283  0.24512544]\n",
            " [-0.02446107  0.10270642]]\n",
            "Updated Bias Hidden:\n",
            "[0.84390567 0.82134245]\n",
            "Updated Bias Output:\n",
            "[0.33591539 0.36437628]\n",
            "Total Error: 1.0984692462637269\n",
            "\n",
            "Epoch 10:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.27622628 0.32611765]\n",
            " [0.38777749 0.12652521]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[ 0.30068225  0.23499124]\n",
            " [-0.03347901  0.09279695]]\n",
            "Updated Bias Hidden:\n",
            "[0.84258601 0.82108039]\n",
            "Updated Bias Output:\n",
            "[0.3237617  0.35091485]\n",
            "Total Error: 1.0912422321281787\n",
            "\n",
            "\n",
            "Training AND gate (Multiple Outputs) with Sigmoid activation function without bias:\n",
            "Epoch 1:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.22448101 0.72469102]\n",
            " [0.30704495 0.42653998]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.00782275 0.09931483]\n",
            " [0.14905541 0.85986993]]\n",
            "Total Error: 1.0476678095589276\n",
            "\n",
            "Epoch 2:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.22429657 0.72371824]\n",
            " [0.306836   0.42572216]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.00642693 0.09187301]\n",
            " [0.1472767  0.85166659]]\n",
            "Total Error: 1.0463617071913638\n",
            "\n",
            "Epoch 3:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.22412539 0.72276722]\n",
            " [0.30663938 0.42492493]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.00505845 0.08452145]\n",
            " [0.14553031 0.84356481]]\n",
            "Total Error: 1.0450884057388299\n",
            "\n",
            "Epoch 4:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.22396707 0.72183766]\n",
            " [0.30645469 0.42414798]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.00371679 0.07726014]\n",
            " [0.14381562 0.83556461]]\n",
            "Total Error: 1.0438474315320938\n",
            "\n",
            "Epoch 5:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.22382119 0.72092927]\n",
            " [0.30628154 0.42339099]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.00240141 0.07008901]\n",
            " [0.14213198 0.82766592]]\n",
            "Total Error: 1.0426382984135694\n",
            "\n",
            "Epoch 6:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.22368736 0.72004175]\n",
            " [0.30611955 0.42265364]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.00111182 0.06300797]\n",
            " [0.1404788  0.81986861]]\n",
            "Total Error: 1.0414605089498417\n",
            "\n",
            "Epoch 7:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.22356518 0.71917478]\n",
            " [0.30596834 0.42193562]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[-1.52495289e-04  5.60168489e-02]\n",
            " [ 1.38855467e-01  8.12172514e-01]]\n",
            "Total Error: 1.0403135556208336\n",
            "\n",
            "Epoch 8:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.22345425 0.71832805]\n",
            " [0.30582753 0.42123658]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[-0.00139201  0.04911546]\n",
            " [ 0.13726139  0.80457741]]\n",
            "Total Error: 1.0391969219822252\n",
            "\n",
            "Epoch 9:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.22335417 0.71750125]\n",
            " [0.30569676 0.42055622]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[-0.00260722  0.04230356]\n",
            " [ 0.13569601  0.79708303]]\n",
            "Total Error: 1.0381100837981105\n",
            "\n",
            "Epoch 10:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.22326457 0.71669405]\n",
            " [0.30557564 0.41989419]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[-0.00379857  0.03558088]\n",
            " [ 0.13415874  0.78968905]]\n",
            "Total Error: 1.037052510141236\n",
            "\n",
            "\n",
            "Training AND gate (Multiple Outputs) with Tanh activation function and bias:\n",
            "Epoch 1:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.57621943 0.67679786]\n",
            " [0.54811992 0.76267475]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.72562013 0.82501605]\n",
            " [0.83009334 0.57667108]]\n",
            "Updated Bias Hidden:\n",
            "[0.6197525  0.91531808]\n",
            "Updated Bias Output:\n",
            "[0.54309574 0.27974109]\n",
            "Total Error: 1.7206016870626353\n",
            "\n",
            "Epoch 2:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.57347769 0.67563089]\n",
            " [0.54539655 0.76167221]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.7132209  0.80001492]\n",
            " [0.81628823 0.54681016]]\n",
            "Updated Bias Hidden:\n",
            "[0.60088245 0.9065858 ]\n",
            "Updated Bias Output:\n",
            "[0.52847922 0.24246524]\n",
            "Total Error: 1.6859458801127398\n",
            "\n",
            "Epoch 3:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.5705088  0.67440271]\n",
            " [0.54246936 0.76061879]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.69999209 0.77310333]\n",
            " [0.80147038 0.51435151]]\n",
            "Updated Bias Hidden:\n",
            "[0.58051829 0.89742532]\n",
            "Updated Bias Output:\n",
            "[0.51280185 0.20177679]\n",
            "Total Error: 1.6451202068927326\n",
            "\n",
            "Epoch 4:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.56734442 0.67312536]\n",
            " [0.53938789 0.75952748]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.68584163 0.74470866]\n",
            " [0.78551384 0.47971668]]\n",
            "Updated Bias Hidden:\n",
            "[0.55885831 0.88797953]\n",
            "Updated Bias Output:\n",
            "[0.49593806 0.15811098]\n",
            "Total Error: 1.5980318707808512\n",
            "\n",
            "Epoch 5:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.56406554 0.67181962]\n",
            " [0.53626567 0.75842106]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.67066779 0.71579619]\n",
            " [0.76827967 0.4439867 ]]\n",
            "Updated Bias Hidden:\n",
            "[0.53639106 0.87849558]\n",
            "Updated Bias Output:\n",
            "[0.47775269 0.11268332]\n",
            "Total Error: 1.5459132909160327\n",
            "\n",
            "Epoch 6:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.56080975 0.67051148]\n",
            " [0.53329452 0.75732982]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.65435934 0.68797919]\n",
            " [0.74961983 0.4090809 ]]\n",
            "Updated Bias Hidden:\n",
            "[0.51395688 0.86931973]\n",
            "Updated Bias Output:\n",
            "[0.45810668 0.06771876]\n",
            "Total Error: 1.4920188320426564\n",
            "\n",
            "Epoch 7:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.55774251 0.66922127]\n",
            " [0.5307146  0.7562808 ]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.63679571 0.6632857 ]\n",
            " [0.72938327 0.37753067]]\n",
            "Updated Bias Hidden:\n",
            "[0.49264037 0.86082809]\n",
            "Updated Bias Output:\n",
            "[0.43686502 0.02621316]\n",
            "Total Error: 1.4413373386037007\n",
            "\n",
            "Epoch 8:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.55498723 0.66795018]\n",
            " [0.52872238 0.75528219]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.61784793 0.64346597]\n",
            " [0.70742291 0.3516531 ]]\n",
            "Updated Bias Hidden:\n",
            "[0.47342922 0.85330089]\n",
            "Updated Bias Output:\n",
            "[ 0.41390493 -0.00902173]\n",
            "Total Error: 1.3984240293797254\n",
            "\n",
            "Epoch 9:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.55256275 0.66667626]\n",
            " [0.52737179 0.75431611]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.5973836  0.62925533]\n",
            " [0.68360338 0.33258192]]\n",
            "Updated Bias Hidden:\n",
            "[0.45683119 0.84682775]\n",
            "Updated Bias Output:\n",
            "[ 0.38912486 -0.03651955]\n",
            "Total Error: 1.364601399297761\n",
            "\n",
            "Epoch 10:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.55038509 0.66536404]\n",
            " [0.52655893 0.75334773]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.57528087 0.62023547]\n",
            " [0.65781496 0.31998826]]\n",
            "Updated Bias Hidden:\n",
            "[0.4427761  0.84132846]\n",
            "Updated Bias Output:\n",
            "[ 0.36246104 -0.05653823]\n",
            "Total Error: 1.337519630852762\n",
            "\n",
            "\n",
            "Training AND gate (Multiple Outputs) with Tanh activation function without bias:\n",
            "Epoch 1:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.21973064 0.59701497]\n",
            " [0.14018293 0.99083894]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.67825958 0.8617208 ]\n",
            " [0.30831773 0.11112125]]\n",
            "Total Error: 1.5425168323783671\n",
            "\n",
            "Epoch 2:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.25280738 0.60016723]\n",
            " [0.18010017 0.99118079]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.68496566 0.87123776]\n",
            " [0.3087032  0.17055884]]\n",
            "Total Error: 1.437334951085992\n",
            "\n",
            "Epoch 3:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.27700745 0.60396333]\n",
            " [0.20848579 0.99207643]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.68950153 0.88024636]\n",
            " [0.30428599 0.21811313]]\n",
            "Total Error: 1.3797106522076135\n",
            "\n",
            "Epoch 4:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.29571189 0.60815239]\n",
            " [0.22951431 0.99325843]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.69250946 0.88838169]\n",
            " [0.29717732 0.25751563]]\n",
            "Total Error: 1.343902491419443\n",
            "\n",
            "Epoch 5:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.3107414  0.61261049]\n",
            " [0.24558931 0.99460848]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.69449586 0.89560275]\n",
            " [0.28856319 0.29101572]]\n",
            "Total Error: 1.3196022226191242\n",
            "\n",
            "Epoch 6:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.3231751  0.61726668]\n",
            " [0.25819652 0.99607186]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.69583318 0.90196806]\n",
            " [0.27915976 0.32006214]]\n",
            "Total Error: 1.3020110481413176\n",
            "\n",
            "Epoch 7:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.3336975  0.62207454]\n",
            " [0.26830264 0.99762176]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.6967901  0.90756181]\n",
            " [0.26941852 0.34563651]]\n",
            "Total Error: 1.2886463829410646\n",
            "\n",
            "Epoch 8:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.34276473 0.6270002 ]\n",
            " [0.27656116 0.9992437 ]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.69755873 0.91246852]\n",
            " [0.2596302  0.36843133]]\n",
            "Total Error: 1.2781158293884818\n",
            "\n",
            "Epoch 9:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.35069217 0.6320169 ]\n",
            " [0.28342686 1.00092858]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.69827504 0.91676494]\n",
            " [0.24998238 0.38895166]]\n",
            "Total Error: 1.2695850152606276\n",
            "\n",
            "Epoch 10:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.3577043  0.63710252]\n",
            " [0.28922345 1.00266964]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.69903383 0.92051812]\n",
            " [0.24059385 0.40757629]]\n",
            "Total Error: 1.2625248437870977\n",
            "\n",
            "\n",
            "Training AND gate (Multiple Outputs) with ReLU activation function and bias:\n",
            "Epoch 1:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.68076035 0.86135497]\n",
            " [0.18195364 0.21229925]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.03484448 0.31040556]\n",
            " [0.27262188 0.05765072]]\n",
            "Updated Bias Hidden:\n",
            "[ 0.33207737 -0.0824364 ]\n",
            "Updated Bias Output:\n",
            "[0.50604948 0.39389716]\n",
            "Total Error: 3.6375295105405216\n",
            "\n",
            "Epoch 2:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.65325013 0.84583778]\n",
            " [0.16001438 0.20033476]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[ 0.00218874  0.23187583]\n",
            " [ 0.25143805 -0.0024929 ]]\n",
            "Updated Bias Hidden:\n",
            "[ 0.30242547 -0.11183366]\n",
            "Updated Bias Output:\n",
            "[0.4659608 0.3266734]\n",
            "Total Error: 1.3528957109018505\n",
            "\n",
            "Epoch 3:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.63897091 0.83791429]\n",
            " [0.14759378 0.19398179]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[-0.00976199  0.2008368 ]\n",
            " [ 0.24469587 -0.03297325]]\n",
            "Updated Bias Hidden:\n",
            "[ 0.29154525 -0.13373558]\n",
            "Updated Bias Output:\n",
            "[0.45089695 0.31462883]\n",
            "Total Error: 1.2534726249281563\n",
            "\n",
            "Epoch 4:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.62856009 0.83207738]\n",
            " [0.13773788 0.18921088]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[-0.01461734  0.18560935]\n",
            " [ 0.24340173 -0.05361959]]\n",
            "Updated Bias Hidden:\n",
            "[ 0.28497948 -0.15450332]\n",
            "Updated Bias Output:\n",
            "[0.44532065 0.32062503]\n",
            "Total Error: 1.2315853217746349\n",
            "\n",
            "Epoch 5:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.61975837 0.82707132]\n",
            " [0.12888558 0.1851984 ]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[-0.01671845  0.17663409]\n",
            " [ 0.24473308 -0.07054699]]\n",
            "Updated Bias Hidden:\n",
            "[ 0.27966367 -0.17539138]\n",
            "Updated Bias Output:\n",
            "[0.44374718 0.33267639]\n",
            "Total Error: 1.2177524783466094\n",
            "\n",
            "Epoch 6:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.61182683 0.82249667]\n",
            " [0.12055326 0.18172048]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[-0.01773464  0.17040385]\n",
            " [ 0.24763965 -0.08602307]]\n",
            "Updated Bias Hidden:\n",
            "[ 0.27471312 -0.19676028]\n",
            "Updated Bias Output:\n",
            "[0.44396599 0.34632294]\n",
            "Total Error: 1.2048269651467152\n",
            "\n",
            "Epoch 7:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.60451472 0.81786798]\n",
            " [0.1125882  0.19607305]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[-0.01929562  0.16564388]\n",
            " [ 0.25121928 -0.10125287]]\n",
            "Updated Bias Hidden:\n",
            "[ 0.2698963  -0.20138897]\n",
            "Updated Bias Output:\n",
            "[0.44384841 0.36004664]\n",
            "Total Error: 1.1945870088100259\n",
            "\n",
            "Epoch 8:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.59769714 0.81320044]\n",
            " [0.10493344 0.21141341]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[-0.02127317  0.16182631]\n",
            " [ 0.2551518  -0.1160077 ]]\n",
            "Updated Bias Hidden:\n",
            "[ 0.26512825 -0.20605651]\n",
            "Updated Bias Output:\n",
            "[0.44341403 0.37331404]\n",
            "Total Error: 1.1859389848402389\n",
            "\n",
            "Epoch 9:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.59119072 0.80896616]\n",
            " [0.09750692 0.20814495]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[-0.02246074  0.15828796]\n",
            " [ 0.25922673 -0.12917981]]\n",
            "Updated Bias Hidden:\n",
            "[ 0.26027125 -0.23014178]\n",
            "Updated Bias Output:\n",
            "[0.44389488 0.38549239]\n",
            "Total Error: 1.1788193219304917\n",
            "\n",
            "Epoch 10:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.58507963 0.80455734]\n",
            " [0.09035326 0.22556059]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[-0.02432001  0.1553425 ]\n",
            " [ 0.26384231 -0.14263555]]\n",
            "Updated Bias Hidden:\n",
            "[ 0.25544847 -0.23455059]\n",
            "Updated Bias Output:\n",
            "[0.44375372 0.3969712 ]\n",
            "Total Error: 1.1696490025527768\n",
            "\n",
            "\n",
            "Training AND gate (Multiple Outputs) with ReLU activation function without bias:\n",
            "Epoch 1:\n",
            "Updated Weights Input-Hidden:\n",
            "[[ 0.76920524  0.46809898]\n",
            " [ 0.24866205 -0.00200373]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.64993661 0.21098319]\n",
            " [0.79736613 0.66484878]]\n",
            "Total Error: 2.1283333648666916\n",
            "\n",
            "Epoch 2:\n",
            "Updated Weights Input-Hidden:\n",
            "[[ 0.71553662  0.40152715]\n",
            " [ 0.24875798 -0.03299659]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.58931862 0.21805685]\n",
            " [0.76116046 0.66430028]]\n",
            "Total Error: 1.6351307348240314\n",
            "\n",
            "Epoch 3:\n",
            "Updated Weights Input-Hidden:\n",
            "[[ 0.68501644  0.36612337]\n",
            " [ 0.25912641 -0.05046699]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.55632842 0.23358893]\n",
            " [0.74039272 0.66900398]]\n",
            "Total Error: 1.5346764366541181\n",
            "\n",
            "Epoch 4:\n",
            "Updated Weights Input-Hidden:\n",
            "[[ 0.66491824  0.34470142]\n",
            " [ 0.27393204 -0.06248569]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.53661918 0.25161626]\n",
            " [0.72593154 0.67516697]]\n",
            "Total Error: 1.4964299677136164\n",
            "\n",
            "Epoch 5:\n",
            "Updated Weights Input-Hidden:\n",
            "[[ 0.65027138  0.3302829 ]\n",
            " [ 0.29085579 -0.07239444]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.52451199 0.26995449]\n",
            " [0.71460047 0.68166974]]\n",
            "Total Error: 1.4751573755366265\n",
            "\n",
            "Epoch 6:\n",
            "Updated Weights Input-Hidden:\n",
            "[[ 0.63870429  0.31954543]\n",
            " [ 0.30875815 -0.08176411]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.51725932 0.28769112]\n",
            " [0.70500276 0.68816187]]\n",
            "Total Error: 1.460098281291576\n",
            "\n",
            "Epoch 7:\n",
            "Updated Weights Input-Hidden:\n",
            "[[ 0.62896515  0.31079883]\n",
            " [ 0.32701135 -0.09136093]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.51336518 0.3044572 ]\n",
            " [0.69642105 0.69457739]]\n",
            "Total Error: 1.4478938625859321\n",
            "\n",
            "Epoch 8:\n",
            "Updated Weights Input-Hidden:\n",
            "[[ 0.62035749  0.30316354]\n",
            " [ 0.34524641 -0.10155281]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.51194054 0.3201433 ]\n",
            " [0.68843926 0.70096908]]\n",
            "Total Error: 1.437251626330205\n",
            "\n",
            "Epoch 9:\n",
            "Updated Weights Input-Hidden:\n",
            "[[ 0.61248411  0.29618397]\n",
            " [ 0.36323825 -0.1125046 ]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.51241477 0.33476803]\n",
            " [0.6807898  0.70743918]]\n",
            "Total Error: 1.4275655548946136\n",
            "\n",
            "Epoch 10:\n",
            "Updated Weights Input-Hidden:\n",
            "[[ 0.60511733  0.28963111]\n",
            " [ 0.38084668 -0.12427863]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.51439382 0.34841117]\n",
            " [0.67328447 0.71410652]]\n",
            "Total Error: 1.4184967005931555\n",
            "\n",
            "\n",
            "Training XOR gate (Multiple Outputs) with Sigmoid activation function and bias:\n",
            "Epoch 1:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.56116719 0.26634532]\n",
            " [0.93809395 0.50288309]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.83974916 0.73174589]\n",
            " [0.74587908 0.81836883]]\n",
            "Updated Bias Hidden:\n",
            "[0.22471193 0.77486723]\n",
            "Updated Bias Output:\n",
            "[0.20270047 0.80847969]\n",
            "Total Error: 1.4718686440577324\n",
            "\n",
            "Epoch 2:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.55851453 0.26396078]\n",
            " [0.93582066 0.50072043]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.82587417 0.72044407]\n",
            " [0.73153727 0.80602172]]\n",
            "Updated Bias Hidden:\n",
            "[0.21927176 0.76986577]\n",
            "Updated Bias Output:\n",
            "[0.18400651 0.79191103]\n",
            "Total Error: 1.458270064568199\n",
            "\n",
            "Epoch 3:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.55587332 0.26158836]\n",
            " [0.93354889 0.49856145]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.81200537 0.70898442]\n",
            " [0.71720437 0.79350133]]\n",
            "Updated Bias Hidden:\n",
            "[0.21386453 0.76489375]\n",
            "Updated Bias Output:\n",
            "[0.165297   0.77508697]\n",
            "Total Error: 1.4445007973323891\n",
            "\n",
            "Epoch 4:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.55324767 0.25923166]\n",
            " [0.93128205 0.49640933]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.79816623 0.69737087]\n",
            " [0.70290505 0.78081197]]\n",
            "Updated Bias Hidden:\n",
            "[0.20849814 0.75995824]\n",
            "Updated Bias Output:\n",
            "[0.14660434 0.75801264]\n",
            "Total Error: 1.4305887156533221\n",
            "\n",
            "Epoch 5:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.55064171 0.25689434]\n",
            " [0.92902366 0.49426729]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.7843809  0.68560824]\n",
            " [0.68866469 0.76795885]]\n",
            "Updated Bias Hidden:\n",
            "[0.20318057 0.75506636]\n",
            "Updated Bias Output:\n",
            "[0.12796213 0.74069449]\n",
            "Total Error: 1.4165636080993136\n",
            "\n",
            "Epoch 6:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.54805957 0.25458003]\n",
            " [0.92677727 0.49213863]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.770674   0.67370231]\n",
            " [0.67450918 0.75494825]]\n",
            "Updated Bias Hidden:\n",
            "[0.19791981 0.75022525]\n",
            "Updated Bias Output:\n",
            "[0.1094048  0.72314045]\n",
            "Total Error: 1.402456870520434\n",
            "\n",
            "Epoch 7:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.54550534 0.25229233]\n",
            " [0.92454648 0.49002663]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.75707034 0.66165984]\n",
            " [0.66046457 0.74178751]]\n",
            "Updated Bias Hidden:\n",
            "[0.19272378 0.74544198]\n",
            "Updated Bias Output:\n",
            "[0.09096721 0.70535996]\n",
            "Total Error: 1.388301157379003\n",
            "\n",
            "Epoch 8:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.54298303 0.25003474]\n",
            " [0.92233487 0.4879346 ]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.7435946  0.64948864]\n",
            " [0.64655683 0.72848511]]\n",
            "Updated Bias Hidden:\n",
            "[0.18760026 0.74072352]\n",
            "Updated Bias Output:\n",
            "[0.0726843 0.6873641]\n",
            "Total Error: 1.374130004443335\n",
            "\n",
            "Epoch 9:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.54049653 0.24781068]\n",
            " [0.92014599 0.48586575]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.73027108 0.63719763]\n",
            " [0.63281149 0.71505075]]\n",
            "Updated Bias Hidden:\n",
            "[0.18255682 0.73607663]\n",
            "Updated Bias Output:\n",
            "[0.05459066 0.66916566]\n",
            "Total Error: 1.3599774367193922\n",
            "\n",
            "Epoch 10:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.53804954 0.24562341]\n",
            " [0.91798331 0.48382327]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.71712338 0.62479688]\n",
            " [0.61925337 0.70149533]]\n",
            "Updated Bias Hidden:\n",
            "[0.17760073 0.73150787]\n",
            "Updated Bias Output:\n",
            "[0.03672008 0.65077918]\n",
            "Total Error: 1.3458775762992892\n",
            "\n",
            "\n",
            "Training XOR gate (Multiple Outputs) with Sigmoid activation function without bias:\n",
            "Epoch 1:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.38947179 0.76584301]\n",
            " [0.47829082 0.56398978]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.6582486  0.58626056]\n",
            " [0.82465122 0.69284044]]\n",
            "Total Error: 1.1774489161647415\n",
            "\n",
            "Epoch 2:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.38696768 0.76320885]\n",
            " [0.4757944  0.56123292]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.64747791 0.57667014]\n",
            " [0.81274383 0.68269313]]\n",
            "Total Error: 1.1726159696510494\n",
            "\n",
            "Epoch 3:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.38451863 0.76062566]\n",
            " [0.47335206 0.55852909]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.63679605 0.56717682]\n",
            " [0.80093193 0.6726474 ]]\n",
            "Total Error: 1.167873912814339\n",
            "\n",
            "Epoch 4:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.38212452 0.75809353]\n",
            " [0.47096366 0.55587836]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.62620547 0.55778184]\n",
            " [0.78921825 0.66270471]]\n",
            "Total Error: 1.1632235482625481\n",
            "\n",
            "Epoch 5:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.37978517 0.75561251]\n",
            " [0.46862902 0.55328072]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.61570847 0.54848635]\n",
            " [0.77760543 0.65286638]]\n",
            "Total Error: 1.1586655220195305\n",
            "\n",
            "Epoch 6:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.37750034 0.75318254]\n",
            " [0.46634789 0.55073608]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.60530724 0.53929136]\n",
            " [0.76609594 0.64313366]]\n",
            "Total Error: 1.1542003270898813\n",
            "\n",
            "Epoch 7:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.37526973 0.75080355]\n",
            " [0.46411998 0.54824432]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.59500385 0.53019782]\n",
            " [0.75469213 0.63350767]]\n",
            "Total Error: 1.1498283075175353\n",
            "\n",
            "Epoch 8:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.37309298 0.74847537]\n",
            " [0.46194492 0.54580525]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.58480023 0.52120656]\n",
            " [0.74339621 0.6239894 ]]\n",
            "Total Error: 1.1455496628885102\n",
            "\n",
            "Epoch 9:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.37096968 0.7461978 ]\n",
            " [0.45982229 0.54341861]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.57469822 0.51231832]\n",
            " [0.73221025 0.61457978]]\n",
            "Total Error: 1.1413644532275102\n",
            "\n",
            "Epoch 10:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.36889936 0.74397057]\n",
            " [0.45775165 0.54108411]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.56469951 0.50353374]\n",
            " [0.72113618 0.60527961]]\n",
            "Total Error: 1.137272604238011\n",
            "\n",
            "\n",
            "Training XOR gate (Multiple Outputs) with Tanh activation function and bias:\n",
            "Epoch 1:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.90295287 0.835509  ]\n",
            " [0.80120076 0.94310545]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.69823035 0.85746985]\n",
            " [0.59636616 0.50081925]]\n",
            "Updated Bias Hidden:\n",
            "[0.60605997 0.38542283]\n",
            "Updated Bias Output:\n",
            "[0.23398224 0.74767092]\n",
            "Total Error: 1.7164033383931745\n",
            "\n",
            "Epoch 2:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.90029245 0.83188695]\n",
            " [0.79821723 0.94023731]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.67409984 0.84150746]\n",
            " [0.57094643 0.4882183 ]]\n",
            "Updated Bias Hidden:\n",
            "[0.59733486 0.37950752]\n",
            "Updated Bias Output:\n",
            "[0.21362124 0.7228244 ]\n",
            "Total Error: 1.6913227753021072\n",
            "\n",
            "Epoch 3:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.89742455 0.82803679]\n",
            " [0.79500069 0.9371902 ]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.64861803 0.82441454]\n",
            " [0.54388691 0.47470111]]\n",
            "Updated Bias Hidden:\n",
            "[0.58857578 0.37380696]\n",
            "Updated Bias Output:\n",
            "[0.19281083 0.69609245]\n",
            "Total Error: 1.6633520353667093\n",
            "\n",
            "Epoch 4:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.89435141 0.82397748]\n",
            " [0.7915492  0.93397504]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.62195563 0.80607094]\n",
            " [0.51530709 0.46015976]]\n",
            "Updated Bias Hidden:\n",
            "[0.57984261 0.36839378]\n",
            "Updated Bias Output:\n",
            "[0.1719071  0.66727881]\n",
            "Total Error: 1.6323906694481503\n",
            "\n",
            "Epoch 5:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.89108724 0.8197461 ]\n",
            " [0.78787167 0.93061456]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.59443704 0.78634839]\n",
            " [0.48547835 0.44447617]]\n",
            "Updated Bias Hidden:\n",
            "[0.57119721 0.36333762]\n",
            "Updated Bias Output:\n",
            "[0.15143715 0.63617667]\n",
            "Total Error: 1.5984990071370815\n",
            "\n",
            "Epoch 6:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.88766139 0.81540063]\n",
            " [0.78399121 0.92714538]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.56657273 0.76511633]\n",
            " [0.45486169 0.4275266 ]]\n",
            "Updated Bias Hidden:\n",
            "[0.56269667 0.35869582]\n",
            "Updated Bias Output:\n",
            "[0.13211702 0.6025783 ]\n",
            "Total Error: 1.5619463947575332\n",
            "\n",
            "Epoch 7:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.8841195  0.81101887]\n",
            " [0.77994735 0.9236179 ]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.5390559  0.74225448]\n",
            " [0.42411269 0.40919206]]\n",
            "Updated Bias Hidden:\n",
            "[0.55438623 0.35450349]\n",
            "Updated Bias Output:\n",
            "[0.11482361 0.56629392]\n",
            "Total Error: 1.5232044220208318\n",
            "\n",
            "Epoch 8:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.88052116 0.8066918 ]\n",
            " [0.77579572 0.92009301]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.51269443 0.71767669]\n",
            " [0.39402376 0.38937916]]\n",
            "Updated Bias Hidden:\n",
            "[0.54629635 0.35076776]\n",
            "Updated Bias Output:\n",
            "[0.100493   0.52718607]\n",
            "Total Error: 1.4828428752448994\n",
            "\n",
            "Epoch 9:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.87693388 0.80251199]\n",
            " [0.77160502 0.91663587]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.48827039 0.69137336]\n",
            " [0.36539329 0.36805825]]\n",
            "Updated Bias Hidden:\n",
            "[0.53845132 0.34747333]\n",
            "Updated Bias Output:\n",
            "[0.08994484 0.48522893]\n",
            "Total Error: 1.441345842438738\n",
            "\n",
            "Epoch 10:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.8734261  0.7985614 ]\n",
            " [0.76745279 0.91330893]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.46636749 0.66348035]\n",
            " [0.33885749 0.34532644]]\n",
            "Updated Bias Hidden:\n",
            "[0.53089493 0.34460389]\n",
            "Updated Bias Output:\n",
            "[0.08368714 0.44060317]\n",
            "Total Error: 1.3989852344445797\n",
            "\n",
            "\n",
            "Training XOR gate (Multiple Outputs) with Tanh activation function without bias:\n",
            "Epoch 1:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.75019975 0.87730356]\n",
            " [0.60354922 0.59903674]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.29435    0.33324055]\n",
            " [0.31721396 0.93747375]]\n",
            "Total Error: 1.2409813028689634\n",
            "\n",
            "Epoch 2:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.74833244 0.87689857]\n",
            " [0.60433913 0.60785851]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.2975257  0.33366472]\n",
            " [0.31952752 0.93805244]]\n",
            "Total Error: 1.2399739445860285\n",
            "\n",
            "Epoch 3:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.74638736 0.87647905]\n",
            " [0.60489901 0.61618157]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.30002839 0.33389447]\n",
            " [0.32102922 0.93855483]]\n",
            "Total Error: 1.2391317977394147\n",
            "\n",
            "Epoch 4:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.74438594 0.87606507]\n",
            " [0.60526427 0.62407561]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.30204054 0.33394772]\n",
            " [0.32190852 0.93898947]]\n",
            "Total Error: 1.2383978395258377\n",
            "\n",
            "Epoch 5:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.74234432 0.87567183]\n",
            " [0.6054627  0.63159707]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.3036987  0.33383974]\n",
            " [0.3223081  0.93936382]]\n",
            "Total Error: 1.2377383402055677\n",
            "\n",
            "Epoch 6:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.74027458 0.87531075]\n",
            " [0.60551618 0.63879213]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.30510543 0.33358364]\n",
            " [0.32233588 0.93968441]]\n",
            "Total Error: 1.237132841554346\n",
            "\n",
            "Epoch 7:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.7381857  0.87499042]\n",
            " [0.60544201 0.64569891]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.30633795 0.33319079]\n",
            " [0.3220737  0.93995701]]\n",
            "Total Error: 1.236568522966739\n",
            "\n",
            "Epoch 8:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.73608428 0.87471724]\n",
            " [0.60525393 0.65234926]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.30745451 0.33267109]\n",
            " [0.32158377 0.94018673]]\n",
            "Total Error: 1.2360370037242452\n",
            "\n",
            "Epoch 9:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.73397514 0.87449597]\n",
            " [0.60496292 0.65877002]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.30849901 0.33203321]\n",
            " [0.32091339 0.94037816]]\n",
            "Total Error: 1.2355325150428746\n",
            "\n",
            "Epoch 10:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.73186169 0.87433009]\n",
            " [0.6045778  0.66498405]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.30950457 0.3312848 ]\n",
            " [0.32009857 0.94053541]]\n",
            "Total Error: 1.2350508495402344\n",
            "\n",
            "\n",
            "Training XOR gate (Multiple Outputs) with ReLU activation function and bias:\n",
            "Epoch 1:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.31085061 0.16945246]\n",
            " [0.21179624 0.50107616]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[-0.02185628  0.5845195 ]\n",
            " [ 0.31277384  0.41677456]]\n",
            "Updated Bias Hidden:\n",
            "[-0.1766382   0.32859997]\n",
            "Updated Bias Output:\n",
            "[0.40117887 0.17179971]\n",
            "Total Error: 2.5547523767525533\n",
            "\n",
            "Epoch 2:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.28015818 0.1414305 ]\n",
            " [0.18198207 0.46128438]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[-0.01214917  0.54780551]\n",
            " [ 0.28820389  0.37188579]]\n",
            "Updated Bias Hidden:\n",
            "[-0.17651788  0.2997376 ]\n",
            "Updated Bias Output:\n",
            "[0.37173034 0.14030669]\n",
            "Total Error: 1.3997049048247072\n",
            "\n",
            "Epoch 3:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.26239451 0.12578229]\n",
            " [0.1664635  0.4363042 ]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.00088669 0.51964423]\n",
            " [0.27728527 0.3545254 ]]\n",
            "Updated Bias Hidden:\n",
            "[-0.16048449  0.29221213]\n",
            "Updated Bias Output:\n",
            "[0.360513   0.14476588]\n",
            "Total Error: 1.3416606857762867\n",
            "\n",
            "Epoch 4:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.24900931 0.11420808]\n",
            " [0.15518505 0.41630126]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.01371549 0.49558293]\n",
            " [0.27132722 0.344859  ]]\n",
            "Updated Bias Hidden:\n",
            "[-0.14162188  0.29034389]\n",
            "Updated Bias Output:\n",
            "[0.35649852 0.15816103]\n",
            "Total Error: 1.310391514825484\n",
            "\n",
            "Epoch 5:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.2376569  0.1044335 ]\n",
            " [0.14554871 0.39860967]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.02555826 0.47444505]\n",
            " [0.26756767 0.33796257]]\n",
            "Updated Bias Hidden:\n",
            "[-0.12307698  0.29012331]\n",
            "Updated Bias Output:\n",
            "[0.35569268 0.17327771]\n",
            "Total Error: 1.2842896939452855\n",
            "\n",
            "Epoch 6:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.22752298 0.09566529]\n",
            " [0.13674058 0.38228906]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.03625038 0.45567484]\n",
            " [0.26490129 0.33231575]]\n",
            "Updated Bias Hidden:\n",
            "[-0.10564575  0.29027964]\n",
            "Updated Bias Output:\n",
            "[0.35639642 0.18797788]\n",
            "Total Error: 1.2621190496230439\n",
            "\n",
            "Epoch 7:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.21826236 0.08757831]\n",
            " [0.1284694  0.36694761]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.04580516 0.43892282]\n",
            " [0.26283797 0.32739036]]\n",
            "Updated Bias Hidden:\n",
            "[-0.0894608   0.29038654]\n",
            "Updated Bias Output:\n",
            "[0.35783293 0.20166844]\n",
            "Total Error: 1.2433894498013014\n",
            "\n",
            "Epoch 8:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.20969423 0.08001657]\n",
            " [0.12061306 0.35239417]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.05429021 0.42393473]\n",
            " [0.26114585 0.32298005]]\n",
            "Updated Bias Hidden:\n",
            "[-0.07446068  0.29030902]\n",
            "Updated Bias Output:\n",
            "[0.35963094 0.21425154]\n",
            "Total Error: 1.227548937074531\n",
            "\n",
            "Epoch 9:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.20170371 0.07289202]\n",
            " [0.11310864 0.33851909]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.06178643 0.41051062]\n",
            " [0.25970894 0.31898976]]\n",
            "Updated Bias Hidden:\n",
            "[-0.06053266  0.29001722]\n",
            "Updated Bias Output:\n",
            "[0.36160727 0.22578408]\n",
            "Total Error: 1.2140839481590198\n",
            "\n",
            "Epoch 10:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.19420707 0.06614702]\n",
            " [0.10591584 0.32524944]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.06837368 0.39848643]\n",
            " [0.25846556 0.31536516]]\n",
            "Updated Bias Hidden:\n",
            "[-0.04755739  0.28951897]\n",
            "Updated Bias Output:\n",
            "[0.36366936 0.23636325]\n",
            "Total Error: 1.2025633280042616\n",
            "\n",
            "\n",
            "Training XOR gate (Multiple Outputs) with ReLU activation function without bias:\n",
            "Epoch 1:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.20299882 0.42589641]\n",
            " [0.52442117 0.05820775]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.656764   0.33964045]\n",
            " [0.92043208 0.8502796 ]]\n",
            "Total Error: 1.8285700070837392\n",
            "\n",
            "Epoch 2:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.16834463 0.36998623]\n",
            " [0.50169274 0.03132789]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.63196757 0.33917104]\n",
            " [0.90072058 0.8410606 ]]\n",
            "Total Error: 1.4403698880100264\n",
            "\n",
            "Epoch 3:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.15145676 0.34381823]\n",
            " [0.49337575 0.02825312]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.6202815  0.34606834]\n",
            " [0.89220675 0.83719308]]\n",
            "Total Error: 1.4042750894922076\n",
            "\n",
            "Epoch 4:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.14165293 0.32940368]\n",
            " [0.48974484 0.03238166]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.61310937 0.35463904]\n",
            " [0.88757633 0.83493392]]\n",
            "Total Error: 1.3962840046754446\n",
            "\n",
            "Epoch 5:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.13522543 0.32042054]\n",
            " [0.48765522 0.03834131]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.60778106 0.36322421]\n",
            " [0.88467604 0.83329049]]\n",
            "Total Error: 1.3926800239962667\n",
            "\n",
            "Epoch 6:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.13064683 0.31428194]\n",
            " [0.48598213 0.04428519]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.60332528 0.37129918]\n",
            " [0.88269217 0.83189732]]\n",
            "Total Error: 1.3902801403506906\n",
            "\n",
            "Epoch 7:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.12721392 0.3098202 ]\n",
            " [0.4843315  0.0496341 ]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.5993644  0.37872721]\n",
            " [0.88126893 0.83059524]]\n",
            "Total Error: 1.3884872313566925\n",
            "\n",
            "Epoch 8:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.12456566 0.30645381]\n",
            " [0.48258513 0.05427453]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.59574488 0.38551082]\n",
            " [0.88023113 0.82930922]]\n",
            "Total Error: 1.3871013099727816\n",
            "\n",
            "Epoch 9:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.12249405 0.30385981]\n",
            " [0.48072684 0.05825486]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.59239992 0.3916997 ]\n",
            " [0.8794816  0.82800296]]\n",
            "Total Error: 1.3860076810030462\n",
            "\n",
            "Epoch 10:\n",
            "Updated Weights Input-Hidden:\n",
            "[[0.12086543 0.30183835]\n",
            " [0.4787746  0.06166932]]\n",
            "Updated Weights Hidden-Output:\n",
            "[[0.5892964  0.39735555]\n",
            " [0.87895971 0.82665938]]\n",
            "Total Error: 1.3851269030064859\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Define the MLP model\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(10, activation='softmax')  # 10 classes for digits 0-9\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f'Test Loss: {test_loss:.4f}')\n",
        "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JuqmEnfUoM74",
        "outputId": "15735d80-905c-47d7-c462-6c388875880b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8641 - loss: 0.4747 - val_accuracy: 0.9592 - val_loss: 0.1403\n",
            "Epoch 2/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9661 - loss: 0.1155 - val_accuracy: 0.9678 - val_loss: 0.1053\n",
            "Epoch 3/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9769 - loss: 0.0748 - val_accuracy: 0.9693 - val_loss: 0.0990\n",
            "Epoch 4/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9844 - loss: 0.0509 - val_accuracy: 0.9743 - val_loss: 0.0912\n",
            "Epoch 5/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9871 - loss: 0.0420 - val_accuracy: 0.9719 - val_loss: 0.1010\n",
            "Epoch 6/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9899 - loss: 0.0315 - val_accuracy: 0.9718 - val_loss: 0.1082\n",
            "Epoch 7/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9911 - loss: 0.0270 - val_accuracy: 0.9722 - val_loss: 0.1055\n",
            "Epoch 8/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9935 - loss: 0.0202 - val_accuracy: 0.9733 - val_loss: 0.1093\n",
            "Epoch 9/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9943 - loss: 0.0186 - val_accuracy: 0.9747 - val_loss: 0.1072\n",
            "Epoch 10/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9950 - loss: 0.0134 - val_accuracy: 0.9745 - val_loss: 0.1158\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9723 - loss: 0.1086\n",
            "Test Loss: 0.0948\n",
            "Test Accuracy: 0.9772\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHHCAYAAABXx+fLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABoJElEQVR4nO3deVxU5f4H8M/MADPDDrIjypKCmoLKklq2UaRmaqRmlohmt1LTqNvVxLWbtJrrNfWmlkuaudSvbppSaeYC4p67qCyyyjIwwAAz5/fHwOgIKChwgPm8X6/zgjk858z3iDUfn/M8z5EIgiCAiIiIyIRIxS6AiIiIqLkxABEREZHJYQAiIiIik8MARERERCaHAYiIiIhMDgMQERERmRwGICIiIjI5DEBERERkchiAiIiIyOQwABFRs5JIJJgzZ06Dj7t69SokEgnWrl3b6DURkelhACIyQWvXroVEIoFEIsH+/ftr/FwQBHh5eUEikeDZZ58VoUIioqbFAERkwhQKBTZu3Fhj/969e5GWlga5XC5CVURETY8BiMiEDRw4EFu2bEFlZaXR/o0bN6J3795wc3MTqTLToVarxS6ByCQxABGZsFGjRuHGjRvYvXu3YV95eTm+//57vPTSS7Ueo1ar8c4778DLywtyuRz+/v747LPPIAiCUTuNRoO3334bzs7OsLGxwXPPPYe0tLRaz5meno5x48bB1dUVcrkc3bp1w+rVq+/pmvLy8vDuu++ie/fusLa2hq2tLQYMGIATJ07UaFtWVoY5c+agc+fOUCgUcHd3x/PPP4/Lly8b2uh0OixatAjdu3eHQqGAs7MznnnmGRw5cgTAnccm3T7eac6cOZBIJDhz5gxeeuklODg44OGHHwYAnDx5EmPHjoWvry8UCgXc3Nwwbtw43Lhxo9Y/r/Hjx8PDwwNyuRw+Pj544403UF5ejuTkZEgkEnzxxRc1jjtw4AAkEgm+/fbbhv6xErU5ZmIXQETi8fb2Rp8+ffDtt99iwIABAIBffvkFhYWFePHFF7F48WKj9oIg4LnnnsPvv/+O8ePHIygoCLt27cI///lPpKenG33ovvrqq1i/fj1eeukl9O3bF7/99hsGDRpUo4asrCw89NBDkEgkmDRpEpydnfHLL79g/PjxUKlUmDp1aoOuKTk5GTt27MDw4cPh4+ODrKwsrFixAo8++ijOnDkDDw8PAIBWq8Wzzz6L+Ph4vPjii5gyZQqKioqwe/dunD59Gn5+fgCA8ePHY+3atRgwYABeffVVVFZW4s8//8ShQ4cQHBzcoNqqDR8+HJ06dcL8+fMNwXH37t1ITk5GdHQ03Nzc8Pfff2PlypX4+++/cejQIUgkEgDA9evXERoaioKCArz22msICAhAeno6vv/+e5SUlMDX1xf9+vXDhg0b8Pbbbxu974YNG2BjY4MhQ4bcU91EbYpARCZnzZo1AgAhMTFRWLp0qWBjYyOUlJQIgiAIw4cPFx5//HFBEAShY8eOwqBBgwzH7dixQwAg/Pvf/zY63wsvvCBIJBLh0qVLgiAIwvHjxwUAwptvvmnU7qWXXhIACLNnzzbsGz9+vODu7i7k5uYatX3xxRcFOzs7Q11XrlwRAAhr1qy547WVlZUJWq3WaN+VK1cEuVwuzJs3z7Bv9erVAgBhwYIFNc6h0+kEQRCE3377TQAgvPXWW3W2uVNdt1/r7NmzBQDCqFGjarStvs5bffvttwIAYd++fYZ9Y8aMEaRSqZCYmFhnTStWrBAACGfPnjX8rLy8XHBychKioqJqHEdkingLjMjEjRgxAqWlpfjpp59QVFSEn376qc7bX//73/8gk8nw1ltvGe1/5513IAgCfvnlF0M7ADXa3d6bIwgCtm7disGDB0MQBOTm5hq2iIgIFBYW4ujRow26HrlcDqlU/782rVaLGzduwNraGv7+/kbn2rp1K5ycnDB58uQa56jubdm6dSskEglmz55dZ5t78frrr9fYp1QqDd+XlZUhNzcXDz30EAAY6tbpdNixYwcGDx5ca+9TdU0jRoyAQqHAhg0bDD/btWsXcnNz8fLLL99z3URtCQMQkYlzdnZGeHg4Nm7ciG3btkGr1eKFF16ote21a9fg4eEBGxsbo/1dunQx/Lz6q1QqNdxGqubv72/0OicnBwUFBVi5ciWcnZ2NtujoaABAdnZ2g65Hp9Phiy++QKdOnSCXy+Hk5ARnZ2ecPHkShYWFhnaXL1+Gv78/zMzqHglw+fJleHh4wNHRsUE13I2Pj0+NfXl5eZgyZQpcXV2hVCrh7OxsaFddd05ODlQqFR588ME7nt/e3h6DBw82muG3YcMGeHp64oknnmjEKyFqvTgGiIjw0ksvYcKECcjMzMSAAQNgb2/fLO+r0+kAAC+//DKioqJqbdOjR48GnXP+/PmYOXMmxo0bhw8++ACOjo6QSqWYOnWq4f0aU109QVqtts5jbu3tqTZixAgcOHAA//znPxEUFARra2vodDo888wz91T3mDFjsGXLFhw4cADdu3fHjz/+iDfffNPQO0Zk6hiAiAjDhg3DP/7xDxw6dAibN2+us13Hjh2xZ88eFBUVGfUCnTt3zvDz6q86nc7Qy1Lt/PnzRuerniGm1WoRHh7eKNfy/fff4/HHH8dXX31ltL+goABOTk6G135+fjh8+DAqKipgbm5e67n8/Pywa9cu5OXl1dkL5ODgYDj/rap7w+ojPz8f8fHxmDt3LmbNmmXYf/HiRaN2zs7OsLW1xenTp+96zmeeeQbOzs7YsGEDwsLCUFJSgldeeaXeNRG1dfynABHB2toay5cvx5w5czB48OA62w0cOBBarRZLly412v/FF19AIpEYZpJVf719FtnChQuNXstkMkRGRmLr1q21fqjn5OQ0+FpkMlmNKflbtmxBenq60b7IyEjk5ubWuBYAhuMjIyMhCALmzp1bZxtbW1s4OTlh3759Rj//z3/+06Cabz1ntdv/vKRSKYYOHYr/+7//M0zDr60mADAzM8OoUaPw3XffYe3atejevXuDe9OI2jL2ABERANR5C+pWgwcPxuOPP44ZM2bg6tWrCAwMxK+//ooffvgBU6dONYz5CQoKwqhRo/Cf//wHhYWF6Nu3L+Lj43Hp0qUa5/zoo4/w+++/IywsDBMmTEDXrl2Rl5eHo0ePYs+ePcjLy2vQdTz77LOYN28eoqOj0bdvX5w6dQobNmyAr6+vUbsxY8bgm2++QUxMDBISEvDII49ArVZjz549ePPNNzFkyBA8/vjjeOWVV7B48WJcvHjRcDvqzz//xOOPP45JkyYB0E/5/+ijj/Dqq68iODgY+/btw4ULF+pds62tLfr3749PPvkEFRUV8PT0xK+//oorV67UaDt//nz8+uuvePTRR/Haa6+hS5cuyMjIwJYtW7B//36j25djxozB4sWL8fvvv+Pjjz9u0J8jUZsn2vwzIhLNrdPg7+T2afCCIAhFRUXC22+/LXh4eAjm5uZCp06dhE8//dQwBbtaaWmp8NZbbwnt2rUTrKyshMGDBwupqak1poYLgiBkZWUJEydOFLy8vARzc3PBzc1NePLJJ4WVK1ca2jRkGvw777wjuLu7C0qlUujXr59w8OBB4dFHHxUeffRRo7YlJSXCjBkzBB8fH8P7vvDCC8Lly5cNbSorK4VPP/1UCAgIECwsLARnZ2dhwIABQlJSktF5xo8fL9jZ2Qk2NjbCiBEjhOzs7Dqnwefk5NSoOy0tTRg2bJhgb28v2NnZCcOHDxeuX79e65/XtWvXhDFjxgjOzs6CXC4XfH19hYkTJwoajabGebt16yZIpVIhLS3tjn9uRKZGIgi39bkSEVGb0bNnTzg6OiI+Pl7sUohaFI4BIiJqo44cOYLjx49jzJgxYpdC1OKwB4iIqI05ffo0kpKS8PnnnyM3NxfJyclQKBRil0XUorAHiIiojfn+++8RHR2NiooKfPvttww/RLVgDxARERGZHPYAERERkclhACIiIiKTw4UQa6HT6XD9+nXY2Njc1xOfiYiIqPkIgoCioiJ4eHjc9bl3DEC1uH79Ory8vMQug4iIiO5Bamoq2rdvf8c2DEC1qH7IY2pqKmxtbUWuhoiIiOpDpVLBy8vL6GHNdWEAqkX1bS9bW1sGICIiolamPsNXOAiaiIiITA4DEBEREZkcBiAiIiIyORwDdB+0Wi0qKirELoMagbm5OWQymdhlEBFRM2EAugeCICAzMxMFBQVil0KNyN7eHm5ublz7iYjIBDAA3YPq8OPi4gJLS0t+YLZygiCgpKQE2dnZAAB3d3eRKyIioqbGANRAWq3WEH7atWsndjnUSJRKJQAgOzsbLi4uvB1GRNTGcRB0A1WP+bG0tBS5Emps1b9TjusiImr7GIDuEW97tT38nRIRmQ4GICIiIjI5DEB0X7y9vbFw4UKxyyAiImoQBiATIZFI7rjNmTPnns6bmJiI1157rXGLJSIiamKcBWYiMjIyDN9v3rwZs2bNwvnz5w37rK2tDd8LggCtVgszs7v/9XB2dm7cQomIqM3S6gSoyytRVFYJc6kELrYK0WphADIRbm5uhu/t7OwgkUgM+/744w88/vjj+N///ofY2FicOnUKv/76K7y8vBATE4NDhw5BrVajS5cuiIuLQ3h4uOFc3t7emDp1KqZOnQpA39O0atUq/Pzzz9i1axc8PT3x+eef47nnnmvW6yUiosYjCAJKK7QoLquEqqwSxZpKFJVVoLhMH2aKbntdrKmEqqyiql1l1f4KqMu1hnNG9mqPz0cEinZNDECNoPovRnNTmssadebStGnT8Nlnn8HX1xcODg5ITU3FwIED8eGHH0Iul+Obb77B4MGDcf78eXTo0KHO88ydOxeffPIJPv30UyxZsgSjR4/GtWvX4Ojo2Gi1EhFR/ZRX6vThpCqMFFWFEUM4qQ4rt4SXorKKW77Xf9XqhEarycJMCgGNd757wQDUCEortOg6a1ezv++ZeRGwtGi8X+G8efPw1FNPGV47OjoiMPBmOv/ggw+wfft2/Pjjj5g0aVKd5xk7dixGjRoFAJg/fz4WL16MhIQEPPPMM41WKxGRKSkt1yItvwTpBaUoLNWHlxq9LbcFGP3+SpRX6hqtDqkEsJabwUZhDhuFGWwUZobX1lWvbapfy6t+rjCD7W2v5WbiLzbLAEQGwcHBRq+Li4sxZ84c/Pzzz8jIyEBlZSVKS0uRkpJyx/P06NHD8L2VlRVsbW0Nj5kgIqKadDoB2UUapOSVGLbUqi0lrwTZRZr7fg9LC5lRYKkRYKoCin6r/bWlRePeeRATA1AjUJrLcGZehCjv25isrKyMXr/77rvYvXs3PvvsMzzwwANQKpV44YUXUF5efsfzmJubG72WSCTQ6RrvXyBERK1RUVkFUvNKkZJXgrT8EqOwk5ZfeteeGmu5Gdo7KGFvaa4PMLf0qNwxwMjNYSWXwUzGid+3YgBqBBKJpFFvRbUUf/31F8aOHYthw4YB0PcIXb16VdyiiIhaqEqtDhmFZYZeG0NPTn4pUvNKkKe+8z8eZVIJPO2V8HJUooOjJbwcLfVfHfRf7S3N20zvS0vQ9j61qdF06tQJ27Ztw+DBgyGRSDBz5kz25BCRyRIEAYWlFVW3p0qNblWl5JXgekEpKu8yUNjB0tw43FR97eBoCXc7BXtpmhEDENVpwYIFGDduHPr27QsnJyf861//gkqlErssIqImU16pQ3pBaa3jcFLySlBUVnnH4y1kUrR3VBp6bYzDjhI2CvM7Hk/NRyIIgrjz0FoglUoFOzs7FBYWwtbW1uhnZWVluHLlCnx8fKBQiLeAEzU+/m6J2j5BEJBbXH5zHM4N40HHGaoy3O1T0dlGbhRuvBz0t6w6tLOEq40CUilvU4nlTp/ft2MPEBERtTlanYAruWqczVDhbIYKF7KKDT05d1u3TWkuuxluqsbjVG/tHSyhtBB/CjfdPwYgIiJq1QpLK3CuKuiczSjC2UwVzmcWQVPHrCqJBHC3VRiNv+nQTh9uOjhawsnagoONTQADEBERtQo6nYBreSWGXp3qwJNeUFpre6W5DP5uNujibosANxt4O1mhg6MlPOwVLWIhPhIXAxAREbU4xZpKQ6/OmYwinKvq1Skpr/32lae9El3c9WGneuvoaMnxOFQnBiAiIhKNTicgLb8UZ6rCzrlMfa9OSl5Jre3lZlJ9r46brSHwBLjbwk7J2VXUMAxARETULErKK3EuswjnMooMt7DOZRahWFP71HI3W8VtvTo28G5nxbVyqFGIHoCWLVuGTz/9FJmZmQgMDMSSJUsQGhpaa9uKigrExcXh66+/Rnp6Ovz9/fHxxx8bPWSzqKgIM2fOxPbt25GdnY2ePXti0aJFCAkJaa5LIiIyaYIg4HphGc5erxqnU9Wrc/WGutYp5hYyKTq5Wt8MOlXjdhysLJq/eDIZogagzZs3IyYmBl9++SXCwsKwcOFCRERE4Pz583BxcanRPjY2FuvXr8eqVasQEBCAXbt2YdiwYThw4AB69uwJAHj11Vdx+vRprFu3Dh4eHli/fj3Cw8Nx5swZeHp6NvclEhG1aWUVWlzIKjIMSD6TocK5DBVUdSwY6GwjNwo5Xdxt4etsBXP26lAzE3UhxLCwMISEhGDp0qUAAJ1OBy8vL0yePBnTpk2r0d7DwwMzZszAxIkTDfsiIyOhVCqxfv16lJaWwsbGBj/88AMGDRpkaNO7d28MGDAA//73v+tVFxdCNE383RLVTRAEZKk0VYOSb96+Ss4pRm1PfzCTSvCAi7Xh1lV12HGyljd/8WQyWsVCiOXl5UhKSsL06dMN+6RSKcLDw3Hw4MFaj9FoNDU+mJRKJfbv3w8AqKyshFarvWMbunePPfYYgoKCsHDhQgCAt7c3pk6diqlTp9Z5jEQiwfbt2zF06ND7eu/GOg8R3ZlaU4n0glKk55ciraAUV29ZTDC/pKLWYxytLPQhx+3mDKwHXKxhYcZeHWq5RAtAubm50Gq1cHV1Ndrv6uqKc+fO1XpMREQEFixYgP79+8PPzw/x8fHYtm0btFr9tEgbGxv06dMHH3zwAbp06QJXV1d8++23OHjwIB544IE6a9FoNNBoNIbXbfF5V4MHD0ZFRQV27txZ42d//vkn+vfvjxMnTqBHjx71PmdiYiKsrKwas0zMmTMHO3bswPHjx432Z2RkwMHBoVHfi8gUFZZWIC2/BOn5pUgvKEVafnXY0e+rK+QA+qeV+zpZGQ1K7upuC2cbORcOpFZH9EHQDbFo0SJMmDABAQEBkEgk8PPzQ3R0NFavXm1os27dOowbNw6enp6QyWTo1asXRo0ahaSkpDrPGxcXh7lz5zbHJYhm/PjxiIyMRFpaGtq3b2/0szVr1iA4OLhB4QcAnJ2dG7PEO3Jzc2u29yJqrQRBQJ663DjY5JcYvS6qY8bVrWwVZmjvYAlPB/1DPQOqgs4DLtZQmHMBQWobRAtATk5OkMlkyMrKMtqflZVV54eds7MzduzYgbKyMty4cQMeHh6YNm0afH19DW38/Pywd+9eqNVqqFQquLu7Y+TIkUZtbjd9+nTExMQYXqtUKnh5ed3nFbYszz77LJydnbF27VrExsYa9hcXF2PLli2YNm0aRo0ahX379iE/Px9+fn54//33MWrUqDrPefstsIsXL2L8+PFISEiAr68vFi1aVOOYf/3rX9i+fTvS0tLg5uaG0aNHY9asWTA3N8fatWsNQbT6X5Nr1qzB2LFja9wCO3XqFKZMmYKDBw/C0tISkZGRWLBgAaytrQEAY8eORUFBAR5++GF8/vnnKC8vx4svvoiFCxfC3JzrhVDrpNMJyCnWIO2WYKMPOaWG7+/2nCsAaGdlAU8HJdo7KOFpr9SHHXslPB30my2fWE4mQLQAZGFhgd69eyM+Pt7woabT6RAfH49Jkybd8ViFQgFPT09UVFRg69atGDFiRI02VlZWsLKyQn5+Pnbt2oVPPvmkzvPJ5XLI5fcxME8QgIraF+1qUuaW+ofa1IOZmRnGjBmDtWvXYsaMGYaAsWXLFmi1Wrz88svYsmUL/vWvf8HW1hY///wzXnnlFfj5+dW5LMGtdDodnn/+ebi6uuLw4cMoLCysdWyQjY0N1q5dCw8PD5w6dQoTJkyAjY0N3nvvPYwcORKnT5/Gzp07sWfPHgCAnZ1djXOo1WpERESgT58+SExMRHZ2Nl599VVMmjQJa9euNbT7/fff4e7ujt9//x2XLl3CyJEjERQUhAkTJtTrz4youVVqdchUldV5e+p6QRnKtbU/3+pWrrbym8HGEHL0m4e9EpYWrarzn6hJiPpfQUxMDKKiohAcHIzQ0FAsXLgQarUa0dHRAIAxY8bA09MTcXFxAIDDhw8jPT0dQUFBSE9Px5w5c6DT6fDee+8Zzrlr1y4IggB/f39cunQJ//znPxEQEGA4Z5OoKAHmezTd+evy/nXAov5jcMaNG4dPP/0Ue/fuxWOPPQZA38MSGRmJjh074t133zW0nTx5Mnbt2oXvvvuuXgFoz549OHfuHHbt2gUPD/2fxfz58zFgwACjdrf2Pnl7e+Pdd9/Fpk2b8N5770GpVMLa2hpmZmZ3vOW1ceNGlJWV4ZtvvjGMQVq6dCkGDx6Mjz/+2DCuzMHBAUuXLoVMJkNAQAAGDRqE+Ph4BiASjaZSi4yCslt6bkqQdksvTqaqDNraplTdQioB3O30PTXtq4KNPuRYor2DEu58zhVRvYgagEaOHImcnBzMmjULmZmZCAoKws6dOw0fYCkpKZBKb84iKCsrQ2xsLJKTk2FtbY2BAwdi3bp1sLe3N7QpLCzE9OnTkZaWBkdHR0RGRuLDDz/kbQ8AAQEB6Nu3L1avXo3HHnsMly5dwp9//ol58+ZBq9Vi/vz5+O6775Ceno7y8nJoNBpYWlrW69xnz56Fl5eXIfwAQJ8+fWq027x5MxYvXozLly+juLgYlZWVd52qWNt7BQYGGg3A7tevH3Q6Hc6fP2/4+9OtWzfIZDc/CNzd3XHq1KkGvRdRQ+l0Av6+rsLJ9AKj21Np+SXILtLUuhDgrcxlEnjY37w9VR1sqm9ZudkquBIyUSMQvR900qRJdd7y+uOPP4xeP/roozhz5swdzzdixIhab4k1KXNLfW9MczOvXzi51fjx4zF58mQsW7YMa9asgZ+fHx599FF8/PHHWLRoERYuXIju3bvDysoKU6dORXl5eaOVe/DgQYwePRpz585FREQE7OzssGnTJnz++eeN9h63uj30SiQS6HR3v31A1FD56nLsu5iDvedzsO9iDnKL6/7vRmEurRpvY3nLGJzqwGMJFxs5H+BJ1AxED0BtgkTSoFtRYhoxYgSmTJmCjRs34ptvvsEbb7wBiUSCv/76C0OGDMHLL78MQD+m58KFC+jatWu9ztulSxekpqYiIyMD7u7uAIBDhw4ZtTlw4AA6duyIGTNmGPZdu3bNqI2FhYVhWYM7vdfatWuhVqsNvUB//fUXpFIp/P3961Uv0f3Q6QScSi/EH+dz8MeFbJxILTBaDNDKQoZgb0d0bGdpCDbVvTjtrCw4ZZyoBWAAMjHW1tYYOXIkpk+fDpVKhbFjxwIAOnXqhO+//x4HDhyAg4MDFixYgKysrHoHoPDwcHTu3BlRUVH49NNPoVKpjIJO9XukpKRg06ZNCAkJwc8//4zt27cbtfH29saVK1dw/PhxtG/fHjY2NjUGqI8ePRqzZ89GVFQU5syZg5ycHEyePBmvvPJKjXWliBpLnrocf17MwR/nc7DvQg5uqI17efxdbfCYvzMe9XdGcEdHLgJI1MIxAJmg8ePH46uvvsLAgQMNY3aqx1ZFRETA0tISr732GoYOHYrCwsJ6nVMqlWL79u0YP348QkND4e3tjcWLFxs9qPa5557D22+/jUmTJkGj0WDQoEGYOXMm5syZY2gTGRmJbdu24fHHH0dBQYFhGvytLC0tsWvXLkyZMgUhISFG0+CJGotWJ+BkWkFVL08OTqYVGI3fsZabod8D7fCYvwse7ewMD3uleMUSUYOJ+iywlorPAjNN/N3SjWIN9t3Sy3P7qsgBbjZ4zN8Fj/k7o1cHB/byELUwreJZYEREYtPqBJyo6uXZez4bJ9MLjXp5bORmeLiTk/7WVmcXuNkxGBO1FQxARGRScos12HdB38vz58WavTxd3G3xmL8zHuvsjF4dHWDOKedEbRIDEBG1aVqdgOOp+fqxPOdzcCrdeFybjcIMj3RywmOdXfCovzNcbdnLQ2QKGICIqM3JKdJg74Uc/HE+G39ezEVhqXEvTzePql4efxf09LLnwoJEJogB6B5x7Hjbw99p61Wp1eF4aoFhXZ7T6Sqjn9sqzPBIZ/1trUc7O8OFvTxEJo8BqIGqVxcuKSmBUslpr21JSYn+gbZ8bErrkK0qwx8X9Ksv/3kxB6qySqOfP+hpi8c662dsBbGXh4huwwDUQDKZDPb29sjOzgagX5OGq7q2boIgoKSkBNnZ2bC3tzd6fhi1HJVaHY6mFOCP89n443wOzmQY9/LYKc3Rv6qX55HOTnCxYS8PEdWNAegeVD+pvDoEUdtgb29/x6fQU/PLUpVhb9VtrT8v5qLotl6eHu3t9Le1/F0Q5GUPGZ+hRUT1xAB0DyQSCdzd3eHi4oKKioq7H0Atnrm5OXt+WoAKrQ5Hr+Xjj6pp6mdv6+WxtzRH/07OeMzfGf07O8PJWl7HmYiI7owB6D7IZDJ+aBLdh7IKLY6nFiDhSh4SruQh6Vo+SituPgxXIgF6eNrh0arVlwPbs5eHiBoHAxARNZuisgokXcs3BJ6TaYUo1+qM2jhaWaB/Jyc85u+CRzo5oR17eYioCTAAEVGTyVOXG8JO4tU8/H29ELrbVhtwsZEj1McRYT6OCPVph04u1pCyl4eImhgDEBE1mozCUkPgSbiSh4vZxTXadHC0RKiPoyH0dHDkTEoian4MQER0TwRBwNUbJUi8kofDV/KQcPUGUvNKa7Tr7GpdFXjaIdTbkQ8UJaIWgQGIiOpFpxNwIbsICdWB50oecoo0Rm2kEuBBTzuEeOt7eEK8HeFoZSFSxUREdWMAIqJaVWh1+Pu6CglXblSN4cmv8UwtC5kUgV52hh6eXh3sYaPgStpE1PIxABERgJtT0hOv5CHhqn5Kekm51qiNpYUMvTs6ILSqhyfQyx4Kcy4FQUStDwMQkYkq1lRWTUnX9/CcSK05Jd1OaY4Q7+oZWo7o6mELcz5Ti4jaAAYgIhORpy5H4tWbM7Rqm5LubCM3hJ1QH0d0drHhlHQiapMYgIjaqMzCMhw2jN/Jw4WsmlPSvRyVCPVuZwg9HdtxSjoRmQYGIKI2QBAEXLtRgoRbenhS8kpqtOvkYm3o3Qn1cYS7nVKEaomIxMcARNTKHbmahxnbT+N8VpHRfqkE6OZhZwg7nJJORHQTAxBRK6Uqq8AnO89h/aEUADenpFevwdO7owOnpBMR1YEBiKgV+vXvTMz64W9kqsoAACODvTB9YADsLdnDQ0RUHwxARK1IdlEZ5vz4N/53KhMA4N3OEvOf746+fk4iV0ZE1LowABG1AoIgYHNiKub/7yxUZZWQSSV4rb8vpjzZiQsREhHdAwYgohbuSq4a07edxKHkPABAd087fBTZHd087ESujIio9WIAImqhKrQ6rPozGQv3XER5pQ4KcynefdofY/t6w4yrMRMR3RcGIKIW6GRaAf619RTOZqgAAI90csKHQ7ujQztLkSsjImobGICIWpCS8kos+PUCVv91BToBsLc0x8xBXfF8L0+u0ExE1IgYgIhaiL0XcjBj+ymk5ZcCAIYEeWDms13hZC0XuTIiorZH9IEEy5Ytg7e3NxQKBcLCwpCQkFBn24qKCsybNw9+fn5QKBQIDAzEzp07jdpotVrMnDkTPj4+UCqV8PPzwwcffABBEOo4K5G48tTliNl8HFGrE5CWXwpPeyXWRIdg0Ys9GX6IiJqIqD1AmzdvRkxMDL788kuEhYVh4cKFiIiIwPnz5+Hi4lKjfWxsLNavX49Vq1YhICAAu3btwrBhw3DgwAH07NkTAPDxxx9j+fLl+Prrr9GtWzccOXIE0dHRsLOzw1tvvdXcl0hUJ0EQ8OOJ65j7f2eQpy6HRAKM7euNd5/2h5WcnbNERE1JIojYNRIWFoaQkBAsXboUAKDT6eDl5YXJkydj2rRpNdp7eHhgxowZmDhxomFfZGQklEol1q9fDwB49tln4erqiq+++qrONnejUqlgZ2eHwsJC2Nra3s8lEtUqLb8EM7afxt4LOQAAf1cbfBTZHT07OIhcGRFR69WQz2/RboGVl5cjKSkJ4eHhN4uRShEeHo6DBw/WeoxGo4FCoTDap1QqsX//fsPrvn37Ij4+HhcuXAAAnDhxAvv378eAAQPqrEWj0UClUhltRE1BqxOwev8VPP3FPuy9kAMLmRTvPt0Z/zf5YYYfIqJmJFo/e25uLrRaLVxdXY32u7q64ty5c7UeExERgQULFqB///7w8/NDfHw8tm3bBq1Wa2gzbdo0qFQqBAQEQCaTQavV4sMPP8To0aPrrCUuLg5z585tnAsjqsO5TBX+tfUUTqQWAABCfRwR93x3+Dlbi1sYEZEJEn0QdEMsWrQInTp1QkBAACwsLDBp0iRER0dDKr15Gd999x02bNiAjRs34ujRo/j666/x2Wef4euvv67zvNOnT0dhYaFhS01NbY7LIRNRVqHFZ7vO49nF+3EitQA2cjPMH9YdmyY8xPBDRCQS0XqAnJycIJPJkJWVZbQ/KysLbm5utR7j7OyMHTt2oKysDDdu3ICHhwemTZsGX19fQ5t//vOfmDZtGl588UUAQPfu3XHt2jXExcUhKiqq1vPK5XLI5ZxtQ43vUPINvL/tFJJz1QCAiG6umDfkQbjaKu5yJBERNSXReoAsLCzQu3dvxMfHG/bpdDrEx8ejT58+dzxWoVDA09MTlZWV2Lp1K4YMGWL4WUlJiVGPEADIZDLodLrGvQCiOygsrcD0bafw4spDSM5Vw8VGji9f7oUVrwQz/BARtQCizrWNiYlBVFQUgoODERoaioULF0KtViM6OhoAMGbMGHh6eiIuLg4AcPjwYaSnpyMoKAjp6emYM2cOdDod3nvvPcM5Bw8ejA8//BAdOnRAt27dcOzYMSxYsADjxo0T5RrJ9Ow8nYlZP5xGdpEGADAqtAOmDQiAndJc5MqIiKiaqAFo5MiRyMnJwaxZs5CZmYmgoCDs3LnTMDA6JSXFqDenrKwMsbGxSE5OhrW1NQYOHIh169bB3t7e0GbJkiWYOXMm3nzzTWRnZ8PDwwP/+Mc/MGvWrOa+PDIxWaoyzPrhNHb9rb+t6+tkhbjnuyPMt53IlRER0e1EXQeopeI6QNQQOp2ATYmpiPvfWRRpKmEmleD1R/0w6YkHoDCXiV0eEZHJaMjnN5ebJboPl3OKMX3bKSRcyQMABHrZ4+PI7ghwY3AmImrJGICI7kF5pQ4r913G4t8uobxSB0sLGd592h9Rfb0hk/Kp7URELR0DEFEDHUvJx/Rtp3AuswgA8GhnZ/x76IPwcrQUuTIiIqovBiCielJrKvHZr+ex9sBVCALgaGWB2YO74rlAD0gk7PUhImpNGICI6uH389mI3X4a6QWlAIDne3oi9tmucLSyELkyIiK6FwxARHdwo1iDeT+dwQ/HrwMA2jsoMX9Yd/Tv7CxyZUREdD8YgIhqIQgCth9Lxwc/nUF+SQWkEmBcPx/EPN0Zlhb8z4aIqLXj/8mJbpOaV4L3t5/CnxdzAQBd3G3xcWR39GhvL25hRETUaBiAiKpUanVYe+AqPv/1AkortLAwk2JqeCdMeMQX5jLRHptHRERNgAGICMCZ6ypM23YSJ9MKAQAP+Toi7vke8HGyErkyIiJqCgxAZNLKKrRYFH8RK/clQ6sTYKsww4xBXTAi2ItT24mI2jAGIDJZyTnFePWbI0jOUQMABnV3x+znusLFRiFyZURE1NQYgMgkJV3Lw6tfH0F+SQVcbeX4YMiDeLqbm9hlERFRM2EAIpOz83Qmpmw6Bk2lDj3a2+GrqBA428jFLouIiJoRAxCZlDV/XcG8n85AEIAnA1yw5KWeXNeHiMgE8f/8ZBJ0OgHz/3cW/91/BQAwOqwD5j7XDWac3k5ErYFOBxRnAUXXAYkUkFnoN6nZze9l5je/Ss0ATuS4IwYgavPKKrR457sT+PlUBgDgvWf88cajfpzlRUQthyAAJXlAwTX9ln/b14JUQKtp2DnvFpIM31eHptv31XJcjTbmt52zrvespY25EpDbNM2fZz0wAFGbVlBSjgnfHEHi1XyYyyT4bHgghgR5il1W48v6GygrBNwDAQuuXUTUImmKbgs2KcYhp7z4zsdLZICNGwAJoC3Xb7rKm9/frq79LUW354Hha0R7ewYgarNS80oQtSYByTlq2CjMsOKV3ujr5yR2WY1HpwMu7AQOLAFSDuj3SWSAa1egfcjNzdEPkPJWH1GTqygDClOrAs3VW3pvUvTfl+bd/RzWboBDR8C+421fOwC27fW9MrURhFvCUEXVVn7zta7ilp9V7680bqMtr2p327HaWo7V1XJsbW1rnK/6OI2+N0hEDEDUJp1MK8C4tUeQW6yBh50Ca6JD4e8mXldro6ooBU5sAg4uBW5c0u+TmgNWzvrxAZmn9NuR1fqfKeyB9sFVgSgY8OwNKB1EK5+o1dJWAqq02ntv8q8BxZl3P4fS8WagMYQbb/1XOy/A/B7XIZNIbt5qag0EQb+JiAGI2pzfz2XjzQ1HUVqhRRd3W6wZGwI3uzawuKH6BpD4XyBhJVCif1Ar5HZAcDQQ9g/A1gNQXQfSjgBpifqv148BZQXApT36rZpT55uBqH0I4Nyl7n9ZEpmK6oHGRmNvbvm+MB0QtHc+h4W1ce+NfQfj7xW2zXMtLZ1EIvogbYkgiBzBWiCVSgU7OzsUFhbC1pZ/WVuTjYdTMPOH09DqBDzSyQn/Gd0LNopW8i+iuty4DBxcBhzfAFSW6ffZdQD6vAn0fPnOgwi1FfrxQdWBKC0RyLtcs525FeDZqyoQheq/Wrs0zfUQiaUxBhrLLG7rvbnlFpW9N2DpKPoHuylryOc3A1AtGIBaH0EQ8Nmv57Hsd/2H+wu92yPu+e6t+ynuKYeBA4uBcz8DqPrP1D0I6PcW0GXIvffYqG8A6UlVoShR/71GVbOdfUfjsURu3QEzi3u9GqKmVVGm770pzgKKMoCiLP0tqeqvqgz9bavyojufRyID7DyremxuDzkdAWtXjqlrwRiA7hMDUOtSXqnDv7aexPZj6QCAKU92wtTwTq1zmrtOC5z7ST+wOS3x5v7OzwB9JwMd+zX+vy51OiD3ApCWcLOnKPssDKGrmkyun2V2660zu/b81y41LU1xVajJvBloijJu2Vf1tayg/ue8daDxrbeoHDoCtp6tZxwN1cAAdJ8YgFoPVVkF3lifhL8u3YBMKsH8YQ9iZEgHsctquHI1cHyjfmBz/lX9PpkFEPgi0GcS4OzfvPWUqYDrR41vnZXcqNnO2u2WAdYhgEcQp+HT3QmCPrDc3ktj+Jp5M9zcbWr4rWRywMZV//eyxlf3qttUXvr1Z6hNYgC6TwxArUNGYSmi1yTiXGYRrCxk+M/LvfFoZ2exy2qY4mz9oObE/wKl+fp9Sgcg5FUgZIL+f94tgSAA+VduGWCdqJ9ppqs0bieRAa7djG+dtfNjL5Gp0On0U70NASbTuJfm1q/V49nqw9xK/9+Cjbv+FpSNW+1flQ78u2biGIDuEwNQy3c2Q4XoNYnIVJXBxUaO1WND8KCnndhl1V/OeX1vz4lNNxcqc/AB+kwEgl5qHb0oFaVAxombgSjtCKBKr9lO6QB43j4N377Zy6X7oK0E1Dl199JUfy3OqhmK70Rhd1svjdttoabqZyKuFkytCwPQfWIAatn2X8zF6+uTUKypxAMu1lgbHYL2DpZil3V3ggBc3a8f33Nx18397UOAvm8BAYMAqUy8+hpDYTqQfts0/Nr+pe/kbzyWyKVL67/2lkIQgEoNUFGiv31UXqK/xVpeXLVPbbxVVH9fclubqmPLCvXLLgi6+tdg6VR7L82tocbalbeiqNExAN0nBqCWa2tSGv619SQqdQLCfByx8pVg2Fm28AGL2krgzA598Mk4XrVTog88fd8COoSJWFwT01YAWaeNb53lJddsZ2ENePTUhyGnzlXPJZLpnydk2KpeS2Q19xk26W2vaztO1jJukwiCPhzWFTyMwsmtgaU62NQWWqpe322tmnshkepDS523oKoDjgsHEZNoGIDuEwNQyyMIApb+dgmf774AABgc6IHPhveA3KwF9xpoioCj64BDy4HCFP0+MwUQNFp/q6udn7j1iUWdazwNPy3p7lOTG5uktnB1h2AluT1Y1db2tmMEXS2hpcT4dUN6Ve6FmQIwt9QHTAsrwMJS/9Xc6pbXVT8ztKtqY2Gt3ye30YccKyf20lGL15DPby79Si1epVaH2B2nsSkxFQDw+qN+eC/CH1JpC/hXfG1U14HDK4AjawBNoX6fpRMQ+hoQMl7/QWLKrJyAzhH6DdBP/c+9oA9DqQn6cUQ6bdVWeXMTatlneH3710r9M4jqImgBrbbhT9duKmZK40BiXh1CbtnqE1rMb21vydW9ie6A/3VQi6bWVGLixqP443wOpBJg7nPd8Eofb7HLql3W38CBpcCpLTc/fNt1AvpOAnqM5HiHukhl+jFALl2AXmMa99w63S3h6fbQdOvruoLVrcfeLXzd9r1EcueAcmtQYc8KUbNjAKIWK7uoDOPWJuJ0ugoKcymWjOqFp7q2kGnh1QQBSP5dP77n8m8393fsp1+4sFMEV40Vk1QKSLl6NRHVxABELdKl7CJErU5EekEp2llZ4L9RwejZoQU9wbyyHPh7mz74ZJ3W75NIga5DgD6Tgfa9xa2PiIjuqEX803TZsmXw9vaGQqFAWFgYEhIS6mxbUVGBefPmwc/PDwqFAoGBgdi5c6dRG29vb0gkkhrbxIkTm/pSqBEkXMlD5PKDSC8ohXc7S2x7s2/LCT9lhcBfi4BFgcD2f+jDj7kVEPY68NYxYPhahh8iolZA9B6gzZs3IyYmBl9++SXCwsKwcOFCRERE4Pz583Bxqfk06tjYWKxfvx6rVq1CQEAAdu3ahWHDhuHAgQPo2bMnACAxMRFa7c1poKdPn8ZTTz2F4cOHN9t10b356eR1xGw+gXKtDr062OO/USFwtGoBtzAKUoHDXwJJX9+csWTtCoT9A+gdrX8CNBERtRqiT4MPCwtDSEgIli5dCgDQ6XTw8vLC5MmTMW3atBrtPTw8MGPGDKPenMjISCiVSqxfv77W95g6dSp++uknXLx4sV4PyOQ0+OYnCAJW/ZmM+f87BwCI6OaKRS/2hMJc5MGh14/rb3P9vf3m2irOXfTje7q/AJjJRS2PiIhuajXT4MvLy5GUlITp06cb9kmlUoSHh+PgwYO1HqPRaKBQKIz2KZVK7N+/v873WL9+PWJiYuoMPxqNBhrNzemwKpWqoZdC90GrEzDv//7G1wevAQDG9vXGzGe7QibWNHedDri0BziwGLj65839Po/qFy584MmWsZAeERHdM1EDUG5uLrRaLVxdjWf2uLq64ty5c7UeExERgQULFqB///7w8/NDfHw8tm3bZnTL61Y7duxAQUEBxo4dW2cdcXFxmDt37j1fB9270nItpmw6hl/PZAEAYgd1wfiHferVU9foKjXAye/0z+jKqfr7J5EBD0bqp7K7BzZ/TURE1CREHwPUUIsWLcKECRMQEBAAiUQCPz8/REdHY/Xq1bW2/+qrrzBgwAB4eHjUec7p06cjJibG8FqlUsHLy6vRaydjN4o1ePWbIziWUgALmRQLRgbi2R51/56aTEkecGS1fvFCdbZ+n4UN0DtKP7jZnn8XiIjaGlEDkJOTE2QyGbKysoz2Z2Vlwc3NrdZjnJ2dsWPHDpSVleHGjRvw8PDAtGnT4OvrW6PttWvXsGfPHmzbtu2OdcjlcsjlHMvRnK7mqjF2TQKu3iiBndIcq8YEI9SnGQYSl5cA+VeAG5f1z6TKOQec+UH/aAIAsPEAHnpDH34Urejp8kRE1CCiBiALCwv07t0b8fHxGDp0KAD9IOj4+HhMmjTpjscqFAp4enqioqICW7duxYgRI2q0WbNmDVxcXDBo0KCmKJ/u0bGUfIz/+gjy1OVo76DE2uhQPOBi3XhvUFEK5F0B8qpCTnXYyUvWP2ahNq7dgX5vAd2G8UGOREQmQPRbYDExMYiKikJwcDBCQ0OxcOFCqNVqREdHAwDGjBkDT09PxMXFAQAOHz6M9PR0BAUFIT09HXPmzIFOp8N7771ndF6dToc1a9YgKioKZmaiXyZV+fXvTLy16RjKKnTo7mmHr8YGw8VGcfcDb1dRZtyTk3e56vsrgCrtzscq7ABHP8DRV/9A0o79AJ/+HNhMRGRCRE8GI0eORE5ODmbNmoXMzEwEBQVh586dhoHRKSkpkN7yKIGysjLExsYiOTkZ1tbWGDhwINatWwd7e3uj8+7ZswcpKSkYN25cc14O3cE3B69i9o9/QxCAx/2dsfSlXrCS3+GvYEUZkH/1tp6cqpBTmAbgDis4yO2Adr76kOPopw861aHH0pFhh4jIxIm+DlBLxHWAGpdOJ+DjneewYl8yAGBUqBc+GPIgzGRS/cyr/Ku19+QUpuLOIcf2Zi+OUdDxBSzbMeQQEZmYVrMOELV9mkot/vVdEk6dOo4npZmI7iKgn0U8JBuqAk9hGiDo6j6BhU1VT84tt6yqv7dyYsghIqJ7wgBEjaOyHCi4ZtSTU5FzCQWp5/B5ZRZk8qqenMu1HGthXXdPjpUzQw4RETU6BiBqOJ1Wv2BgetLN8TkFKTV6cswBuAKABNCaWULm5FezJ6edH0MOERE1OwYgahh1LrD1VSD595o/M7cCHH1RaOmF7dfk+FvjDJWyA959aQA6+fgx5BARUYvBAET1l5oAfBcFFF0HzC2B4HGAs//NnhxrV/xxIQdvbjiKknItAtxssCY6BO52SrErJyIiMsIARHcnCPrHRPw6A9BVAu06ASPXAS5djJptTkzB+9tPQ6sT0O+Bdlj+cm/YKrioIBERtTwMQHRnmiLgx8nA39v1r7sNA55bAshtDE0EQcAXey5icfxFAMDzvTzx0fM9YGEmre2MREREomMAorplnwU2vwLcuAhIzYCnPwTC/mE0lqe8Uofp205h61H96suTn3gAMU91Fudp7kRERPXEAES1O7kF+L+39A8JtfEARnwNeIUaNSkqq8Ab649i/6VcyKQS/HvogxgV2kGkgomIiOqPAYiMVWqAXe8Dif/Vv/Z9DIj8Sr/o4C0yC8swdk0CzmUWwdJChmUv9cLjAS7NXy8REdE9YACimwpS9LO8rh/Vv+7/T+Cx6YBUZtSssLQCkcsPIL2gFE7WcqwZG4Lu7e1EKJiIiOjeMACR3sU9wLZXgdJ8QOkAPL8K6PRUrU3jz2YhvaAUHnYKbP5HH3g5WjZzsURERPeHAcjU6bTA3o+BvZ8AEACPnsDwrwGHjnUekng1DwDwbKAHww8REbVKDECmTH0D2Dr+5qrOweOAZz4CzOR3POzwFX0ACvV2bOoKiYiImgQDkKlKTQS2RAGqdMBMCQxeBASOvOthucUaJOeoAQDB3g5NXSUREVGTYAAyNYIAJKwEds0AdBVAuweAEesA1671OjyxqvfH39UG9pYWTVkpERFRk2EAMiWaYv3aPqe36l93HQI8txRQ2Nb7FAlV439CfXj7i4iIWi8GIFORfQ747hUg94J+VeenPgAeeqPBT2hPqOoBCmEAIiKiVowByBSc+h748S2gQg3YuAPD1wIdHmrwaYrKKnA2QwWAA6CJiKh1YwBqyyo1+rE+iav0r336A5GrAWvnezpd0rV86ASgg6Ml3OwUjVgoERFR82IAaqsKUvWzvNKT9K8feRd4/P0aqzo3RPXtL47/ISKi1o4BqC26tAfYOgEozQMU9sDzK4HOEfd92uoFEHn7i4iIWjsGoLZEp9Wv6Lz3YwAC4B4EjPjmjqs611dZhRYnUgsBcAA0ERG1ftKGHuDt7Y158+YhJSWlKeqhe6W+AWx4Adj7EQAB6B0NjNvVKOEHAE6kFqBcq4OzjRze7fj4CyIiat0aHICmTp2Kbdu2wdfXF0899RQ2bdoEjUbTFLVRfaUdAVb0By7/pl/VedgKYPBCwLzxBion3PL4C0kDp84TERG1NPcUgI4fP46EhAR06dIFkydPhru7OyZNmoSjR482RY1UF0EADq8EVj8DqNIARz9gQjwQ+GKjvxUXQCQiorakwQGoWq9evbB48WJcv34ds2fPxn//+1+EhIQgKCgIq1evhiAIjVkn3U5TrH+Q6S//1D/SostzwGt/AK7dGv2tKrU6HL2WDwAI4QBoIiJqA+55EHRFRQW2b9+ONWvWYPfu3XjooYcwfvx4pKWl4f3338eePXuwcePGxqyVquWcBza/AuSeByQy4OkPgIfebPCqzvV1JkMFdbkWtgoz+LvZNMl7EBERNacGB6CjR49izZo1+PbbbyGVSjFmzBh88cUXCAgIMLQZNmwYQkJCGrVQqnL7qs4vrAE69mnSt6we/xPs7QiZlON/iIio9WtwAAoJCcFTTz2F5cuXY+jQoTA3N6/RxsfHBy++2PjjUExaZTnwayyQsEL/2qc/EPkVYO3S5G9teP4Xb38REVEb0eAAlJycjI4d7zy12srKCmvWrLnnoug2hWnAd1FA+hH960feAR6fcV+rOteXIAg3F0DkAGgiImojGhyAsrOzkZmZibCwMKP9hw8fhkwmQ3BwcKMVRwAuxQNbX61a1dkOGLYS8H+m+d4+uxj5JRVQmEvR3dOu2d6XiIioKTV4FtjEiRORmppaY396ejomTpzYKEURAJ0O+ONjYH2kPvy4BwL/2Nes4Qe4Of29p5cDLMzuedIgERFRi9LgHqAzZ86gV69eNfb37NkTZ86caZSiTF5JHrBtgv6ZXgDQKwoY8EmjLmxYX4nV4394+4uIiNqQBv+TXi6XIysrq8b+jIwMmJk1fFb9smXL4O3tDYVCgbCwMCQkJNTZtqKiAvPmzYOfnx8UCgUCAwOxc+fOGu3S09Px8ssvo127dlAqlejevTuOHDnS4NpEkZakX9X50h79qs5DlwPPLRYl/AA3B0CHMQAREVEb0uAA9PTTT2P69OkoLCw07CsoKMD777+Pp556qkHn2rx5M2JiYjB79mwcPXoUgYGBiIiIQHZ2dq3tY2NjsWLFCixZsgRnzpzB66+/jmHDhuHYsWOGNvn5+ejXrx/Mzc3xyy+/4MyZM/j888/h4ODQ0EttXoIAJKwCVkcAhamAoy/w6h4g6CXRSkrLL8H1wjKYSSXo2cFetDqIiIgam0Ro4JLN6enp6N+/P27cuIGePXsCAI4fPw5XV1fs3r0bXl5e9T5XWFgYQkJCsHTpUgCATqeDl5cXJk+ejGnTptVo7+HhgRkzZhiNNYqMjIRSqcT69esBANOmTcNff/2FP//8syGXZUSlUsHOzg6FhYWwtbW95/PUW7ka+L8pwKkt+tddBgNDlukHPYto29E0xHx3AoFe9vhhYj9RayEiIrqbhnx+N7gHyNPTEydPnsQnn3yCrl27onfv3li0aBFOnTrVoPBTXl6OpKQkhIeH3yxGKkV4eDgOHjxY6zEajQYKhfGtIKVSif379xte//jjjwgODsbw4cPh4uKCnj17YtWqVQ28ymaUcwFY9YQ+/EhkwNP/BkasEz38ADBMf+ftLyIiamvu6VEYVlZWeO211+7rjXNzc6HVauHq6mq039XVFefOnav1mIiICCxYsAD9+/eHn58f4uPjsW3bNmi1WkOb5ORkLF++HDExMXj//feRmJiIt956CxYWFoiKiqr1vBqNxuiJ9iqV6r6urd5ObwN+nAyUFwPWbsDwNUDHvs3z3vVwmAsgEhFRG3XPzwI7c+YMUlJSUF5ebrT/ueeeu++i6rJo0SJMmDABAQEBkEgk8PPzQ3R0NFavXm1oo9PpEBwcjPnz5wPQz047ffo0vvzyyzoDUFxcHObOndtkdddQWQ7sngkc/lL/2vsR/arONq53Pq4Z5RZrkJyjBgCEeLfw8VNEREQNdE8rQQ8bNgynTp2CRCIxPPVdUvUgzlt7Y+7EyckJMpmsxoyyrKwsuLm51XqMs7MzduzYgbKyMty4cQMeHh6YNm0afH19DW3c3d3RtWtXo+O6dOmCrVu31lnL9OnTERMTY3itUqkadDuvQQrTgS1jgbSq2W4Pvw08HgvI7jmLNokjVbe//F1tYG9pIXI1REREjavBY4CmTJkCHx8fZGdnw9LSEn///Tf27duH4OBg/PHHH/U+j4WFBXr37o34+HjDPp1Oh/j4ePTpc+eHeyoUCnh6eqKyshJbt27FkCFDDD/r168fzp8/b9T+woULd3x8h1wuh62trdHWJC7/Dqx4RB9+5HbAi98C4XNaXPgBbt7+4uMviIioLWrwJ+/Bgwfx22+/wcnJCVKpFFKpFA8//DDi4uLw1ltvGU1Jv5uYmBhERUUhODgYoaGhWLhwIdRqNaKjowEAY8aMgaenJ+Li4gDoH7eRnp6OoKAgpKenY86cOdDpdHjvvfcM53z77bfRt29fzJ8/HyNGjEBCQgJWrlyJlStXNvRSG1/JDf3m1gMY8Q3g6CN2RXWqHgDNBRCJiKgtanAA0mq1sLGxAaC/jXX9+nX4+/ujY8eONXpe7mbkyJHIycnBrFmzkJmZiaCgIOzcudMwMDolJQVS6c1OqrKyMsTGxiI5ORnW1tYYOHAg1q1bB3t7e0ObkJAQbN++HdOnT8e8efPg4+ODhQsXYvTo0Q291MbX/QX914BBgLlS3FruoKisAmeu6weCh3IANBERtUENXgfokUcewTvvvIOhQ4fipZdeQn5+PmJjY7Fy5UokJSXh9OnTTVVrs2n2dYBamD/OZ2PsmkR0cLTEvvceF7scIiKiemnI53eDe4BiY2OhVutnB82bNw/PPvssHnnkEbRr1w6bN2++t4qpRUng9HciImrjGhyAIiIiDN8/8MADOHfuHPLy8uDg4GCYCUatGxdAJCKitq5Bs8AqKipgZmZW4zaXo6Mjw08bUVahxYlU/XPeOACaiIjaqgYFIHNzc3To0KHea/1Q63MitQDlWh2cbeTwbmcpdjlERERNosHrAM2YMQPvv/8+8vLymqIeEln17a9Qb/bqERFR29XgMUBLly7FpUuX4OHhgY4dO8LKysro50ePHm204qj53Xz+Fx9/QUREbVeDA9DQoUOboAxqCSq1Ohy9lg8ACPVpJ3I1RERETafBAWj27NlNUQe1AGcyVFCXa2GjMIO/m43Y5RARETWZBo8Borbr1vV/ZFKO/yEiorarwT1AUqn0joNjOUOs9eICiEREZCoaHIC2b99u9LqiogLHjh3D119/jblz5zZaYdS8BEHAEcP4HwYgIiJq2xocgIYMGVJj3wsvvIBu3bph8+bNGD9+fKMURs3rck4x8tTlUJhL0d3TTuxyiIiImlSjjQF66KGHEB8f31ino2ZWPf09yMseFmYcGkZERG1bo3zSlZaWYvHixfD09GyM05EIEqsCEKe/ExGRKWjwLbDbH3oqCAKKiopgaWmJ9evXN2px1HyqB0CHcgA0ERGZgAYHoC+++MIoAEmlUjg7OyMsLAwODlw9uDVKyy/B9cIymEkl6NXRXuxyiIiImlyDA9DYsWOboAwSU3XvTzdPO1haNPivBBERUavT4DFAa9aswZYtW2rs37JlC77++utGKYqaV/UDUMM4/Z2IiExEgwNQXFwcnJycaux3cXHB/PnzG6Uoal5cAJGIiExNgwNQSkoKfHx8auzv2LEjUlJSGqUoaj65xRpczlEDAII7cgwXERGZhgYHIBcXF5w8ebLG/hMnTqBdO06hbm2OVN3+8ne1gYOVhcjVEBERNY8GB6BRo0bhrbfewu+//w6tVgutVovffvsNU6ZMwYsvvtgUNVITql4AMcSHvT9ERGQ6Gjzl54MPPsDVq1fx5JNPwsxMf7hOp8OYMWM4BqgVqh4AzQUQiYjIlDQ4AFlYWGDz5s3497//jePHj0OpVKJ79+7o2LFjU9RHTaiorAJnrqsAcAFEIiIyLfe86EunTp3QqVOnxqyFmlnStXzoBKCDoyXc7BRil0NERNRsGjwGKDIyEh9//HGN/Z988gmGDx/eKEVR86i+/cXp70REZGoaHID27duHgQMH1tg/YMAA7Nu3r1GKouZheP4XB0ATEZGJaXAAKi4uhoVFzenS5ubmUKlUjVIUNb2yCi1OpBYC4ABoIiIyPQ0OQN27d8fmzZtr7N+0aRO6du3aKEVR0zuRWoByrQ5O1nJ4t7MUuxwiIqJm1eBB0DNnzsTzzz+Py5cv44knngAAxMfHY+PGjfj+++8bvUBqGrc+/0sikYhcDRERUfNqcAAaPHgwduzYgfnz5+P777+HUqlEYGAgfvvtNzg6cjBta2FYANGb43+IiMj03NM0+EGDBmHQoEEAAJVKhW+//RbvvvsukpKSoNVqG7VAanyVWh2OXssHwPE/RERkmho8Bqjavn37EBUVBQ8PD3z++ed44okncOjQocasjZrI2YwiqMu1sFGYwd/NRuxyiIiIml2DeoAyMzOxdu1afPXVV1CpVBgxYgQ0Gg127NjBAdCtyOErNwDo1/+RSTn+h4iITE+9e4AGDx4Mf39/nDx5EgsXLsT169exZMmSpqyNmggXQCQiIlNX7wD0yy+/YPz48Zg7dy4GDRoEmUzWaEUsW7YM3t7eUCgUCAsLQ0JCQp1tKyoqMG/ePPj5+UGhUCAwMBA7d+40ajNnzhxIJBKjLSAgoNHqbc0EQUDi1erxPxwATUREpqneAWj//v0oKipC7969ERYWhqVLlyI3N/e+C9i8eTNiYmIwe/ZsHD16FIGBgYiIiEB2dnat7WNjY7FixQosWbIEZ86cweuvv45hw4bh2LFjRu26deuGjIwMw7Z///77rrUtuJxTjDx1OeRmUnT3tBe7HCIiIlHUOwA99NBDWLVqFTIyMvCPf/wDmzZtgoeHB3Q6HXbv3o2ioqJ7KmDBggWYMGECoqOj0bVrV3z55ZewtLTE6tWra22/bt06vP/++xg4cCB8fX3xxhtvYODAgfj888+N2pmZmcHNzc2wOTk53VN9bU319PeeHexhYXbPY+CJiIhatQZ/AlpZWWHcuHHYv38/Tp06hXfeeQcfffQRXFxc8NxzzzXoXOXl5UhKSkJ4ePjNgqRShIeH4+DBg7Ueo9FooFAYP7lcqVTW6OG5ePEiPDw84Ovri9GjRyMlJaXOOjQaDVQqldHWViUanv/F6e9ERGS67qsLwN/fH5988gnS0tLw7bffNvj43NxcaLVauLq6Gu13dXVFZmZmrcdERERgwYIFuHjxoqH3adu2bcjIyDC0CQsLw9q1a7Fz504sX74cV65cwSOPPFJnL1VcXBzs7OwMm5eXV4OvpbUwjP/hAGgiIjJhjXIPRCaTYejQofjxxx8b43R3tGjRInTq1AkBAQGwsLDApEmTEB0dDan05qUMGDAAw4cPR48ePRAREYH//e9/KCgowHfffVfrOadPn47CwkLDlpqa2uTXIYa0/BKkF5TCTCpBr472YpdDREQkGlEHgTg5OUEmkyErK8tof1ZWFtzc3Go9xtnZGTt27IBarca1a9dw7tw5WFtbw9fXt873sbe3R+fOnXHp0qVafy6Xy2Fra2u0tUXV09+7edrB0uKeFgEnIiJqE0QNQBYWFujduzfi4+MN+3Q6HeLj49GnT587HqtQKODp6YnKykps3boVQ4YMqbNtcXExLl++DHd390arvTVKqB7/w+d/ERGRiRN9GlBMTAxWrVqFr7/+GmfPnsUbb7wBtVqN6OhoAMCYMWMwffp0Q/vDhw9j27ZtSE5Oxp9//olnnnkGOp0O7733nqHNu+++i7179+Lq1as4cOAAhg0bBplMhlGjRjX79bUkCRwATUREBOAeH4bamEaOHImcnBzMmjULmZmZCAoKws6dOw0Do1NSUozG95SVlSE2NhbJycmwtrbGwIEDsW7dOtjb2xvapKWlYdSoUbhx4wacnZ3x8MMP49ChQ3B2dm7uy2sxcos1uJyjBgAEd2QPEBERmTaJIAiC2EW0NCqVCnZ2digsLGwz44F2ns7A6+uPwt/VBrve7i92OURERI2uIZ/fot8Co+aRcEU//T2Ej78gIiJiADIVCVf1T4Dn+B8iIiIGIJNQVFaBM9f1q1tzAUQiIiIGIJOQdC0fOgHwclTCzU5x9wOIiIjaOAYgE1C9AGKoN29/ERERAQxAJuHm+j8cAE1ERAQwALV5ZRVanEgtBMAB0ERERNUYgNq4k2mFKNfq4GQth3c7S7HLISIiahEYgNq4hCv66e9hPo6QSCQiV0NERNQyMAC1cQlXqxZA5ANQiYiIDBiA2rBKrQ5JVTPAQny4/g8REVE1BqA27GxGEdTlWtgozBDg1jaeaUZERNQYGIDasMNV43+COzpAJuX4HyIiomoMQG2YYQFETn8nIiIywgDURgmCgMSqAdBcAJGIiMgYA1AbdTmnGHnqcsjNpOjuaS92OURERC0KA1AblXBF3/vTs4M9LMz4ayYiIroVPxnbqOoFEEO9Of2diIjodgxAbdTN8T8cAE1ERHQ7BqA2KC2/BOkFpZBJJejZwV7scoiIiFocBqA2qHr6+4OedrCSm4lcDRERUcvDANQGVQ+ADuXzv4iIiGrFANQGGQZAc/wPERFRrRiA2pjcYg0u56gB6B+BQURERDUxALUxR6rG/3R2tYaDlYXI1RAREbVMDEBtjGH8jw/X/yEiIqoLA1Abk3BVP/4nhAsgEhER1YkBqA0pKqvAmesqAOwBIiIiuhMGoDYk6Vo+dALg5aiEu51S7HKIiIhaLAagNqR6AcRQb05/JyIiuhMGoDYk0TAAmtPfiYiI7oQBqI0oq9DieGoBAA6AJiIiuhsGoDbiZFohyrU6OFnL4eNkJXY5RERELRoDUBtx8/EXDpBIJCJXQ0RE1LK1iAC0bNkyeHt7Q6FQICwsDAkJCXW2raiowLx58+Dn5weFQoHAwEDs3LmzzvYfffQRJBIJpk6d2gSVtxwJV6sfgMrbX0RERHcjegDavHkzYmJiMHv2bBw9ehSBgYGIiIhAdnZ2re1jY2OxYsUKLFmyBGfOnMHrr7+OYcOG4dixYzXaJiYmYsWKFejRo0dTX4aoKrU6JFXNAAvh+j9ERER3JXoAWrBgASZMmIDo6Gh07doVX375JSwtLbF69epa269btw7vv/8+Bg4cCF9fX7zxxhsYOHAgPv/8c6N2xcXFGD16NFatWgUHh7Y9K+psRhHU5VrYKMwQ4GYrdjlEREQtnqgBqLy8HElJSQgPDzfsk0qlCA8Px8GDB2s9RqPRQKFQGO1TKpXYv3+/0b6JEydi0KBBRueui0ajgUqlMtpak4Sq3p/gjg6QSTn+h4iI6G5EDUC5ubnQarVwdXU12u/q6orMzMxaj4mIiMCCBQtw8eJF6HQ67N69G9u2bUNGRoahzaZNm3D06FHExcXVq464uDjY2dkZNi8vr3u/KBFUD4Dm7S8iIqL6Ef0WWEMtWrQInTp1QkBAACwsLDBp0iRER0dDKtVfSmpqKqZMmYINGzbU6Cmqy/Tp01FYWGjYUlNTm/ISGpUgCEisGgAdxgBERERUL6IGICcnJ8hkMmRlZRntz8rKgpubW63HODs7Y8eOHVCr1bh27RrOnTsHa2tr+Pr6AgCSkpKQnZ2NXr16wczMDGZmZti7dy8WL14MMzMzaLXaGueUy+WwtbU12lqLyznFyFOXQ24mRXdPe7HLISIiahVEDUAWFhbo3bs34uPjDft0Oh3i4+PRp0+fOx6rUCjg6emJyspKbN26FUOGDAEAPPnkkzh16hSOHz9u2IKDgzF69GgcP34cMpmsSa+puSVUPf6iZwd7WJi1ug49IiIiUZiJXUBMTAyioqIQHByM0NBQLFy4EGq1GtHR0QCAMWPGwNPT0zCe5/Dhw0hPT0dQUBDS09MxZ84c6HQ6vPfeewAAGxsbPPjgg0bvYWVlhXbt2tXY3xYYFkDk+j9ERET1JnoAGjlyJHJycjBr1ixkZmYiKCgIO3fuNAyMTklJMYzvAYCysjLExsYiOTkZ1tbWGDhwINatWwd7e3uRrkBc1eN/Qn34BHgiIqL6kgiCIIhdREujUqlgZ2eHwsLCFj0eKC2/BA9//DtkUglOzn4aVnLR8ywREZFoGvL5zUEjrVhi1fo/D3rYMvwQERE1AANQK1Y9ADqU09+JiIgahAGoFTMsgMgB0ERERA3CANRK5RZrcDlHDYABiIiIqKEYgFqpI1Xjfzq7WsPBykLkaoiIiFoXBqBWiuN/iIiI7h0DUCtVPQOMt7+IiIgajgGoFSoqq8Df1wsBsAeIiIjoXjAAtUJHUwqgEwAvRyXc7ZRil0NERNTqMAC1Qpz+TkREdH8YgFqhxKoB0GG8/UVERHRPGIBambIKLY6nFgBgDxAREdG9YgBqZU6mFaJcq4OTtRw+TlZil0NERNQqMQC1MtXT30N9HCCRSESuhoiIqHViAGplDl/h+j9ERET3iwGoFanU6nD0GleAJiIiul8MQK3I2YwiFGsqYSM3Q4CbrdjlEBERtVoMQK1IQtX4n2BvB8ikHP9DRER0rxiAWhHDAoi8/UVERHRfGIBaCUEQcOQqF0AkIiJqDAxArcTlHDVuqMshN5Oiu6e92OUQERG1agxArURC1fT3IC97WJjx10ZERHQ/+EnaSlQvgMjbX0RERPePAaiVqO4B4gBoIiKi+8cA1Aqk5ZcgvaAUMqkEvTo4iF0OERFRq8cA1ApU3/560MMWVnIzkashIiJq/RiAWoGEK3z8BRERUWNiAGoFqnuA+ABUIiKixsEA1MLdKNbgUnYxAAYgIiKixsIA1MIlVq3+3NnVGg5WFiJXQ0RE1DYwALVwhunv7P0hIiJqNAxALVz1+B8OgCYiImo8DEAtWFFZBf6+XgiAAYiIiKgxMQC1YEdTCqATAC9HJdztlGKXQ0RE1GYwALVgiRz/Q0RE1CRaRABatmwZvL29oVAoEBYWhoSEhDrbVlRUYN68efDz84NCoUBgYCB27txp1Gb58uXo0aMHbG1tYWtriz59+uCXX35p6stodNUDoEMZgIiIiBqV6AFo8+bNiImJwezZs3H06FEEBgYiIiIC2dnZtbaPjY3FihUrsGTJEpw5cwavv/46hg0bhmPHjhnatG/fHh999BGSkpJw5MgRPPHEExgyZAj+/vvv5rqs+1ZWocXxtAIAHP9DRETU2CSCIAhiFhAWFoaQkBAsXboUAKDT6eDl5YXJkydj2rRpNdp7eHhgxowZmDhxomFfZGQklEol1q9fX+f7ODo64tNPP8X48ePvWpNKpYKdnR0KCwtha2t7D1d1/xKu5GHEioNwsrZA4oxwSCQSUeogIiJqLRry+S1qD1B5eTmSkpIQHh5u2CeVShEeHo6DBw/WeoxGo4FCoTDap1QqsX///lrba7VabNq0CWq1Gn369KnznCqVymgT263T3xl+iIiIGpeoASg3NxdarRaurq5G+11dXZGZmVnrMREREViwYAEuXrwInU6H3bt3Y9u2bcjIyDBqd+rUKVhbW0Mul+P111/H9u3b0bVr11rPGRcXBzs7O8Pm5eXVOBd4Hw5zADQREVGTEX0MUEMtWrQInTp1QkBAACwsLDBp0iRER0dDKjW+FH9/fxw/fhyHDx/GG2+8gaioKJw5c6bWc06fPh2FhYWGLTU1tTkupU5anYCj1/gEeCIioqYiagBycnKCTCZDVlaW0f6srCy4ubnVeoyzszN27NgBtVqNa9eu4dy5c7C2toavr69ROwsLCzzwwAPo3bs34uLiEBgYiEWLFtV6TrlcbpgxVr2J6WyGCsWaStjIzRDgJm4tREREbZGoAcjCwgK9e/dGfHy8YZ9Op0N8fHyd43WqKRQKeHp6orKyElu3bsWQIUPu2F6n00Gj0TRK3U2t+vZXb28HyKQc/0NERNTYzMQuICYmBlFRUQgODkZoaCgWLlwItVqN6OhoAMCYMWPg6emJuLg4AMDhw4eRnp6OoKAgpKenY86cOdDpdHjvvfcM55w+fToGDBiADh06oKioCBs3bsQff/yBXbt2iXKNDVW9ACJvfxERETUN0QPQyJEjkZOTg1mzZiEzMxNBQUHYuXOnYWB0SkqK0fiesrIyxMbGIjk5GdbW1hg4cCDWrVsHe3t7Q5vs7GyMGTMGGRkZsLOzQ48ePbBr1y489dRTzX15DSYIws0ZYBwATURE1CREXweoJRJzHaBL2cUIX7AXcjMpTs55GnIzWbO+PxERUWvVatYBopqqH38R5GXP8ENERNREGIBamOrbX2Ec/0NERNRkGIBamOoeoBAGICIioibDANSCpBeUIr2gFDKpBL06OIhdDhERUZvFANSCVE9/f9DDFlZy0SfoERERtVkMQC0In/9FRETUPBiAWpBbnwBPRERETYcBqIW4UazBpexiAOwBIiIiamoMQC1E4lX90987u1rDwcpC5GqIiIjaNgagFiKB43+IiIiaDQNQC8HxP0RERM2HAagFKNZU4u/rhQDYA0RERNQcGIBagKRr+dAJQHsHJTzslWKXQ0RE1OYxALUA1Qsg8vYXERFR82AAagGqB0CH8vYXERFRs2AAEllZhRbH0woAsAeIiIiouTAAiexkWiHKK3VwsraAj5OV2OUQERGZBAYgkVVPfw/xdoREIhG5GiIiItPAACSyBA6AJiIianYMQCLS6gQkXdM/AoPr/xARETUfBiARnc1QoVhTCRu5Gbq424pdDhERkclgABLR4arbX729HSCTcvwPERFRc2EAEhEXQCQiIhIHA5BIBEG4+QBUjv8hIiJqVgxAIrmco8YNdTkszKTo3t5O7HKIiIhMCgOQSKp7f3p62UNuJhO5GiIiItPCACQSrv9DREQkHgYgkTAAERERiYcBSATpBaVILyiFTCpBrw4OYpdDRERkchiARFA9/f1BD1tYyc1EroaIiMj0MACJoHoBRD7+goiISBwMQCIwPAGe43+IiIhEwQDUzG4Ua3ApuxgAe4CIiIjEwgDUzBKv6p/+3snFGo5WFiJXQ0REZJpaRABatmwZvL29oVAoEBYWhoSEhDrbVlRUYN68efDz84NCoUBgYCB27txp1CYuLg4hISGwsbGBi4sLhg4divPnzzf1ZdSL4fEXvP1FREQkGtED0ObNmxETE4PZs2fj6NGjCAwMREREBLKzs2ttHxsbixUrVmDJkiU4c+YMXn/9dQwbNgzHjh0ztNm7dy8mTpyIQ4cOYffu3aioqMDTTz8NtVrdXJdVJ67/Q0REJD6JIAiCmAWEhYUhJCQES5cuBQDodDp4eXlh8uTJmDZtWo32Hh4emDFjBiZOnGjYFxkZCaVSifXr19f6Hjk5OXBxccHevXvRv3//u9akUqlgZ2eHwsJC2Nra3uOV1VSsqUSPObugE4AD056Ah72y0c5NRERk6hry+S1qD1B5eTmSkpIQHh5u2CeVShEeHo6DBw/WeoxGo4FCoTDap1QqsX///jrfp7CwEADg6Fh7r4tGo4FKpTLamkLStXzoBKC9g5Lhh4iISESiBqDc3FxotVq4uroa7Xd1dUVmZmatx0RERGDBggW4ePEidDoddu/ejW3btiEjI6PW9jqdDlOnTkW/fv3w4IMP1tomLi4OdnZ2hs3Ly+v+LqwOuUUa2CjMEMrZX0RERKISfQxQQy1atAidOnVCQEAALCwsMGnSJERHR0Mqrf1SJk6ciNOnT2PTpk11nnP69OkoLCw0bKmpqU1Se2Tv9jg+62nMfq5bk5yfiIiI6kfUAOTk5ASZTIasrCyj/VlZWXBzc6v1GGdnZ+zYsQNqtRrXrl3DuXPnYG1tDV9f3xptJ02ahJ9++gm///472rdvX2cdcrkctra2RltTkUklsFOaN9n5iYiI6O5EDUAWFhbo3bs34uPjDft0Oh3i4+PRp0+fOx6rUCjg6emJyspKbN26FUOGDDH8TBAETJo0Cdu3b8dvv/0GHx+fJrsGIiIian1EfxJnTEwMoqKiEBwcjNDQUCxcuBBqtRrR0dEAgDFjxsDT0xNxcXEAgMOHDyM9PR1BQUFIT0/HnDlzoNPp8N577xnOOXHiRGzcuBE//PADbGxsDOOJ7OzsoFRy8DEREZGpEz0AjRw5Ejk5OZg1axYyMzMRFBSEnTt3GgZGp6SkGI3vKSsrQ2xsLJKTk2FtbY2BAwdi3bp1sLe3N7RZvnw5AOCxxx4zeq81a9Zg7NixTX1JRERE1MKJvg5QS9RU6wARERFR02k16wARERERiYEBiIiIiEwOAxARERGZHAYgIiIiMjkMQERERGRyGICIiIjI5DAAERERkclhACIiIiKTwwBEREREJkf0R2G0RNWLY6tUKpErISIiovqq/tyuz0MuGIBqUVRUBADw8vISuRIiIiJqqKKiItjZ2d2xDZ8FVgudTofr16/DxsYGEomkUc+tUqng5eWF1NRUPmesBeDvo2Xh76Nl4e+j5eHv5M4EQUBRURE8PDyMHqReG/YA1UIqlaJ9+/ZN+h62trb8y9uC8PfRsvD30bLw99Hy8HdSt7v1/FTjIGgiIiIyOQxAREREZHIYgJqZXC7H7NmzIZfLxS6FwN9HS8PfR8vC30fLw99J4+EgaCIiIjI57AEiIiIik8MARERERCaHAYiIiIhMDgMQERERmRwGoGa0bNkyeHt7Q6FQICwsDAkJCWKXZLLi4uIQEhICGxsbuLi4YOjQoTh//rzYZRGAjz76CBKJBFOnThW7FJOWnp6Ol19+Ge3atYNSqUT37t1x5MgRscsySVqtFjNnzoSPjw+USiX8/PzwwQcf1Ot5V1Q3BqBmsnnzZsTExGD27Nk4evQoAgMDERERgezsbLFLM0l79+7FxIkTcejQIezevRsVFRV4+umnoVarxS7NpCUmJmLFihXo0aOH2KWYtPz8fPTr1w/m5ub45ZdfcObMGXz++edwcHAQuzST9PHHH2P58uVYunQpzp49i48//hiffPIJlixZInZprRqnwTeTsLAwhISEYOnSpQD0zxvz8vLC5MmTMW3aNJGro5ycHLi4uGDv3r3o37+/2OWYpOLiYvTq1Qv/+c9/8O9//xtBQUFYuHCh2GWZpGnTpuGvv/7Cn3/+KXYpBODZZ5+Fq6srvvrqK8O+yMhIKJVKrF+/XsTKWjf2ADWD8vJyJCUlITw83LBPKpUiPDwcBw8eFLEyqlZYWAgAcHR0FLkS0zVx4kQMGjTI6L8TEsePP/6I4OBgDB8+HC4uLujZsydWrVoldlkmq2/fvoiPj8eFCxcAACdOnMD+/fsxYMAAkStr3fgw1GaQm5sLrVYLV1dXo/2urq44d+6cSFVRNZ1Oh6lTp6Jfv3548MEHxS7HJG3atAlHjx5FYmKi2KUQgOTkZCxfvhwxMTF4//33kZiYiLfeegsWFhaIiooSuzyTM23aNKhUKgQEBEAmk0Gr1eLDDz/E6NGjxS6tVWMAIpM3ceJEnD59Gvv37xe7FJOUmpqKKVOmYPfu3VAoFGKXQ9D/oyA4OBjz588HAPTs2ROnT5/Gl19+yQAkgu+++w4bNmzAxo0b0a1bNxw/fhxTp06Fh4cHfx/3gQGoGTg5OUEmkyErK8tof1ZWFtzc3ESqigBg0qRJ+Omnn7Bv3z60b99e7HJMUlJSErKzs9GrVy/DPq1Wi3379mHp0qXQaDSQyWQiVmh63N3d0bVrV6N9Xbp0wdatW0WqyLT985//xLRp0/Diiy8CALp3745r164hLi6OAeg+cAxQM7CwsEDv3r0RHx9v2KfT6RAfH48+ffqIWJnpEgQBkyZNwvbt2/Hbb7/Bx8dH7JJM1pNPPolTp07h+PHjhi04OBijR4/G8ePHGX5E0K9fvxrLQly4cAEdO3YUqSLTVlJSAqnU+ONaJpNBp9OJVFHbwB6gZhITE4OoqCgEBwcjNDQUCxcuhFqtRnR0tNilmaSJEydi48aN+OGHH2BjY4PMzEwAgJ2dHZRKpcjVmRYbG5saY6+srKzQrl07jskSydtvv42+ffti/vz5GDFiBBISErBy5UqsXLlS7NJM0uDBg/Hhhx+iQ4cO6NatG44dO4YFCxZg3LhxYpfWqnEafDNaunQpPv30U2RmZiIoKAiLFy9GWFiY2GWZJIlEUuv+NWvWYOzYsc1bDNXw2GOPcRq8yH766SdMnz4dFy9ehI+PD2JiYjBhwgSxyzJJRUVFmDlzJrZv347s7Gx4eHhg1KhRmDVrFiwsLMQur9ViACIiIiKTwzFAREREZHIYgIiIiMjkMAARERGRyWEAIiIiIpPDAEREREQmhwGIiIiITA4DEBEREZkcBiAionqQSCTYsWOH2GUQUSNhACKiFm/s2LGQSCQ1tmeeeUbs0oioleKzwIioVXjmmWewZs0ao31yuVykaoiotWMPEBG1CnK5HG5ubkabg4MDAP3tqeXLl2PAgAFQKpXw9fXF999/b3T8qVOn8MQTT0CpVKJdu3Z47bXXUFxcbNRm9erV6NatG+RyOdzd3TFp0iSjn+fm5mLYsGGwtLREp06d8OOPPzbtRRNRk2EAIqI2YebMmYiMjMSJEycwevRovPjiizh79iwAQK1WIyIiAg4ODkhMTMSWLVuwZ88eo4CzfPlyTJw4Ea+99hpOnTqFH3/8EQ888IDRe8ydOxcjRozAyZMnMXDgQIwePRp5eXnNep1E1EgEIqIWLioqSpDJZIKVlZXR9uGHHwqCIAgAhNdff93omLCwMOGNN94QBEEQVq5cKTg4OAjFxcWGn//888+CVCoVMjMzBUEQBA8PD2HGjBl11gBAiI2NNbwuLi4WAAi//PJLo10nETUfjgEiolbh8ccfx/Lly432OTo6Gr7v06eP0c/69OmD48ePAwDOnj2LwMBAWFlZGX7er18/6HQ6nD9/HhKJBNevX8eTTz55xxp69Ohh+N7Kygq2trbIzs6+10siIhExABFRq2BlZVXjllRjUSqV9Wpnbm5u9FoikUCn0zVFSUTUxDgGiIjahEOHDtV43aVLFwBAly5dcOLECajVasPP//rrL0ilUvj7+8PGxgbe3t6Ij49v1pqJSDzsASKiVkGj0SAzM9Non5mZGZycnAAAW7ZsQXBwMB5++GFs2LABCQkJ+OqrrwAAo0ePxuzZsxEVFYU5c+YgJycHkydPxiuvvAJXV1cAwJw5c/D666/DxcUFAwYMQFFREf766y9Mnjy5eS+UiJoFAxARtQo7d+6Eu7u70T5/f3+cO3cOgH6G1qZNm/Dmm2/C3d0d3377Lbp27QoAsLS0xK5duzBlyhSEhITA0tISkZGRWLBggeFcUVFRKCsrwxdffIF3330XTk5OeOGFF5rvAomoWUkEQRDELoKI6H5IJBJs374dQ4cOFbsUImolOAaIiIiITA4DEBEREZkcjgEiolaPd/KJqKHYA0REREQmhwGIiIiITA4DEBEREZkcBiAiIiIyOQxAREREZHIYgIiIiMjkMAARERGRyWEAIiIiIpPDAEREREQm5/8BLR9gymgJuoMAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}